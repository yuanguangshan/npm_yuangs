# Threat Model & Security Boundaries

> 本文档显式描述 yuangs 的威胁模型、攻击面与防御边界。  
> 目标是回答：  
> **系统在假设什么可能出错，以及如何确保最坏情况下仍可控。**

---

## 1. 威胁假设（Threat Assumptions）

yuangs 假设以下情况**一定会发生**：

- AI 可能产生错误、幻觉或过度自信的建议
- 用户可能在压力或疲劳状态下操作
- 执行环境可能包含高价值资产（代码、数据、凭据）

---

## 2. 主要威胁源

### 2.1 AI 层风险

- 错误推理
- 不完整上下文下的过度推断
- 建议具有破坏性的命令

✅ 防御：
- AI 无执行权限
- 所有建议需用户确认

---

### 2.2 上下文泄露风险

- 读取未授权文件
- 扫描敏感目录
- 环境变量暴露

✅ 防御：
- 显式上下文声明
- 默认零上下文
- 无隐式扫描
(例外：Git Diff 仅限当前变更，不含历史)

---

### 2.3 代理失控风险 (Agent Overreach)

- Planner 自动推进任务
- Auto-retry 无限循环
- "修复"操作引入更大破坏

✅ 防御：
- Planner 产出仅为建议列表
- 步骤间必须有 Explicit User Gate (人工关卡)
- 严禁 Loop 自动闭环

---

### 2.4 人为误操作风险

---

### 2.3 人为误操作风险

- 误执行建议命令
- 忽略命令真实含义

✅ 防御：
- 命令可见
- 无自动执行
- `\:exec` 明确语义

---

## 3. 不在威胁模型内的事项

yuangs **不尝试防御**：

- 用户主动执行的破坏性命令
- 合法权限下的人为错误
- 系统级漏洞（Kernel / OS）

原因：  
> **yuangs 的目标是语义安全，而不是权限沙箱。**

---

## 4. 安全边界总结

| 边界 | 说明 |
|----|----|
| 执行边界 | 仅用户可执行 |
| 推理边界 | AI 不可越权 |
| 上下文边界 | 必须显式声明 |
| 责任边界 | 执行即责任 |

---

## 5. 最终原则

> **在最坏情况下，  
> yuangs 允许犯错，但不允许失控。**

---

## 结语（工程声明）

当一个系统涉及 AI 与执行能力时：

- 不明确边界 = 不安全
- 不可审计 = 不可靠

**yuangs 选择牺牲魔法感，  
换取长期工程可信度。**
