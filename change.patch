diff --git a/.github/workflows/publish.yml b/.github/workflows/publish.yml
deleted file mode 100644
index 90198ab..0000000
--- a/.github/workflows/publish.yml
+++ /dev/null
@@ -1,35 +0,0 @@
-name: Publish to npm
-
-on:
-  push:
-    tags:
-      - "v*"
-
-jobs:
-  publish:
-    runs-on: ubuntu-latest
-
-    permissions:
-      contents: read        # åªè¯»å³å¯
-      id-token: write       # npm provenance å¿…éœ€
-
-    steps:
-      - name: Checkout repository
-        uses: actions/checkout@v4
-
-      - name: Set up Node.js
-        uses: actions/setup-node@v4
-        with:
-          node-version: "18"
-          registry-url: "https://registry.npmjs.org/"
-
-      - name: Install dependencies
-        run: npm ci
-
-      - name: Build
-        run: npm run build
-
-      - name: Publish to npm
-        run: npm publish --provenance
-        env:
-          NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}
diff --git a/change.patch b/change.patch
index 0ce3233..e69de29 100644
--- a/change.patch
+++ b/change.patch
@@ -1,1606 +0,0 @@
-diff --git a/AGENT_PIPELINE.md b/AGENT_PIPELINE.md
-new file mode 100644
-index 0000000..bd7bdc8
---- /dev/null
-+++ b/AGENT_PIPELINE.md
-@@ -0,0 +1,249 @@
-+# Agent Pipeline Architecture
-+
-+## æ¦‚è¿°
-+
-+ç‰ˆæœ¬ 2.1.0 å¼•å…¥äº†å…¨æ–°çš„ **Agent Pipeline** æ¶æ„ï¼Œç»Ÿä¸€äº† AI Chat å’Œ AI Command çš„æ‰§è¡Œæµç¨‹ã€‚è¿™æ˜¯ä¸€ä¸ªå¯æ‰©å±•ã€å¯è°ƒè¯•ã€å¯è¿›åŒ–çš„æ™ºèƒ½ä½“ç³»ç»Ÿã€‚
-+
-+## æ ¸å¿ƒæ¶æ„
-+
-+### Pipeline é˜¶æ®µ
-+
-+```
-+User Input
-+   â†“
-+1. Intent Analysis (æ„å›¾åˆ†æ)
-+   â†“
-+2. Context Assembly (ä¸Šä¸‹æ–‡ç»„è£…)
-+   â†“
-+3. Prompt Construction (æç¤ºè¯æ„å»º)
-+   â†“
-+4. Model Selection (æ¨¡å‹é€‰æ‹©)
-+   â†“
-+5. LLM Execution (LLM æ‰§è¡Œ)
-+   â†“
-+6. Result Interpretation (ç»“æœè§£é‡Š)
-+   â†“
-+7. Action Execution (åŠ¨ä½œæ‰§è¡Œ)
-+   â†“
-+8. Execution Record (æ‰§è¡Œè®°å½•)
-+```
-+
-+### ç›®å½•ç»“æ„
-+
-+```
-+src/agent/
-+â”œâ”€â”€ AgentPipeline.ts    # æ ¸å¿ƒç¼–æ’å™¨
-+â”œâ”€â”€ types.ts            # ç±»å‹å®šä¹‰
-+â”œâ”€â”€ intent.ts           # æ„å›¾æ¨æ–­
-+â”œâ”€â”€ context.ts          # ä¸Šä¸‹æ–‡ç»„è£…
-+â”œâ”€â”€ prompt.ts           # æç¤ºè¯æ„å»º
-+â”œâ”€â”€ selectModel.ts      # æ¨¡å‹é€‰æ‹©
-+â”œâ”€â”€ llm.ts              # LLM æ‰§è¡Œ
-+â”œâ”€â”€ interpret.ts        # ç»“æœè§£é‡Š
-+â”œâ”€â”€ actions.ts          # åŠ¨ä½œæ‰§è¡Œ
-+â”œâ”€â”€ record.ts           # æ‰§è¡Œè®°å½•
-+â”œâ”€â”€ replay.ts           # é‡æ”¾åŠŸèƒ½
-+â””â”€â”€ index.ts            # å¯¼å‡º
-+```
-+
-+## æ ¸å¿ƒæ¦‚å¿µ
-+
-+### AgentMode
-+
-+ä¸‰ç§è¿è¡Œæ¨¡å¼ï¼š
-+
-+- `chat`: AI èŠå¤©æ¨¡å¼ï¼ˆæµå¼è¾“å‡ºï¼Œæ— å‘½ä»¤æ‰§è¡Œï¼‰
-+- `command`: ç”Ÿæˆ shell å‘½ä»¤ï¼ˆéœ€è¦ç¡®è®¤ï¼‰
-+- `command+exec`: ç”Ÿæˆå¹¶æ‰§è¡Œå‘½ä»¤
-+
-+### AgentInput
-+
-+ç»Ÿä¸€çš„è¾“å…¥æ¥å£ï¼š
-+
-+```typescript
-+interface AgentInput {
-+  rawInput: string;           // ç”¨æˆ·è¾“å…¥
-+  stdin?: string;             // ç®¡é“è¾“å…¥
-+  context?: AgentContext;     // ä¸Šä¸‹æ–‡
-+  options?: {
-+    model?: string;           // æŒ‡å®šæ¨¡å‹
-+    stream?: boolean;         // æ˜¯å¦æµå¼
-+    autoYes?: boolean;        // è‡ªåŠ¨ç¡®è®¤
-+    verbose?: boolean;        // è¯¦ç»†è¾“å‡º
-+  };
-+}
-+```
-+
-+### AgentContext
-+
-+ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
-+
-+```typescript
-+interface AgentContext {
-+  files?: Array<{           // æ–‡ä»¶ä¸Šä¸‹æ–‡
-+    path: string;
-+    content: string;
-+  }>;
-+  gitDiff?: string;         // Git å·®å¼‚
-+  history?: AIRequestMessage[];  // å¯¹è¯å†å²
-+}
-+```
-+
-+## ä½¿ç”¨ç¤ºä¾‹
-+
-+### åŸºç¡€ç”¨æ³•
-+
-+```typescript
-+import { AgentPipeline } from './agent';
-+
-+const agent = new AgentPipeline();
-+
-+// Chat æ¨¡å¼
-+await agent.run(
-+  { rawInput: "è§£é‡Šä¸€ä¸‹å†’æ³¡æ’åº" },
-+  'chat'
-+);
-+
-+// Command æ¨¡å¼
-+await agent.run(
-+  { rawInput: "åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶" },
-+  'command'
-+);
-+```
-+
-+### é«˜çº§ç”¨æ³•
-+
-+```typescript
-+// å¸¦ä¸Šä¸‹æ–‡çš„æŸ¥è¯¢
-+await agent.run(
-+  {
-+    rawInput: "è¿™ä¸ªæ–‡ä»¶æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
-+    context: {
-+      files: [{
-+        path: 'src/index.ts',
-+        content: fs.readFileSync('src/index.ts', 'utf8')
-+      }]
-+    },
-+    options: {
-+      model: 'gemini-2.0-flash-exp',
-+      verbose: true
-+    }
-+  },
-+  'chat'
-+);
-+```
-+
-+## æ‰§è¡Œè®°å½•ä¸é‡æ”¾
-+
-+### æ‰§è¡Œè®°å½•
-+
-+æ¯æ¬¡ Agent è¿è¡Œéƒ½ä¼šè‡ªåŠ¨ä¿å­˜æ‰§è¡Œè®°å½•ï¼š
-+
-+```typescript
-+interface ExecutionRecord {
-+  id: string;                 // å”¯ä¸€ ID
-+  timestamp: number;          // æ—¶é—´æˆ³
-+  mode: AgentMode;            // è¿è¡Œæ¨¡å¼
-+  input: AgentInput;          // è¾“å…¥
-+  prompt: AgentPrompt;        // æç¤ºè¯
-+  model: string;              // ä½¿ç”¨çš„æ¨¡å‹
-+  llmResult: LLMResult;       // LLM ç»“æœ
-+  action: AgentAction;        // æ‰§è¡Œçš„åŠ¨ä½œ
-+}
-+```
-+
-+### é‡æ”¾åŠŸèƒ½
-+
-+```typescript
-+import { replay, getRecordById } from './agent/replay';
-+
-+// è·å–è®°å½•
-+const record = getRecordById('some-uuid');
-+
-+// é‡æ”¾æ‰§è¡Œ
-+if (record) {
-+  await replay(record);
-+}
-+```
-+
-+## èƒ½åŠ›ç³»ç»Ÿé›†æˆ
-+
-+Agent Pipeline å®Œå…¨é›†æˆäº†ç°æœ‰çš„ Capability Systemï¼š
-+
-+- **Intent Analysis**: è‡ªåŠ¨æ¨æ–­æ‰€éœ€èƒ½åŠ›
-+- **Model Selection**: æ ¹æ®èƒ½åŠ›é€‰æ‹©æœ€ä½³æ¨¡å‹
-+- **Execution Record**: è®°å½•èƒ½åŠ›åŒ¹é…ç»“æœ
-+
-+## æ‰©å±•æ€§
-+
-+### æ·»åŠ æ–°çš„ Action ç±»å‹
-+
-+```typescript
-+// åœ¨ types.ts ä¸­æ‰©å±• AgentAction
-+export type AgentAction =
-+  | { type: 'print'; content: string }
-+  | { type: 'confirm'; next: AgentAction }
-+  | { type: 'execute'; command: string; risk: 'low' | 'medium' | 'high' }
-+  | { type: 'custom'; handler: () => Promise<void> };  // æ–°ç±»å‹
-+
-+// åœ¨ actions.ts ä¸­å®ç°
-+if (action.type === 'custom') {
-+  await action.handler();
-+}
-+```
-+
-+### æ·»åŠ æ–°çš„ Context æ¥æº
-+
-+```typescript
-+// åœ¨ context.ts ä¸­æ‰©å±•
-+export function buildContext(input: AgentInput): AgentContext {
-+  return {
-+    files: getFiles(),
-+    gitDiff: getGitDiff(),
-+    history: getHistory(),
-+    // æ–°å¢
-+    systemInfo: getSystemInfo(),
-+    recentCommands: getRecentCommands(),
-+  };
-+}
-+```
-+
-+## ä¸‹ä¸€æ­¥è®¡åˆ’
-+
-+æ ¹æ® todo.mdï¼Œåç»­å°†å®ç°ï¼š
-+
-+1. **Planner / Tool Calling**: å¤šæ­¥ Agent æ‰§è¡Œ
-+2. **Agent Memory**: é•¿æœŸè®°å¿†ä¸æ‘˜è¦
-+3. **æˆæœ¬ / Token å¯è§†åŒ–**: æ‰§è¡ŒæŒ‡æ ‡è¿½è¸ª
-+4. **é£é™©ç­–ç•¥**: é«˜é£é™©å‘½ä»¤å¼ºåˆ¶å¤šç¡®è®¤
-+5. **Multi-Agent**: Planner / Executor / Critic åˆ†ä½“
-+6. **UI åŒ–**: Timeline + Replay + Diff
-+
-+## è¿ç§»æŒ‡å—
-+
-+### ä»æ—§ç³»ç»Ÿè¿ç§»
-+
-+æ—§çš„ `handleAICommand` å’Œ `handleAIChat` ä»ç„¶å¯ç”¨ï¼Œä½†å»ºè®®é€æ­¥è¿ç§»åˆ° Agent Pipelineï¼š
-+
-+```typescript
-+// æ—§æ–¹å¼
-+await handleAICommand(question, { execute: false, model });
-+
-+// æ–°æ–¹å¼
-+const agent = new AgentPipeline();
-+await agent.run(
-+  { rawInput: question, options: { model } },
-+  'command'
-+);
-+```
-+
-+### å…¼å®¹æ€§
-+
-+- âœ… å®Œå…¨å‘åå…¼å®¹ç°æœ‰ CLI å‘½ä»¤
-+- âœ… å¤ç”¨ç°æœ‰çš„ Capability System
-+- âœ… å¤ç”¨ç°æœ‰çš„ AI Client
-+- âœ… å¤ç”¨ç°æœ‰çš„ Context Buffer
-+
-+## è´¡çŒ®
-+
-+æ¬¢è¿è´¡çŒ®æ–°çš„ Agent èƒ½åŠ›å’Œæ‰©å±•ï¼è¯·å‚è€ƒ `src/agent/` ç›®å½•ä¸‹çš„ä»£ç ç»“æ„ã€‚
-diff --git a/dist/agent/AgentPipeline.d.ts b/dist/agent/AgentPipeline.d.ts
-new file mode 100644
-index 0000000..5301aaf
---- /dev/null
-+++ b/dist/agent/AgentPipeline.d.ts
-@@ -0,0 +1,4 @@
-+import { AgentInput, AgentMode } from './types';
-+export declare class AgentPipeline {
-+    run(input: AgentInput, mode: AgentMode): Promise<void>;
-+}
-diff --git a/dist/agent/AgentPipeline.js b/dist/agent/AgentPipeline.js
-new file mode 100644
-index 0000000..4b457c1
---- /dev/null
-+++ b/dist/agent/AgentPipeline.js
-@@ -0,0 +1,62 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.AgentPipeline = void 0;
-+const intent_1 = require("./intent");
-+const context_1 = require("./context");
-+const prompt_1 = require("./prompt");
-+const selectModel_1 = require("./selectModel");
-+const llm_1 = require("./llm");
-+const interpret_1 = require("./interpret");
-+const actions_1 = require("./actions");
-+const record_1 = require("./record");
-+const crypto_1 = require("crypto");
-+class AgentPipeline {
-+    async run(input, mode) {
-+        const id = (0, crypto_1.randomUUID)();
-+        // 1. Intent Analysis
-+        const intent = (0, intent_1.inferIntent)(input, mode);
-+        // 2. Context Assembly
-+        const context = (0, context_1.buildContext)(input);
-+        // 3. Prompt Construction
-+        const prompt = (0, prompt_1.buildPrompt)(intent, context, mode, input.rawInput);
-+        // 4. Model Selection
-+        const model = (0, selectModel_1.selectModel)(intent, input.options?.model);
-+        // 5. LLM Execution
-+        const result = await (0, llm_1.runLLM)({
-+            prompt,
-+            model,
-+            stream: mode === 'chat',
-+            onChunk: mode === 'chat'
-+                ? (s) => process.stdout.write(s)
-+                : undefined,
-+        });
-+        // 6. Result Interpretation
-+        const action = (0, interpret_1.interpretResult)(result, intent, mode);
-+        // 7. Save Execution Record (before execution for safety)
-+        (0, record_1.saveRecord)({
-+            id,
-+            timestamp: Date.now(),
-+            mode,
-+            input,
-+            prompt,
-+            model,
-+            llmResult: result,
-+            action,
-+        });
-+        // 8. Action Execution
-+        await (0, actions_1.executeAction)(action, input.options);
-+        // Log execution metrics if verbose
-+        if (input.options?.verbose) {
-+            console.log(`\n${'-'.repeat(50)}`);
-+            console.log(`Execution ID: ${id}`);
-+            console.log(`Model: ${model}`);
-+            console.log(`Latency: ${result.latencyMs}ms`);
-+            if (result.tokens) {
-+                console.log(`Tokens: ${result.tokens.total}`);
-+            }
-+            console.log(`${'-'.repeat(50)}\n`);
-+        }
-+    }
-+}
-+exports.AgentPipeline = AgentPipeline;
-+//# sourceMappingURL=AgentPipeline.js.map
-\ No newline at end of file
-diff --git a/dist/agent/actions.d.ts b/dist/agent/actions.d.ts
-new file mode 100644
-index 0000000..60b8e87
---- /dev/null
-+++ b/dist/agent/actions.d.ts
-@@ -0,0 +1,4 @@
-+import { AgentAction } from './types';
-+export declare function executeAction(action: AgentAction, options?: {
-+    autoYes?: boolean;
-+}): Promise<void>;
-diff --git a/dist/agent/actions.js b/dist/agent/actions.js
-new file mode 100644
-index 0000000..9056f15
---- /dev/null
-+++ b/dist/agent/actions.js
-@@ -0,0 +1,51 @@
-+"use strict";
-+var __importDefault = (this && this.__importDefault) || function (mod) {
-+    return (mod && mod.__esModule) ? mod : { "default": mod };
-+};
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.executeAction = executeAction;
-+const child_process_1 = require("child_process");
-+const util_1 = require("util");
-+const chalk_1 = __importDefault(require("chalk"));
-+const readline_1 = __importDefault(require("readline"));
-+const execAsync = (0, util_1.promisify)(child_process_1.exec);
-+async function executeAction(action, options) {
-+    if (action.type === 'print') {
-+        console.log(action.content);
-+        return;
-+    }
-+    if (action.type === 'confirm') {
-+        const ok = options?.autoYes || await confirm('Execute this action?');
-+        if (ok) {
-+            await executeAction(action.next, options);
-+        }
-+        return;
-+    }
-+    if (action.type === 'execute') {
-+        try {
-+            console.log(chalk_1.default.cyan(`\nExecuting: ${action.command}\n`));
-+            const { stdout, stderr } = await execAsync(action.command);
-+            if (stdout)
-+                console.log(stdout);
-+            if (stderr)
-+                console.error(chalk_1.default.yellow(stderr));
-+        }
-+        catch (error) {
-+            console.error(chalk_1.default.red(`Execution failed: ${error.message}`));
-+            throw error;
-+        }
-+    }
-+}
-+async function confirm(message) {
-+    const rl = readline_1.default.createInterface({
-+        input: process.stdin,
-+        output: process.stdout,
-+    });
-+    return new Promise((resolve) => {
-+        rl.question(chalk_1.default.cyan(`${message} (y/N): `), (answer) => {
-+            rl.close();
-+            resolve(answer.toLowerCase() === 'y' || answer.toLowerCase() === 'yes');
-+        });
-+    });
-+}
-+//# sourceMappingURL=actions.js.map
-\ No newline at end of file
-diff --git a/dist/agent/context.d.ts b/dist/agent/context.d.ts
-new file mode 100644
-index 0000000..b79baf0
---- /dev/null
-+++ b/dist/agent/context.d.ts
-@@ -0,0 +1,4 @@
-+import { AgentInput, AgentContext } from './types';
-+import { ContextBuffer } from '../commands/contextBuffer';
-+export declare function buildContext(input: AgentInput): AgentContext;
-+export declare function getAgentContextBuffer(): ContextBuffer;
-diff --git a/dist/agent/context.js b/dist/agent/context.js
-new file mode 100644
-index 0000000..efdfeab
---- /dev/null
-+++ b/dist/agent/context.js
-@@ -0,0 +1,22 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.buildContext = buildContext;
-+exports.getAgentContextBuffer = getAgentContextBuffer;
-+const contextBuffer_1 = require("../commands/contextBuffer");
-+// Create a singleton instance for the agent
-+const globalContextBuffer = new contextBuffer_1.ContextBuffer();
-+function buildContext(input) {
-+    const items = globalContextBuffer.export();
-+    return {
-+        files: items.map(item => ({
-+            path: item.path,
-+            content: item.content,
-+        })),
-+        gitDiff: undefined, // Will be enhanced later
-+        history: [], // Will be populated from conversation history
-+    };
-+}
-+function getAgentContextBuffer() {
-+    return globalContextBuffer;
-+}
-+//# sourceMappingURL=context.js.map
-\ No newline at end of file
-diff --git a/dist/agent/index.d.ts b/dist/agent/index.d.ts
-new file mode 100644
-index 0000000..d186c12
---- /dev/null
-+++ b/dist/agent/index.d.ts
-@@ -0,0 +1,2 @@
-+export { AgentPipeline } from './AgentPipeline';
-+export * from './types';
-diff --git a/dist/agent/index.js b/dist/agent/index.js
-new file mode 100644
-index 0000000..7679fad
---- /dev/null
-+++ b/dist/agent/index.js
-@@ -0,0 +1,21 @@
-+"use strict";
-+var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
-+    if (k2 === undefined) k2 = k;
-+    var desc = Object.getOwnPropertyDescriptor(m, k);
-+    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
-+      desc = { enumerable: true, get: function() { return m[k]; } };
-+    }
-+    Object.defineProperty(o, k2, desc);
-+}) : (function(o, m, k, k2) {
-+    if (k2 === undefined) k2 = k;
-+    o[k2] = m[k];
-+}));
-+var __exportStar = (this && this.__exportStar) || function(m, exports) {
-+    for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);
-+};
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.AgentPipeline = void 0;
-+var AgentPipeline_1 = require("./AgentPipeline");
-+Object.defineProperty(exports, "AgentPipeline", { enumerable: true, get: function () { return AgentPipeline_1.AgentPipeline; } });
-+__exportStar(require("./types"), exports);
-+//# sourceMappingURL=index.js.map
-\ No newline at end of file
-diff --git a/dist/agent/intent.d.ts b/dist/agent/intent.d.ts
-new file mode 100644
-index 0000000..f4a378e
---- /dev/null
-+++ b/dist/agent/intent.d.ts
-@@ -0,0 +1,2 @@
-+import { AgentInput, AgentIntent, AgentMode } from './types';
-+export declare function inferIntent(input: AgentInput, mode: AgentMode): AgentIntent;
-diff --git a/dist/agent/intent.js b/dist/agent/intent.js
-new file mode 100644
-index 0000000..f30203f
---- /dev/null
-+++ b/dist/agent/intent.js
-@@ -0,0 +1,28 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.inferIntent = inferIntent;
-+const capabilityInference_1 = require("../core/capabilityInference");
-+const capabilities_1 = require("../core/capabilities");
-+function inferIntent(input, mode) {
-+    if (mode === 'chat') {
-+        return {
-+            type: 'chat',
-+            capabilities: {
-+                reasoning: true,
-+                streaming: true,
-+                longContext: true,
-+            },
-+        };
-+    }
-+    // For command mode, use the existing capability inference
-+    const capReq = (0, capabilityInference_1.inferCapabilityRequirement)(input.rawInput);
-+    return {
-+        type: 'shell',
-+        capabilities: {
-+            reasoning: capReq.required.includes(capabilities_1.AtomicCapability.REASONING),
-+            code: capReq.required.includes(capabilities_1.AtomicCapability.CODE_GENERATION),
-+            longContext: capReq.required.includes(capabilities_1.AtomicCapability.LONG_CONTEXT),
-+        },
-+    };
-+}
-+//# sourceMappingURL=intent.js.map
-\ No newline at end of file
-diff --git a/dist/agent/interpret.d.ts b/dist/agent/interpret.d.ts
-new file mode 100644
-index 0000000..f0df3fa
---- /dev/null
-+++ b/dist/agent/interpret.d.ts
-@@ -0,0 +1,2 @@
-+import { AgentIntent, AgentMode, LLMResult, AgentAction } from './types';
-+export declare function interpretResult(result: LLMResult, intent: AgentIntent, mode: AgentMode): AgentAction;
-diff --git a/dist/agent/interpret.js b/dist/agent/interpret.js
-new file mode 100644
-index 0000000..9f348ba
---- /dev/null
-+++ b/dist/agent/interpret.js
-@@ -0,0 +1,21 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.interpretResult = interpretResult;
-+function interpretResult(result, intent, mode) {
-+    if (mode === 'chat') {
-+        return { type: 'print', content: result.rawText };
-+    }
-+    const plan = result.parsed;
-+    if (!plan || !plan.command) {
-+        throw new Error('Invalid command plan from LLM');
-+    }
-+    return {
-+        type: 'confirm',
-+        next: {
-+            type: 'execute',
-+            command: plan.command,
-+            risk: plan.risk ?? 'medium',
-+        },
-+    };
-+}
-+//# sourceMappingURL=interpret.js.map
-\ No newline at end of file
-diff --git a/dist/agent/llm.d.ts b/dist/agent/llm.d.ts
-new file mode 100644
-index 0000000..ec69906
---- /dev/null
-+++ b/dist/agent/llm.d.ts
-@@ -0,0 +1,7 @@
-+import { AgentPrompt, LLMResult } from './types';
-+export declare function runLLM({ prompt, model, stream, onChunk, }: {
-+    prompt: AgentPrompt;
-+    model: string;
-+    stream: boolean;
-+    onChunk?: (s: string) => void;
-+}): Promise<LLMResult>;
-diff --git a/dist/agent/llm.js b/dist/agent/llm.js
-new file mode 100644
-index 0000000..e5efa78
---- /dev/null
-+++ b/dist/agent/llm.js
-@@ -0,0 +1,76 @@
-+"use strict";
-+var __importDefault = (this && this.__importDefault) || function (mod) {
-+    return (mod && mod.__esModule) ? mod : { "default": mod };
-+};
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.runLLM = runLLM;
-+const client_1 = require("../ai/client");
-+const axios_1 = __importDefault(require("axios"));
-+const validation_1 = require("../core/validation");
-+const fs_1 = __importDefault(require("fs"));
-+const path_1 = __importDefault(require("path"));
-+const os_1 = __importDefault(require("os"));
-+const validation_2 = require("../core/validation");
-+const CONFIG_FILE = path_1.default.join(os_1.default.homedir(), '.yuangs.json');
-+function getUserConfig() {
-+    if (fs_1.default.existsSync(CONFIG_FILE)) {
-+        try {
-+            const content = fs_1.default.readFileSync(CONFIG_FILE, 'utf8');
-+            return JSON.parse(content);
-+        }
-+        catch (e) { }
-+    }
-+    return {};
-+}
-+async function runLLM({ prompt, model, stream, onChunk, }) {
-+    const start = Date.now();
-+    if (stream) {
-+        let raw = '';
-+        await (0, client_1.callAI_Stream)(prompt.messages, model, (chunk) => {
-+            raw += chunk;
-+            onChunk?.(chunk);
-+        });
-+        return {
-+            rawText: raw,
-+            latencyMs: Date.now() - start,
-+        };
-+    }
-+    // Non-streaming mode with optional schema
-+    const config = getUserConfig();
-+    const url = config.aiProxyUrl || validation_1.DEFAULT_AI_PROXY_URL;
-+    const headers = {
-+        'Content-Type': 'application/json',
-+        'X-Client-ID': 'npm_yuangs',
-+        'Origin': 'https://cli.want.biz',
-+        'Referer': 'https://cli.want.biz/',
-+        'account': config.accountType || validation_1.DEFAULT_ACCOUNT_TYPE,
-+        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1',
-+        'Accept': 'application/json'
-+    };
-+    const data = {
-+        model: model || config.defaultModel || validation_1.DEFAULT_MODEL,
-+        messages: prompt.messages,
-+        stream: false
-+    };
-+    try {
-+        const response = await axios_1.default.post(url, data, { headers });
-+        const rawText = response.data.choices[0]?.message?.content || '';
-+        let parsed = undefined;
-+        if (prompt.outputSchema) {
-+            const parseResult = (0, validation_2.safeParseJSON)(rawText, prompt.outputSchema, {});
-+            if (parseResult.success) {
-+                parsed = parseResult.data;
-+            }
-+        }
-+        return {
-+            rawText,
-+            parsed,
-+            latencyMs: Date.now() - start,
-+        };
-+    }
-+    catch (error) {
-+        const errorMsg = error.response?.data?.error?.message || error.response?.data?.message || error.message || 'æœªçŸ¥é”™è¯¯';
-+        throw new Error(`AI è¯·æ±‚å¤±è´¥: ${errorMsg}`);
-+    }
-+}
-+//# sourceMappingURL=llm.js.map
-\ No newline at end of file
-diff --git a/dist/agent/prompt.d.ts b/dist/agent/prompt.d.ts
-new file mode 100644
-index 0000000..141d77f
---- /dev/null
-+++ b/dist/agent/prompt.d.ts
-@@ -0,0 +1,2 @@
-+import { AgentIntent, AgentContext, AgentMode, AgentPrompt } from './types';
-+export declare function buildPrompt(intent: AgentIntent, context: AgentContext, mode: AgentMode, input: string): AgentPrompt;
-diff --git a/dist/agent/prompt.js b/dist/agent/prompt.js
-new file mode 100644
-index 0000000..79628d1
---- /dev/null
-+++ b/dist/agent/prompt.js
-@@ -0,0 +1,49 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.buildPrompt = buildPrompt;
-+const prompt_1 = require("../ai/prompt");
-+const os_1 = require("../core/os");
-+const macros_1 = require("../core/macros");
-+const validation_1 = require("../core/validation");
-+function buildPrompt(intent, context, mode, input) {
-+    if (mode === 'chat') {
-+        return buildChatPrompt(context, input);
-+    }
-+    return buildCommandPromptObject(input, context);
-+}
-+function buildChatPrompt(context, input) {
-+    const messages = [
-+        ...(context.history ?? []),
-+    ];
-+    // Add context files if available
-+    if (context.files && context.files.length > 0) {
-+        const contextDesc = context.files.map(f => `File: ${f.path}\n\`\`\`\n${f.content}\n\`\`\``).join('\n\n');
-+        messages.push({
-+            role: 'system',
-+            content: `Context:\n${contextDesc}`,
-+        });
-+    }
-+    messages.push({
-+        role: 'user',
-+        content: input,
-+    });
-+    return {
-+        system: 'You are a helpful AI assistant with expertise in software development, system administration, and problem-solving.',
-+        messages,
-+    };
-+}
-+function buildCommandPromptObject(input, context) {
-+    const os = (0, os_1.getOSProfile)();
-+    const macros = (0, macros_1.getMacros)();
-+    const promptText = (0, prompt_1.buildCommandPrompt)(input, os, macros);
-+    return {
-+        messages: [
-+            {
-+                role: 'user',
-+                content: promptText,
-+            },
-+        ],
-+        outputSchema: validation_1.aiCommandPlanSchema,
-+    };
-+}
-+//# sourceMappingURL=prompt.js.map
-\ No newline at end of file
-diff --git a/dist/agent/record.d.ts b/dist/agent/record.d.ts
-new file mode 100644
-index 0000000..2eb4bdd
---- /dev/null
-+++ b/dist/agent/record.d.ts
-@@ -0,0 +1,14 @@
-+import { AgentInput, AgentMode, AgentPrompt, LLMResult, AgentAction } from './types';
-+export interface ExecutionRecord {
-+    id: string;
-+    timestamp: number;
-+    mode: AgentMode;
-+    input: AgentInput;
-+    prompt: AgentPrompt;
-+    model: string;
-+    llmResult: LLMResult;
-+    action: AgentAction;
-+}
-+export declare function saveRecord(record: ExecutionRecord): void;
-+export declare function getRecords(): ExecutionRecord[];
-+export declare function getRecordById(id: string): ExecutionRecord | undefined;
-diff --git a/dist/agent/record.js b/dist/agent/record.js
-new file mode 100644
-index 0000000..3377683
---- /dev/null
-+++ b/dist/agent/record.js
-@@ -0,0 +1,20 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.saveRecord = saveRecord;
-+exports.getRecords = getRecords;
-+exports.getRecordById = getRecordById;
-+const records = [];
-+function saveRecord(record) {
-+    records.push(record);
-+    // Keep only last 100 records in memory
-+    if (records.length > 100) {
-+        records.shift();
-+    }
-+}
-+function getRecords() {
-+    return [...records];
-+}
-+function getRecordById(id) {
-+    return records.find(r => r.id === id);
-+}
-+//# sourceMappingURL=record.js.map
-\ No newline at end of file
-diff --git a/dist/agent/replay.d.ts b/dist/agent/replay.d.ts
-new file mode 100644
-index 0000000..6854ae5
---- /dev/null
-+++ b/dist/agent/replay.d.ts
-@@ -0,0 +1,2 @@
-+import { ExecutionRecord } from './record';
-+export declare function replay(record: ExecutionRecord): Promise<import("./types").AgentAction>;
-diff --git a/dist/agent/replay.js b/dist/agent/replay.js
-new file mode 100644
-index 0000000..aeb1755
---- /dev/null
-+++ b/dist/agent/replay.js
-@@ -0,0 +1,25 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.replay = replay;
-+const llm_1 = require("./llm");
-+const interpret_1 = require("./interpret");
-+async function replay(record) {
-+    console.log(`\nReplaying execution: ${record.id}`);
-+    console.log(`Original timestamp: ${new Date(record.timestamp).toISOString()}`);
-+    console.log(`Mode: ${record.mode}\n`);
-+    const result = await (0, llm_1.runLLM)({
-+        prompt: record.prompt,
-+        model: record.model,
-+        stream: record.mode === 'chat',
-+        onChunk: record.mode === 'chat'
-+            ? (s) => process.stdout.write(s)
-+            : undefined,
-+    });
-+    // Create a minimal intent for interpretation
-+    const intent = {
-+        type: record.mode === 'chat' ? 'chat' : 'shell',
-+        capabilities: {},
-+    };
-+    return (0, interpret_1.interpretResult)(result, intent, record.mode);
-+}
-+//# sourceMappingURL=replay.js.map
-\ No newline at end of file
-diff --git a/dist/agent/selectModel.d.ts b/dist/agent/selectModel.d.ts
-new file mode 100644
-index 0000000..c226651
---- /dev/null
-+++ b/dist/agent/selectModel.d.ts
-@@ -0,0 +1,2 @@
-+import { AgentIntent } from './types';
-+export declare function selectModel(intent: AgentIntent, override?: string): string;
-diff --git a/dist/agent/selectModel.js b/dist/agent/selectModel.js
-new file mode 100644
-index 0000000..f18a9b5
---- /dev/null
-+++ b/dist/agent/selectModel.js
-@@ -0,0 +1,19 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+exports.selectModel = selectModel;
-+function selectModel(intent, override) {
-+    if (override)
-+        return override;
-+    const caps = intent.capabilities;
-+    // Long context + reasoning = most powerful model
-+    if (caps.longContext && caps.reasoning) {
-+        return 'gemini-2.0-flash-exp';
-+    }
-+    // Code-focused tasks
-+    if (caps.code) {
-+        return 'gemini-2.5-flash-lite';
-+    }
-+    // Default to balanced model
-+    return 'gemini-2.5-flash-lite';
-+}
-+//# sourceMappingURL=selectModel.js.map
-\ No newline at end of file
-diff --git a/dist/agent/types.d.ts b/dist/agent/types.d.ts
-new file mode 100644
-index 0000000..7f86ae8
---- /dev/null
-+++ b/dist/agent/types.d.ts
-@@ -0,0 +1,57 @@
-+import type { AIRequestMessage } from '../core/validation';
-+export type AgentMode = 'chat' | 'command' | 'command+exec';
-+export interface AgentInput {
-+    rawInput: string;
-+    stdin?: string;
-+    context?: AgentContext;
-+    options?: {
-+        model?: string;
-+        stream?: boolean;
-+        autoYes?: boolean;
-+        verbose?: boolean;
-+    };
-+}
-+export interface AgentContext {
-+    files?: Array<{
-+        path: string;
-+        content: string;
-+    }>;
-+    gitDiff?: string;
-+    history?: AIRequestMessage[];
-+}
-+export interface AgentIntent {
-+    type: 'chat' | 'shell' | 'analysis';
-+    capabilities: {
-+        reasoning?: boolean;
-+        code?: boolean;
-+        longContext?: boolean;
-+        streaming?: boolean;
-+    };
-+}
-+export interface AgentPrompt {
-+    system?: string;
-+    messages: AIRequestMessage[];
-+    outputSchema?: any;
-+}
-+export interface LLMResult {
-+    rawText: string;
-+    parsed?: any;
-+    latencyMs: number;
-+    tokens?: {
-+        prompt: number;
-+        completion: number;
-+        total: number;
-+    };
-+    costUsd?: number;
-+}
-+export type AgentAction = {
-+    type: 'print';
-+    content: string;
-+} | {
-+    type: 'confirm';
-+    next: AgentAction;
-+} | {
-+    type: 'execute';
-+    command: string;
-+    risk: 'low' | 'medium' | 'high';
-+};
-diff --git a/dist/agent/types.js b/dist/agent/types.js
-new file mode 100644
-index 0000000..11e638d
---- /dev/null
-+++ b/dist/agent/types.js
-@@ -0,0 +1,3 @@
-+"use strict";
-+Object.defineProperty(exports, "__esModule", { value: true });
-+//# sourceMappingURL=types.js.map
-\ No newline at end of file
-diff --git a/dist/cli.js b/dist/cli.js
-old mode 100644
-new mode 100755
-diff --git a/package.json b/package.json
-index 56bc142..6f87b01 100644
---- a/package.json
-+++ b/package.json
-@@ -1,6 +1,6 @@
- {
-   "name": "yuangs",
--  "version": "2.0.22",
-+  "version": "2.1.0",
-   "description": "è‹‘å¹¿å±±çš„ä¸ªäººåº”ç”¨é›†åˆ CLIï¼ˆå½©è‰²ç‰ˆï¼‰",
-   "author": "è‹‘å¹¿å±±",
-   "license": "ISC",
-diff --git a/src/agent/AgentPipeline.ts b/src/agent/AgentPipeline.ts
-new file mode 100644
-index 0000000..2b63597
---- /dev/null
-+++ b/src/agent/AgentPipeline.ts
-@@ -0,0 +1,73 @@
-+import {
-+    AgentInput,
-+    AgentMode,
-+    AgentAction,
-+} from './types';
-+
-+import { inferIntent } from './intent';
-+import { buildContext } from './context';
-+import { buildPrompt } from './prompt';
-+import { selectModel } from './selectModel';
-+import { runLLM } from './llm';
-+import { interpretResult } from './interpret';
-+import { executeAction } from './actions';
-+import { saveRecord } from './record';
-+import { randomUUID } from 'crypto';
-+
-+export class AgentPipeline {
-+    async run(input: AgentInput, mode: AgentMode): Promise<void> {
-+        const id = randomUUID();
-+
-+        // 1. Intent Analysis
-+        const intent = inferIntent(input, mode);
-+
-+        // 2. Context Assembly
-+        const context = buildContext(input);
-+
-+        // 3. Prompt Construction
-+        const prompt = buildPrompt(intent, context, mode, input.rawInput);
-+
-+        // 4. Model Selection
-+        const model = selectModel(intent, input.options?.model);
-+
-+        // 5. LLM Execution
-+        const result = await runLLM({
-+            prompt,
-+            model,
-+            stream: mode === 'chat',
-+            onChunk: mode === 'chat'
-+                ? (s) => process.stdout.write(s)
-+                : undefined,
-+        });
-+
-+        // 6. Result Interpretation
-+        const action: AgentAction = interpretResult(result, intent, mode);
-+
-+        // 7. Save Execution Record (before execution for safety)
-+        saveRecord({
-+            id,
-+            timestamp: Date.now(),
-+            mode,
-+            input,
-+            prompt,
-+            model,
-+            llmResult: result,
-+            action,
-+        });
-+
-+        // 8. Action Execution
-+        await executeAction(action, input.options);
-+
-+        // Log execution metrics if verbose
-+        if (input.options?.verbose) {
-+            console.log(`\n${'-'.repeat(50)}`);
-+            console.log(`Execution ID: ${id}`);
-+            console.log(`Model: ${model}`);
-+            console.log(`Latency: ${result.latencyMs}ms`);
-+            if (result.tokens) {
-+                console.log(`Tokens: ${result.tokens.total}`);
-+            }
-+            console.log(`${'-'.repeat(50)}\n`);
-+        }
-+    }
-+}
-diff --git a/src/agent/actions.ts b/src/agent/actions.ts
-new file mode 100644
-index 0000000..dff07f8
---- /dev/null
-+++ b/src/agent/actions.ts
-@@ -0,0 +1,51 @@
-+import { AgentAction } from './types';
-+import { exec } from 'child_process';
-+import { promisify } from 'util';
-+import chalk from 'chalk';
-+import readline from 'readline';
-+
-+const execAsync = promisify(exec);
-+
-+export async function executeAction(
-+    action: AgentAction,
-+    options?: { autoYes?: boolean }
-+): Promise<void> {
-+    if (action.type === 'print') {
-+        console.log(action.content);
-+        return;
-+    }
-+
-+    if (action.type === 'confirm') {
-+        const ok = options?.autoYes || await confirm('Execute this action?');
-+        if (ok) {
-+            await executeAction(action.next, options);
-+        }
-+        return;
-+    }
-+
-+    if (action.type === 'execute') {
-+        try {
-+            console.log(chalk.cyan(`\nExecuting: ${action.command}\n`));
-+            const { stdout, stderr } = await execAsync(action.command);
-+            if (stdout) console.log(stdout);
-+            if (stderr) console.error(chalk.yellow(stderr));
-+        } catch (error: any) {
-+            console.error(chalk.red(`Execution failed: ${error.message}`));
-+            throw error;
-+        }
-+    }
-+}
-+
-+async function confirm(message: string): Promise<boolean> {
-+    const rl = readline.createInterface({
-+        input: process.stdin,
-+        output: process.stdout,
-+    });
-+
-+    return new Promise((resolve) => {
-+        rl.question(chalk.cyan(`${message} (y/N): `), (answer) => {
-+            rl.close();
-+            resolve(answer.toLowerCase() === 'y' || answer.toLowerCase() === 'yes');
-+        });
-+    });
-+}
-diff --git a/src/agent/context.ts b/src/agent/context.ts
-new file mode 100644
-index 0000000..2a148fe
---- /dev/null
-+++ b/src/agent/context.ts
-@@ -0,0 +1,22 @@
-+import { AgentInput, AgentContext } from './types';
-+import { ContextBuffer } from '../commands/contextBuffer';
-+
-+// Create a singleton instance for the agent
-+const globalContextBuffer = new ContextBuffer();
-+
-+export function buildContext(input: AgentInput): AgentContext {
-+    const items = globalContextBuffer.export();
-+
-+    return {
-+        files: items.map(item => ({
-+            path: item.path,
-+            content: item.content,
-+        })),
-+        gitDiff: undefined, // Will be enhanced later
-+        history: [], // Will be populated from conversation history
-+    };
-+}
-+
-+export function getAgentContextBuffer(): ContextBuffer {
-+    return globalContextBuffer;
-+}
-diff --git a/src/agent/index.ts b/src/agent/index.ts
-new file mode 100644
-index 0000000..d186c12
---- /dev/null
-+++ b/src/agent/index.ts
-@@ -0,0 +1,2 @@
-+export { AgentPipeline } from './AgentPipeline';
-+export * from './types';
-diff --git a/src/agent/intent.ts b/src/agent/intent.ts
-new file mode 100644
-index 0000000..12a31c9
---- /dev/null
-+++ b/src/agent/intent.ts
-@@ -0,0 +1,31 @@
-+import { AgentInput, AgentIntent, AgentMode } from './types';
-+import { inferCapabilityRequirement } from '../core/capabilityInference';
-+import { AtomicCapability } from '../core/capabilities';
-+
-+export function inferIntent(
-+    input: AgentInput,
-+    mode: AgentMode
-+): AgentIntent {
-+    if (mode === 'chat') {
-+        return {
-+            type: 'chat',
-+            capabilities: {
-+                reasoning: true,
-+                streaming: true,
-+                longContext: true,
-+            },
-+        };
-+    }
-+
-+    // For command mode, use the existing capability inference
-+    const capReq = inferCapabilityRequirement(input.rawInput);
-+
-+    return {
-+        type: 'shell',
-+        capabilities: {
-+            reasoning: capReq.required.includes(AtomicCapability.REASONING),
-+            code: capReq.required.includes(AtomicCapability.CODE_GENERATION),
-+            longContext: capReq.required.includes(AtomicCapability.LONG_CONTEXT),
-+        },
-+    };
-+}
-diff --git a/src/agent/interpret.ts b/src/agent/interpret.ts
-new file mode 100644
-index 0000000..f29f95a
---- /dev/null
-+++ b/src/agent/interpret.ts
-@@ -0,0 +1,25 @@
-+import { AgentIntent, AgentMode, LLMResult, AgentAction } from './types';
-+
-+export function interpretResult(
-+    result: LLMResult,
-+    intent: AgentIntent,
-+    mode: AgentMode
-+): AgentAction {
-+    if (mode === 'chat') {
-+        return { type: 'print', content: result.rawText };
-+    }
-+
-+    const plan = result.parsed;
-+    if (!plan || !plan.command) {
-+        throw new Error('Invalid command plan from LLM');
-+    }
-+
-+    return {
-+        type: 'confirm',
-+        next: {
-+            type: 'execute',
-+            command: plan.command,
-+            risk: plan.risk ?? 'medium',
-+        },
-+    };
-+}
-diff --git a/src/agent/llm.ts b/src/agent/llm.ts
-new file mode 100644
-index 0000000..10f736c
---- /dev/null
-+++ b/src/agent/llm.ts
-@@ -0,0 +1,88 @@
-+import { AgentPrompt, LLMResult } from './types';
-+import { callAI_Stream } from '../ai/client';
-+import axios from 'axios';
-+import { DEFAULT_AI_PROXY_URL, DEFAULT_MODEL, DEFAULT_ACCOUNT_TYPE, type AIRequestMessage } from '../core/validation';
-+import fs from 'fs';
-+import path from 'path';
-+import os from 'os';
-+import { safeParseJSON } from '../core/validation';
-+
-+const CONFIG_FILE = path.join(os.homedir(), '.yuangs.json');
-+
-+function getUserConfig(): any {
-+    if (fs.existsSync(CONFIG_FILE)) {
-+        try {
-+            const content = fs.readFileSync(CONFIG_FILE, 'utf8');
-+            return JSON.parse(content);
-+        } catch (e) { }
-+    }
-+    return {};
-+}
-+
-+export async function runLLM({
-+    prompt,
-+    model,
-+    stream,
-+    onChunk,
-+}: {
-+    prompt: AgentPrompt;
-+    model: string;
-+    stream: boolean;
-+    onChunk?: (s: string) => void;
-+}): Promise<LLMResult> {
-+    const start = Date.now();
-+
-+    if (stream) {
-+        let raw = '';
-+        await callAI_Stream(prompt.messages, model, (chunk) => {
-+            raw += chunk;
-+            onChunk?.(chunk);
-+        });
-+        return {
-+            rawText: raw,
-+            latencyMs: Date.now() - start,
-+        };
-+    }
-+
-+    // Non-streaming mode with optional schema
-+    const config = getUserConfig();
-+    const url = config.aiProxyUrl || DEFAULT_AI_PROXY_URL;
-+
-+    const headers = {
-+        'Content-Type': 'application/json',
-+        'X-Client-ID': 'npm_yuangs',
-+        'Origin': 'https://cli.want.biz',
-+        'Referer': 'https://cli.want.biz/',
-+        'account': config.accountType || DEFAULT_ACCOUNT_TYPE,
-+        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1',
-+        'Accept': 'application/json'
-+    };
-+
-+    const data = {
-+        model: model || config.defaultModel || DEFAULT_MODEL,
-+        messages: prompt.messages,
-+        stream: false
-+    };
-+
-+    try {
-+        const response = await axios.post(url, data, { headers });
-+        const rawText = response.data.choices[0]?.message?.content || '';
-+
-+        let parsed = undefined;
-+        if (prompt.outputSchema) {
-+            const parseResult = safeParseJSON(rawText, prompt.outputSchema, {});
-+            if (parseResult.success) {
-+                parsed = parseResult.data;
-+            }
-+        }
-+
-+        return {
-+            rawText,
-+            parsed,
-+            latencyMs: Date.now() - start,
-+        };
-+    } catch (error: any) {
-+        const errorMsg = error.response?.data?.error?.message || error.response?.data?.message || error.message || 'æœªçŸ¥é”™è¯¯';
-+        throw new Error(`AI è¯·æ±‚å¤±è´¥: ${errorMsg}`);
-+    }
-+}
-diff --git a/src/agent/prompt.ts b/src/agent/prompt.ts
-new file mode 100644
-index 0000000..0de87b3
---- /dev/null
-+++ b/src/agent/prompt.ts
-@@ -0,0 +1,73 @@
-+import {
-+    AgentIntent,
-+    AgentContext,
-+    AgentMode,
-+    AgentPrompt,
-+} from './types';
-+import { buildCommandPrompt as buildCommandPromptString } from '../ai/prompt';
-+import { getOSProfile } from '../core/os';
-+import { getMacros } from '../core/macros';
-+import { aiCommandPlanSchema } from '../core/validation';
-+
-+export function buildPrompt(
-+    intent: AgentIntent,
-+    context: AgentContext,
-+    mode: AgentMode,
-+    input: string
-+): AgentPrompt {
-+    if (mode === 'chat') {
-+        return buildChatPrompt(context, input);
-+    }
-+
-+    return buildCommandPromptObject(input, context);
-+}
-+
-+function buildChatPrompt(
-+    context: AgentContext,
-+    input: string
-+): AgentPrompt {
-+    const messages: any[] = [
-+        ...(context.history ?? []),
-+    ];
-+
-+    // Add context files if available
-+    if (context.files && context.files.length > 0) {
-+        const contextDesc = context.files.map(f =>
-+            `File: ${f.path}\n\`\`\`\n${f.content}\n\`\`\``
-+        ).join('\n\n');
-+
-+        messages.push({
-+            role: 'system',
-+            content: `Context:\n${contextDesc}`,
-+        });
-+    }
-+
-+    messages.push({
-+        role: 'user',
-+        content: input,
-+    });
-+
-+    return {
-+        system: 'You are a helpful AI assistant with expertise in software development, system administration, and problem-solving.',
-+        messages,
-+    };
-+}
-+
-+function buildCommandPromptObject(
-+    input: string,
-+    context: AgentContext
-+): AgentPrompt {
-+    const os = getOSProfile();
-+    const macros = getMacros();
-+    const promptText = buildCommandPromptString(input, os, macros);
-+
-+    return {
-+        messages: [
-+            {
-+                role: 'user',
-+                content: promptText,
-+            },
-+        ],
-+        outputSchema: aiCommandPlanSchema,
-+    };
-+}
-diff --git a/src/agent/record.ts b/src/agent/record.ts
-new file mode 100644
-index 0000000..78cf4a1
---- /dev/null
-+++ b/src/agent/record.ts
-@@ -0,0 +1,36 @@
-+import {
-+    AgentInput,
-+    AgentMode,
-+    AgentPrompt,
-+    LLMResult,
-+    AgentAction,
-+} from './types';
-+
-+export interface ExecutionRecord {
-+    id: string;
-+    timestamp: number;
-+    mode: AgentMode;
-+    input: AgentInput;
-+    prompt: AgentPrompt;
-+    model: string;
-+    llmResult: LLMResult;
-+    action: AgentAction;
-+}
-+
-+const records: ExecutionRecord[] = [];
-+
-+export function saveRecord(record: ExecutionRecord) {
-+    records.push(record);
-+    // Keep only last 100 records in memory
-+    if (records.length > 100) {
-+        records.shift();
-+    }
-+}
-+
-+export function getRecords(): ExecutionRecord[] {
-+    return [...records];
-+}
-+
-+export function getRecordById(id: string): ExecutionRecord | undefined {
-+    return records.find(r => r.id === id);
-+}
-diff --git a/src/agent/replay.ts b/src/agent/replay.ts
-new file mode 100644
-index 0000000..a1eb788
---- /dev/null
-+++ b/src/agent/replay.ts
-@@ -0,0 +1,27 @@
-+import { ExecutionRecord } from './record';
-+import { runLLM } from './llm';
-+import { interpretResult } from './interpret';
-+import { AgentIntent } from './types';
-+
-+export async function replay(record: ExecutionRecord) {
-+    console.log(`\nReplaying execution: ${record.id}`);
-+    console.log(`Original timestamp: ${new Date(record.timestamp).toISOString()}`);
-+    console.log(`Mode: ${record.mode}\n`);
-+
-+    const result = await runLLM({
-+        prompt: record.prompt,
-+        model: record.model,
-+        stream: record.mode === 'chat',
-+        onChunk: record.mode === 'chat'
-+            ? (s) => process.stdout.write(s)
-+            : undefined,
-+    });
-+
-+    // Create a minimal intent for interpretation
-+    const intent: AgentIntent = {
-+        type: record.mode === 'chat' ? 'chat' : 'shell',
-+        capabilities: {},
-+    };
-+
-+    return interpretResult(result, intent, record.mode);
-+}
-diff --git a/src/agent/selectModel.ts b/src/agent/selectModel.ts
-new file mode 100644
-index 0000000..0818dde
---- /dev/null
-+++ b/src/agent/selectModel.ts
-@@ -0,0 +1,23 @@
-+import { AgentIntent } from './types';
-+
-+export function selectModel(
-+    intent: AgentIntent,
-+    override?: string
-+): string {
-+    if (override) return override;
-+
-+    const caps = intent.capabilities;
-+
-+    // Long context + reasoning = most powerful model
-+    if (caps.longContext && caps.reasoning) {
-+        return 'gemini-2.0-flash-exp';
-+    }
-+
-+    // Code-focused tasks
-+    if (caps.code) {
-+        return 'gemini-2.5-flash-lite';
-+    }
-+
-+    // Default to balanced model
-+    return 'gemini-2.5-flash-lite';
-+}
-diff --git a/src/agent/types.ts b/src/agent/types.ts
-new file mode 100644
-index 0000000..3f5eb5d
---- /dev/null
-+++ b/src/agent/types.ts
-@@ -0,0 +1,54 @@
-+import type { AIRequestMessage } from '../core/validation';
-+
-+export type AgentMode = 'chat' | 'command' | 'command+exec';
-+
-+export interface AgentInput {
-+    rawInput: string;
-+    stdin?: string;
-+    context?: AgentContext;
-+    options?: {
-+        model?: string;
-+        stream?: boolean;
-+        autoYes?: boolean;
-+        verbose?: boolean;
-+    };
-+}
-+
-+export interface AgentContext {
-+    files?: Array<{ path: string; content: string }>;
-+    gitDiff?: string;
-+    history?: AIRequestMessage[];
-+}
-+
-+export interface AgentIntent {
-+    type: 'chat' | 'shell' | 'analysis';
-+    capabilities: {
-+        reasoning?: boolean;
-+        code?: boolean;
-+        longContext?: boolean;
-+        streaming?: boolean;
-+    };
-+}
-+
-+export interface AgentPrompt {
-+    system?: string;
-+    messages: AIRequestMessage[];
-+    outputSchema?: any;
-+}
-+
-+export interface LLMResult {
-+    rawText: string;
-+    parsed?: any;
-+    latencyMs: number;
-+    tokens?: {
-+        prompt: number;
-+        completion: number;
-+        total: number;
-+    };
-+    costUsd?: number;
-+}
-+
-+export type AgentAction =
-+    | { type: 'print'; content: string }
-+    | { type: 'confirm'; next: AgentAction }
-+    | { type: 'execute'; command: string; risk: 'low' | 'medium' | 'high' };
-diff --git a/test_agent_pipeline.js b/test_agent_pipeline.js
-new file mode 100644
-index 0000000..80f8130
---- /dev/null
-+++ b/test_agent_pipeline.js
-@@ -0,0 +1,98 @@
-+#!/usr/bin/env node
-+
-+/**
-+ * Agent Pipeline æµ‹è¯•è„šæœ¬
-+ * 
-+ * ç”¨æ³•ï¼š
-+ *   node test_agent_pipeline.js
-+ */
-+
-+const { AgentPipeline } = require('./dist/agent');
-+
-+async function testChatMode() {
-+    console.log('\n=== æµ‹è¯• Chat æ¨¡å¼ ===\n');
-+
-+    const agent = new AgentPipeline();
-+
-+    try {
-+        await agent.run(
-+            {
-+                rawInput: "ç®€å•è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯å†’æ³¡æ’åº",
-+                options: {
-+                    verbose: true
-+                }
-+            },
-+            'chat'
-+        );
-+
-+        console.log('\nâœ… Chat æ¨¡å¼æµ‹è¯•é€šè¿‡\n');
-+    } catch (error) {
-+        console.error('\nâŒ Chat æ¨¡å¼æµ‹è¯•å¤±è´¥:', error.message);
-+    }
-+}
-+
-+async function testCommandMode() {
-+    console.log('\n=== æµ‹è¯• Command æ¨¡å¼ ===\n');
-+
-+    const agent = new AgentPipeline();
-+
-+    try {
-+        await agent.run(
-+            {
-+                rawInput: "åˆ—å‡ºå½“å‰ç›®å½•çš„æ‰€æœ‰ TypeScript æ–‡ä»¶",
-+                options: {
-+                    verbose: true,
-+                    autoYes: false  // ä¸è‡ªåŠ¨æ‰§è¡Œï¼Œåªç”Ÿæˆå‘½ä»¤
-+                }
-+            },
-+            'command'
-+        );
-+
-+        console.log('\nâœ… Command æ¨¡å¼æµ‹è¯•é€šè¿‡\n');
-+    } catch (error) {
-+        console.error('\nâŒ Command æ¨¡å¼æµ‹è¯•å¤±è´¥:', error.message);
-+    }
-+}
-+
-+async function testExecutionRecord() {
-+    console.log('\n=== æµ‹è¯•æ‰§è¡Œè®°å½• ===\n');
-+
-+    const { getRecords } = require('./dist/agent/record');
-+
-+    const records = getRecords();
-+    console.log(`å½“å‰å…±æœ‰ ${records.length} æ¡æ‰§è¡Œè®°å½•`);
-+
-+    if (records.length > 0) {
-+        const latest = records[records.length - 1];
-+        console.log('\næœ€æ–°è®°å½•:');
-+        console.log(`  ID: ${latest.id}`);
-+        console.log(`  æ¨¡å¼: ${latest.mode}`);
-+        console.log(`  æ—¶é—´: ${new Date(latest.timestamp).toLocaleString()}`);
-+        console.log(`  æ¨¡å‹: ${latest.model}`);
-+        console.log(`  å»¶è¿Ÿ: ${latest.llmResult.latencyMs}ms`);
-+    }
-+
-+    console.log('\nâœ… æ‰§è¡Œè®°å½•æµ‹è¯•é€šè¿‡\n');
-+}
-+
-+async function main() {
-+    console.log('ğŸš€ å¼€å§‹æµ‹è¯• Agent Pipeline\n');
-+
-+    // æ³¨æ„ï¼šè¿™äº›æµ‹è¯•éœ€è¦æœ‰æ•ˆçš„ AI API é…ç½®
-+    // å¦‚æœæ²¡æœ‰é…ç½®ï¼Œæµ‹è¯•ä¼šå¤±è´¥
-+
-+    try {
-+        await testChatMode();
-+        // await testCommandMode();  // å–æ¶ˆæ³¨é‡Šä»¥æµ‹è¯•å‘½ä»¤æ¨¡å¼
-+        await testExecutionRecord();
-+
-+        console.log('\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼\n');
-+    } catch (error) {
-+        console.error('\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯:', error);
-+        process.exit(1);
-+    }
-+}
-+
-+if (require.main === module) {
-+    main();
-+}
diff --git a/poeapi_go.code-workspace b/poeapi_go.code-workspace
index 4235c93..08f164b 100644
--- a/poeapi_go.code-workspace
+++ b/poeapi_go.code-workspace
@@ -3,10 +3,6 @@
 		{
 			"name": "npm_yuangs",
 			"path": "."
-		},
-		{
-			"name": "poeapi_go",
-			"path": "../poeapi_go"
 		}
 	],
 	"settings": {}
diff --git a/src/agent/AgentPipeline.ts b/src/agent/AgentPipeline.ts
index 2b63597..572457e 100644
--- a/src/agent/AgentPipeline.ts
+++ b/src/agent/AgentPipeline.ts
@@ -1,7 +1,6 @@
 import {
     AgentInput,
     AgentMode,
-    AgentAction,
 } from './types';
 
 import { inferIntent } from './intent';
@@ -9,9 +8,10 @@ import { buildContext } from './context';
 import { buildPrompt } from './prompt';
 import { selectModel } from './selectModel';
 import { runLLM } from './llm';
-import { interpretResult } from './interpret';
-import { executeAction } from './actions';
+import { interpretResultToPlan } from './interpret';
+import { executePlan } from './planExecutor';
 import { saveRecord } from './record';
+import { learnSkillFromRecord } from './skills';
 import { randomUUID } from 'crypto';
 
 export class AgentPipeline {
@@ -40,8 +40,9 @@ export class AgentPipeline {
                 : undefined,
         });
 
-        // 6. Result Interpretation
-        const action: AgentAction = interpretResult(result, intent, mode);
+        // 6. Result Interpretation -> Plan
+        const plan = interpretResultToPlan(result, intent, mode);
+        result.plan = plan; // Attach plan to result for recording
 
         // 7. Save Execution Record (before execution for safety)
         saveRecord({
@@ -52,11 +53,32 @@ export class AgentPipeline {
             prompt,
             model,
             llmResult: result,
-            action,
+            action: plan.tasks[0]?.type === 'shell' ? {
+                type: 'execute',
+                command: plan.tasks[0].payload.command,
+                risk: plan.tasks[0].payload.risk
+            } : { type: 'print', content: result.rawText }, // For backward compatibility with record.action
         });
 
-        // 8. Action Execution
-        await executeAction(action, input.options);
+        // 8. Plan Execution
+        await executePlan(plan, input.options);
+
+        // 9. Post-execution: Learn Skill if successful
+        // Note: In an MVP, we assume it's successful if executePlan finishes without error
+        learnSkillFromRecord({
+            id,
+            timestamp: Date.now(),
+            mode,
+            input,
+            prompt,
+            model,
+            llmResult: result,
+            action: plan.tasks[0]?.type === 'shell' ? {
+                type: 'execute',
+                command: plan.tasks[0].payload.command,
+                risk: plan.tasks[0].payload.risk
+            } : { type: 'print', content: result.rawText },
+        });
 
         // Log execution metrics if verbose
         if (input.options?.verbose) {
diff --git a/src/agent/interpret.ts b/src/agent/interpret.ts
index f29f95a..7e22929 100644
--- a/src/agent/interpret.ts
+++ b/src/agent/interpret.ts
@@ -1,25 +1,44 @@
-import { AgentIntent, AgentMode, LLMResult, AgentAction } from './types';
+import { AgentIntent, AgentMode, LLMResult } from './types';
+import { AgentPlan } from './plan';
 
-export function interpretResult(
+export function interpretResultToPlan(
     result: LLMResult,
     intent: AgentIntent,
     mode: AgentMode
-): AgentAction {
+): AgentPlan {
     if (mode === 'chat') {
-        return { type: 'print', content: result.rawText };
+        return {
+            goal: 'å›ç­”ç”¨æˆ·å’¨è¯¢',
+            tasks: [{
+                id: 'chat-response',
+                description: 'è¾“å‡º AI å›ç­”',
+                type: 'custom',
+                status: 'pending',
+                payload: { kind: 'print', text: result.rawText }
+            }]
+        };
     }
 
-    const plan = result.parsed;
-    if (!plan || !plan.command) {
-        throw new Error('Invalid command plan from LLM');
+    const aiPlan = result.parsed;
+    if (!aiPlan || (!aiPlan.command && !aiPlan.macro)) {
+        throw new Error('AI æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„æ‰§è¡Œè®¡åˆ’');
     }
 
+    const command = aiPlan.command || aiPlan.macro; // æš‚æ—¶ç®€åŒ–å¤„ç†
+
     return {
-        type: 'confirm',
-        next: {
-            type: 'execute',
-            command: plan.command,
-            risk: plan.risk ?? 'medium',
-        },
+        goal: aiPlan.plan || 'æ‰§è¡Œ Shell å‘½ä»¤',
+        tasks: [
+            {
+                id: 'exec-shell',
+                description: `æ‰§è¡Œå‘½ä»¤: ${command}`,
+                type: 'shell',
+                status: 'pending',
+                payload: {
+                    command: command,
+                    risk: aiPlan.risk ?? 'medium'
+                }
+            }
+        ]
     };
 }
diff --git a/src/agent/plan.ts b/src/agent/plan.ts
new file mode 100644
index 0000000..a68fafd
--- /dev/null
+++ b/src/agent/plan.ts
@@ -0,0 +1,14 @@
+export interface AgentPlan {
+    goal: string;
+    tasks: AgentTask[];
+}
+
+export interface AgentTask {
+    id: string;
+    description: string;
+    type: 'llm' | 'shell' | 'custom';
+    dependsOn?: string[];
+    payload?: any;
+    status: 'pending' | 'running' | 'success' | 'failed';
+    result?: any;
+}
diff --git a/src/agent/planExecutor.ts b/src/agent/planExecutor.ts
new file mode 100644
index 0000000..bd4e9b2
--- /dev/null
+++ b/src/agent/planExecutor.ts
@@ -0,0 +1,78 @@
+import { AgentPlan, AgentTask } from './plan';
+import { executeAction } from './actions';
+import chalk from 'chalk';
+
+export async function executePlan(
+    plan: AgentPlan,
+    options?: { autoYes?: boolean; verbose?: boolean }
+): Promise<void> {
+    const completed = new Set<string>();
+    const failed = new Set<string>();
+
+    if (options?.verbose) {
+        console.log(chalk.bold.cyan(`\nğŸš€ å¼€å§‹æ‰§è¡Œè®¡åˆ’: ${plan.goal}`));
+        console.log(chalk.gray(`å…± ${plan.tasks.length} ä¸ªä»»åŠ¡\n`));
+    }
+
+    for (const task of plan.tasks) {
+        // æ£€æŸ¥ä¾èµ–
+        if (task.dependsOn?.some(depId => !completed.has(depId))) {
+            if (options?.verbose) {
+                console.log(chalk.yellow(`â­ï¸ è·³è¿‡ä»»åŠ¡ ${task.id}: ä¾èµ–æœªå®Œæˆ`));
+            }
+            continue;
+        }
+
+        if (failed.has(task.id)) continue;
+
+        try {
+            task.status = 'running';
+            if (options?.verbose) {
+                console.log(chalk.cyan(`âš™ï¸ æ‰§è¡Œä»»åŠ¡ ${task.id}: ${task.description}`));
+            }
+
+            await executeTask(task, options);
+
+            task.status = 'success';
+            completed.add(task.id);
+        } catch (error: any) {
+            task.status = 'failed';
+            failed.add(task.id);
+            console.error(chalk.red(`âŒ ä»»åŠ¡ ${task.id} å¤±è´¥: ${error.message}`));
+            // å¦‚æœä¸€ä¸ªä»»åŠ¡å¤±è´¥ï¼Œåç»­ä¾èµ–å®ƒçš„ä»»åŠ¡éƒ½ä¼šè¢«è·³è¿‡
+        }
+    }
+
+    if (options?.verbose) {
+        console.log(chalk.bold.green(`\nâœ… è®¡åˆ’æ‰§è¡Œå®Œæˆ (${completed.size}/${plan.tasks.length} æˆåŠŸ)\n`));
+    }
+}
+
+async function executeTask(
+    task: AgentTask,
+    options?: { autoYes?: boolean }
+): Promise<void> {
+    switch (task.type) {
+        case 'shell':
+            await executeAction({
+                type: 'confirm',
+                next: {
+                    type: 'execute',
+                    command: task.payload.command,
+                    risk: task.payload.risk || 'medium'
+                }
+            }, options);
+            break;
+
+        case 'custom':
+            if (task.payload?.kind === 'print' && task.payload?.text) {
+                console.log(task.payload.text);
+            }
+            break;
+
+        case 'llm':
+            // æœªæ¥å¯ä»¥æ”¯æŒä»»åŠ¡ä¸­å†æ¬¡è°ƒç”¨ LLM (Recursive Agent)
+            console.log(chalk.gray(`[LLM Task] ${task.description} (Not implemented in MVP)`));
+            break;
+    }
+}
diff --git a/src/agent/prompt.ts b/src/agent/prompt.ts
index 0de87b3..69d6373 100644
--- a/src/agent/prompt.ts
+++ b/src/agent/prompt.ts
@@ -8,6 +8,7 @@ import { buildCommandPrompt as buildCommandPromptString } from '../ai/prompt';
 import { getOSProfile } from '../core/os';
 import { getMacros } from '../core/macros';
 import { aiCommandPlanSchema } from '../core/validation';
+import { getRelevantSkills } from './skills';
 
 export function buildPrompt(
     intent: AgentIntent,
@@ -59,7 +60,13 @@ function buildCommandPromptObject(
 ): AgentPrompt {
     const os = getOSProfile();
     const macros = getMacros();
-    const promptText = buildCommandPromptString(input, os, macros);
+    const skills = getRelevantSkills(input);
+    let promptText = buildCommandPromptString(input, os, macros);
+
+    if (skills.length > 0) {
+        const skillList = skills.map(s => `- ${s.name}: å½“é‡åˆ° "${s.whenToUse}" æ—¶ï¼Œä½ å¯ä»¥å‚è€ƒè®¡åˆ’: ${s.planTemplate.goal}`).join('\n');
+        promptText = `ã€å‚è€ƒæŠ€èƒ½åº“ã€‘\n${skillList}\n\n${promptText}`;
+    }
 
     return {
         messages: [
diff --git a/src/agent/skills.ts b/src/agent/skills.ts
new file mode 100644
index 0000000..dfe228a
--- /dev/null
+++ b/src/agent/skills.ts
@@ -0,0 +1,61 @@
+import { AgentPlan } from './plan';
+import { ExecutionRecord } from './record';
+
+export interface Skill {
+    id: string;
+    name: string;
+    description: string;
+    whenToUse: string; // è§¦å‘åœºæ™¯æè¿°
+    planTemplate: AgentPlan;
+    successCount: number;
+    lastUsed: number;
+}
+
+const skillLibrary: Skill[] = [];
+
+/**
+ * ä»æˆåŠŸçš„æ‰§è¡Œè®°å½•ä¸­å­¦ä¹ æŠ€èƒ½
+ */
+export function learnSkillFromRecord(record: ExecutionRecord) {
+    // åªæœ‰æˆåŠŸçš„ shell å‘½ä»¤æ‰å€¼å¾—å­¦ä¹ 
+    if (record.mode === 'chat') return;
+    if (!record.llmResult.plan) return;
+
+    // æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç±»ä¼¼çš„æŠ€èƒ½ (ç®€å•åŸºäºåç§°åŒ¹é…)
+    const existingSkill = skillLibrary.find(s => s.name === record.llmResult.plan?.goal);
+
+    if (existingSkill) {
+        existingSkill.successCount++;
+        existingSkill.lastUsed = Date.now();
+        return;
+    }
+
+    // é™åˆ¶æŠ€èƒ½åº“å¤§å°
+    if (skillLibrary.length > 50) {
+        skillLibrary.shift(); // ç§»é™¤æœ€è€çš„ä¸€ä¸ª
+    }
+
+    skillLibrary.push({
+        id: record.id,
+        name: record.llmResult.plan.goal,
+        description: `è‡ªåŠ¨å­¦ä¹ çš„æŠ€èƒ½: ${record.llmResult.plan.goal}`,
+        whenToUse: record.input.rawInput,
+        planTemplate: record.llmResult.plan,
+        successCount: 1,
+        lastUsed: Date.now()
+    });
+}
+
+/**
+ * è·å–ç›¸å…³æŠ€èƒ½ä»¥æ³¨å…¥ Prompt
+ */
+export function getRelevantSkills(input: string): Skill[] {
+    // ç®€å•è¿”å›æœ€è¿‘ä½¿ç”¨çš„ 3 ä¸ªï¼Œæœªæ¥å¯ä»¥ç”¨å‘é‡æ£€ç´¢ (Vector Search)
+    return skillLibrary
+        .sort((a, b) => b.lastUsed - a.lastUsed)
+        .slice(0, 3);
+}
+
+export function getAllSkills(): Skill[] {
+    return [...skillLibrary];
+}
diff --git a/src/agent/types.ts b/src/agent/types.ts
index 3f5eb5d..ef0f303 100644
--- a/src/agent/types.ts
+++ b/src/agent/types.ts
@@ -1,4 +1,5 @@
 import type { AIRequestMessage } from '../core/validation';
+import { AgentPlan } from './plan';
 
 export type AgentMode = 'chat' | 'command' | 'command+exec';
 
@@ -39,6 +40,7 @@ export interface AgentPrompt {
 export interface LLMResult {
     rawText: string;
     parsed?: any;
+    plan?: AgentPlan;
     latencyMs: number;
     tokens?: {
         prompt: number;
