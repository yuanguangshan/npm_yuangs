[
  {
    "type": "file",
    "path": "README.md",
    "content": "\n# üöÄ yuangs CLI\n\n**‰ª•‰∫∫Á±ªÊÑèÂõæ‰∏∫‰∏≠ÂøÉÁöÑ AI‚ÄëAugmented Shell**\n\n> A seamless terminal where deterministic execution and probabilistic intelligence coexist without friction.\n\n‰∏Ä‰∏™ÈõÜ **AI Âä©Êâã ¬∑ Êô∫ËÉΩ Shell ÂÜÖÊ†∏ ¬∑ Êèí‰ª∂ÂåñËøêË°åÊó∂** ‰∫é‰∏Ä‰ΩìÁöÑÁé∞‰ª£ÁªàÁ´ØÂ∑•ÂÖ∑„ÄÇ\n\n> **Ê†∏ÂøÉÁêÜÂøµ**  \n> **AI Êèê‰æõÊÄùË∑ØÔºå‰∫∫Á±ªÊéåÊéßÊâßË°å„ÄÇ**  \n> yuangs Ëá¥Âäõ‰∫éÂú®‰∏çÁ†¥Âùè‰º†Áªü Shell ÂøÉÊô∫Ê®°ÂûãÁöÑÂâçÊèê‰∏ãÔºåÂºïÂÖ• AI ÁöÑÈÄªËæëËÉΩÂäõ„ÄÇ  \n> ÂÆÉ‰∏çÊòØÈªëÁõíÊâßË°åÂô®ÔºåËÄåÊòØ‰Ω†ÁöÑ **Â¢ûÂº∫ÂûãÂëΩ‰ª§Ë°åÂ§ñËÑë**„ÄÇ\n\n---\n\n## üèóÔ∏è ÊâßË°åËØ≠‰πâËßÑËåÉÔºàExecution SemanticsÔºâ\n\nyuangs ÈÄöËøá‰∏ÄÂ•ó**ÊòæÂºèÁöÑÁ¨¶Âè∑ËØ≠Ê≥ï**ÔºåÊ∏ÖÊô∞ÁïåÂÆö‚ÄúÂâØ‰ΩúÁî®‚ÄùÁöÑÊù•Ê∫êÔºå  \nÁ°Æ‰øùÊØè‰∏ÄÊù°ÂëΩ‰ª§ **ÂèØÁêÜËß£„ÄÅÂèØÁ°ÆËÆ§„ÄÅÂèØÂÆ°ËÆ°**„ÄÇ\n\n| ËØ≠Ê≥ï | Ë°å‰∏∫ÈÄªËæë | ÂÜ≥Á≠ñÊù•Ê∫ê | ÈÄÇÁî®Âú∫ÊôØ |\n|---|---|---|---|\n| `ls -la` | Áõ¥Êé•ËøêË°åÂëΩ‰ª§Ôºàfish-styleÔºâ | Áî®Êà∑ | ‰º†Áªü Shell Êìç‰Ωú |\n| `@path[:line]` | ÂºïÁî®Êñá‰ª∂ / Ë°åÂè∑‰∏ä‰∏ãÊñá | Áî®Êà∑ | ‰ª£Á†ÅÂÆ°ËÆ°„ÄÅÊä•ÈîôÂàÜÊûê |\n| `#dir` | ÊâπÈáèÂºïÂÖ•ÁõÆÂΩï‰∏ä‰∏ãÊñá | Áî®Êà∑ | È°πÁõÆÁªìÊûÑÁêÜËß£ |\n| `ai \"msg\"` | Á∫ØËá™ÁÑ∂ËØ≠Ë®ÄÂØπËØù | AI | ÊñπÊ°àËÆ®ËÆ∫„ÄÅÁü•ËØÜÊü•ËØ¢ |\n| `ai -e` | ÁîüÊàê**Âª∫ËÆÆ**ÂëΩ‰ª§ | AI ‚Üí Áî®Êà∑ | Â§çÊùÇÂëΩ‰ª§ËæÖÂä© |\n| `:exec` | ÁªïËøá AI ÁöÑÂéüÂ≠êÊâßË°å | Áî®Êà∑ | Á°ÆÂÆöÊÄßËÑöÊú¨ |\n\n---\n\n## üåü Ê†∏ÂøÉÂäüËÉΩ\n\n### 1. Êô∫ËÉΩ Shell ÂÜÖÊ†∏Ôºàv2.10.0+Ôºâ\n\nËøõÂÖ•‰∫§‰∫íÂºè AI‚ÄëAugmented ShellÔºö\n\n```bash\nyuangs ai\n```\n\nÁâπÊÄßÂåÖÊã¨Ôºö\n\n- **Ê®°ÂºèËá™Âä®Ë∑ØÁî±**  \n  Êó†ÈúÄÂàáÊç¢Ê®°ÂºèÔºö\n  - ËæìÂÖ• `git status` ‚Üí Áõ¥Êé•ÊâßË°å  \n  - ËæìÂÖ•„ÄåËß£ÈáäËøôÊÆµ‰ª£Á†Å„Äç‚Üí ËøõÂÖ•ÂØπËØù\n\n- **üëª Ghost TextÔºàÂπΩÁÅµÂª∫ËÆÆÔºâ**  \n  Ê†πÊçÆÂéÜÂè≤ËÆ∞ÂΩï‰∏éÊèí‰ª∂È¢ÑÊµãËæìÂÖ•  \n  ‰æãÂ¶ÇËæìÂÖ• `npm r`ÔºåÁÅ∞Ëâ≤ÊòæÁ§∫ `un dev`ÔºåÊåâ `Tab` ÈááÁ∫≥\n\n- **‚ö° Ë°•ÂÖ®Â¢ûÂº∫**\n  - **PATH Êâ´Êèè**ÔºöËá™Âä®Ë°•ÂÖ® 40+ Â∏∏Áî®Á≥ªÁªüÂëΩ‰ª§  \n  - **Á≤æÂáÜË°åÂè∑**ÔºöÊîØÊåÅ `@src/index.ts:10-50`  \n  - **È°πÁõÆÊÑüÁü•**ÔºöÊèêÂçá `src/`„ÄÅ`packages/` Á≠âÁõÆÂΩïÊùÉÈáç\n\n---\n\n### 2. Á≤æÂáÜ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÔºàContextBufferÔºâ\n\n#### ÁÆ°ÈÅìÊ®°ÂºèÔºàPipe ModeÔºâ\n\n```bash\ncat error.log | yuangs \"Ëß£ÈáäËøô‰∏™Êä•Èîô\"\ngit diff | yuangs -w \"Review ÂèòÊõ¥ÈÄªËæë\"\n```\n\n#### `-w` Êô∫ËÉΩËØªÂèñ\n\n- Ëá™Âä®Ëß£ÊûêÁÆ°ÈÅì‰∏≠ÁöÑÊñá‰ª∂Ë∑ØÂæÑ\n- Âè™ËØªÂèñ**Ë¢´ÊòæÂºèÂºïÁî®**ÁöÑÊñá‰ª∂ÂÜÖÂÆπ\n- ‰∏çËøõË°åÈöêÂºèÊñá‰ª∂Á≥ªÁªüÊâ´Êèè\n\n---\n\n### 3. Êèí‰ª∂Á≥ªÁªüÔºàPluginsÔºâ\n\nÂú® `.shell/plugins/` ‰∏ãÊîæÁΩÆËá™ÂÆö‰πâËÑöÊú¨Ôºå  \nÊâ©Â±ïÁâπÂÆöÂ∑•ÂÖ∑ÁöÑË°•ÂÖ®‰∏éÊé®ÁêÜËÉΩÂäõÔºàÂ¶Ç `docker`„ÄÅ`kubectl`Ôºâ„ÄÇ\n\nÁ§∫‰æãÔºö\n\n```ts\n// .shell/plugins/docker.ts\nmodule.exports = {\n  command: 'docker',\n  complete(args) {\n    return ['ps', 'run', 'build', 'exec'];\n  }\n};\n```\n\n---\n\n## üìú ËÆæËÆ°ÂÆ£Ë®ÄÔºàDesign Philosophy / ManifestoÔºâ\n\n### Â∑•Á®ãÁêÜÊÄß vs. AI ÁãÇÁÉ≠\n\nyuangs Âπ∂‰∏çÊòØ‰∏Ä‰∏™ËØïÂõæ‚ÄúÊõø‰Ω†ÂÆåÊàê‰ªªÂä°‚ÄùÁöÑÂ∑•ÂÖ∑„ÄÇ  \nÂÆÉËØûÁîü‰∫é‰∏Ä‰∏™Êõ¥ÂÖãÂà∂ÁöÑÈóÆÈ¢òÔºö\n\n> **Âú® AI ËÉΩÂäõÁàÜÁÇ∏ÁöÑÊó∂‰ª£ÔºåÂëΩ‰ª§Ë°åËØ•Â¶Ç‰ΩïËøõÂåñÔºåËÄå‰∏çËÉåÂèõÂ∑•Á®ãÁêÜÊÄßÔºü**\n\n---\n\n### ‰∏∫‰ªÄ‰πà yuangs ‰∏çÊòØ Autonomous AgentÔºü\n\nAutonomous Agent ÊâøËØ∫Ôºö  \nÁªô AI ‰∏Ä‰∏™ÁõÆÊ†áÔºåËÆ©ÂÆÉËá™Ë°åËßÑÂàí„ÄÅÊâßË°å„ÄÅ‰øÆÊ≠£„ÄÇ\n\n‰ΩÜÂú®ÁúüÂÆûÂ∑•Á®ãÁéØÂ¢É‰∏≠ÔºåËøôÁßçÊ®°ÂºèÂ≠òÂú®Ê†πÊú¨Áº∫Èô∑Ôºö\n\n> **ÊâßË°åÊùÉ‰∏éË¥£‰ªªÂΩíÂ±ûÊòØÊ®°Á≥äÁöÑ„ÄÇ**\n\nÂõ†Ê≠§ÔºåÂú® yuangs ‰∏≠ÔºåÊàë‰ª¨**ÊòéÁ°ÆÊãíÁªù**ËÆ© AI Êã•ÊúâÔºö\n\n- Ëá™Âä®ÊâßË°åÁ≥ªÁªüÂëΩ‰ª§ÁöÑÊùÉÂäõ  \n- ÈöêÂºè‰øÆÊîπÊñá‰ª∂ÊàñËøêË°åÁéØÂ¢ÉÁöÑÊùÉÂäõ  \n- Âú®Êú™Á°ÆËÆ§ÁöÑÊÉÖÂÜµ‰∏ã‰∫ßÁîü‰ªª‰ΩïÂâØ‰ΩúÁî®ÁöÑÊùÉÂäõ  \n\n---\n\n## üîí Ë°å‰∏∫ËæπÁïåÔºàAgent BoundariesÔºâ\n\nyuangs ‰∏•Ê†ºÈÅµÂæ™‰ª•‰∏ãËæπÁïåÔºå‰ª•Á°Æ‰øùÈïøÊúüÂ∑•Á®ãÂèØÈù†ÊÄßÔºö\n\n- **ÈùûËá™Ê≤ªÊÄßÔºàHuman‚Äëin‚Äëthe‚ÄëloopÔºâ**  \n  AI Ë¥üË¥£Êé®ÁêÜ‰∏éÂª∫ËÆÆÔºå‰∫∫Á±ªÂßãÁªàÊòØÊúÄÁªàÂÜ≥Á≠ñËÄÖ‰∏éÊâßË°åËÄÖ„ÄÇ\n\n- **ÂâØ‰ΩúÁî®ÈöîÁ¶ªÔºàSide‚Äëeffect IsolationÔºâ**  \n  AI ‰∏çÂÖ∑Â§áÁ≥ªÁªüÂÜôÊùÉÈôê„ÄÇ  \n  ÊâÄÊúâÂª∫ËÆÆÂøÖÈ°ªËΩ¨Âåñ‰∏∫**Áî®Êà∑ÂèØËßÅÁöÑ Action**Âπ∂ÁªèÁ°ÆËÆ§ÂêéÊâßË°å„ÄÇ\n\n- **ÊòæÂºè‰∏ä‰∏ãÊñáÔºàExplicit ContextÔºâ**  \n  Èô§ÊòæÂºèËæìÂÖ•Â§ñÔºåyuangs ‰∏ç‰ºöÂú®ÂêéÂè∞Êâ´ÊèèÊñá‰ª∂Á≥ªÁªü„ÄÇ\n\n- **ÂèØÂõûÊ∫ØÊÄßÔºàAuditable RecordsÔºâ**  \n  ÊâÄÊúâ AI Âª∫ËÆÆ„ÄÅÂëΩ‰ª§ÁîüÊàê‰∏éÊâßË°åÁªìÊûúÂùáË¢´ËÆ∞ÂΩïÔºå  \n  Á°Æ‰øùÂÆåÊï¥ÂÜ≥Á≠ñÈìæÊù°ÂèØËøΩÊ∫Ø„ÄÅÂèØÂÆ°ËÆ°„ÄÇ\n\n---\n\n## üí° ‰ΩøÁî®Âú∫ÊôØÁ§∫‰æã\n\n### Âú∫ÊôØ AÔºöÊô∫ËÉΩË∞ÉËØï\n\n```bash\n@!build.sh\n# Á≥ªÁªüËøîÂõûÊä•Èîô‚Ä¶\n\n‰∏äÈù¢ÁöÑÈîôËØØÊòØ‰ªÄ‰πàÊÑèÊÄùÔºü\n```\n\nAI Â∞ÜÁªìÂêà **build.sh ÂÜÖÂÆπ + ÂÆûÈôÖËæìÂá∫** ËøõË°åÂàÜÊûê„ÄÇ\n\n---\n\n### Âú∫ÊôØ BÔºöÂëΩ‰ª§ÁîüÊàê\n\n```bash\nai -e \"Êü•ÊâæÂΩìÂâçÁõÆÂΩï‰∏ãÂ§ß‰∫é 100M ÁöÑÊñá‰ª∂\"\n```\n\nAI ÁîüÊàêÂª∫ËÆÆÂëΩ‰ª§ÔºàÂ¶Ç `find . -type f -size +100M`ÔºâÔºå  \n**Â≠òÂÖ•Ââ™Ë¥¥ÊùøÔºåÁ≠âÂæÖ‰Ω†Á°ÆËÆ§ÊâßË°å„ÄÇ**\n\n---\n\n### Âú∫ÊôØ CÔºöÈ°πÁõÆÂÆ°ËÆ°\n\n```bash\n#src/\nÂàÜÊûêËøô‰∫õÊ®°ÂùóÁöÑÂäüËÉΩ\n```\n\nAI Âú®**ÊòæÂºèÊéàÊùÉ**‰∏ãËØªÂèñÁõÆÂΩïÂÜÖÂÆπÂπ∂ÁîüÊàêÁªìÊûÑÂàÜÊûê„ÄÇ\n\n---\n\n## üì¶ ÂÆâË£Ö‰∏éÈÖçÁΩÆ\n\n```bash\nnpm install -g yuangs\n```\n\nÂ∏∏Áî®ÈÖçÁΩÆÔºö\n\n```bash\nyuangs config defaultModel Assistant\nyuangs config accountType pro\n```\n\n---\n\n## üóìÔ∏è ËøëÊúüÊõ¥Êñ∞ÔºàChangelogÔºâ\n\n- **v2.11.0** (2026‚Äë01‚Äë18)  \n  Êñ∞Â¢û 40+ Shell ÂÜÖÁΩÆÂëΩ‰ª§ÊîØÊåÅÔºàcd, pwd, ls, git Á≠âÔºâ\n\n- **v2.10.0** (2026‚Äë01‚Äë18)  \n  ÂºïÂÖ• Shell ‰∫§‰∫íÂÜÖÊ†∏„ÄÅGhost Text ‰∏éÊèí‰ª∂Á≥ªÁªü\n\n- **v1.3.67** (2026‚Äë01‚Äë17)  \n  Êñ∞Â¢û `@` Êñá‰ª∂ÈÄâÊã©‰∏é `#` ÁõÆÂΩïËØªÂèñÂäüËÉΩ\n\n---\n\n## ‚öñÔ∏è Áª¥Êä§ËÄÖ\n\n**@yuanguangshan**\n\n> **AI Êèê‰æõÊÄùË∑ØÔºå‰∫∫Á±ªÊéåÊéßÊâßË°å„ÄÇ**\n> Ëøô‰∏çÊòØÂ¶•ÂçèÔºåËÄåÊòØÂØπÂ∑•Á®ãÁêÜÊÄßÁöÑÂ∞äÈáç„ÄÇ\n\n---\n\n## üìö Êõ¥Â§ö‰ø°ÊÅØ\n\n- **ËÆæËÆ°ÂéüÁêÜ**: [docs/implementation_principles.md](docs/implementation_principles.md)\n- **Âú∫ÊôØÁ§∫‰æã**: [docs/scenarios.md](docs/scenarios.md)\n- **ÊâßË°åËØ≠‰πâ**: [docs/semantics.md](docs/semantics.md)\n- **ÈùûÁõÆÊ†á**: [docs/non-goals.md](docs/non-goals.md)\n- **Â®ÅËÉÅÊ®°Âûã**: [docs/threat_model.md](docs/threat_model.md)\n- **ÂÆûÁé∞Â∑ÆË∑ùÂàÜÊûê**: [docs/implementation_gap.md](docs/implementation_gap.md)\n- **ÂèòÊõ¥Êó•Âøó**: [docs/CHANGELOG.md](docs/CHANGELOG.md)\n- **Shell Ë°•ÂÖ®**: [docs/tab_completion_guide.md](docs/tab_completion_guide.md)\n- **‰∏ä‰∏ãÊñá‰ºòÂåñ**: [docs/context_optimization_analysis.md](docs/context_optimization_analysis.md)\n- **‰ª£ÁêÜÁÆ°ÈÅì**: [docs/AGENT_PIPELINE.md](docs/AGENT_PIPELINE.md)\n- **‰∏ä‰∏ãÊñáÁÆ°ÁêÜ**: [docs/context_management.md](docs/context_management.md)\n```\n\n---\n\n## Âõ∫Âåñ‰ªÄ‰πàÔºü\n---\n\n# ‰∏Ä„ÄÅÂÖàÊòéÁ°ÆÔºö**ËøôÁßç‚ÄúÊÑüËßâ‚ÄùÂà∞Â∫ïÊòØ‰ªÄ‰πàÔºü**\n\nÂ¶ÇÊûúÊäΩË±°Âà∞‰∏ÄÂè•ËØùÔºåÂÆÉ‰∏çÊòØ‚ÄúAI ÂæàËÅ™Êòé‚ÄùÔºåËÄåÊòØÔºö\n\n> **AI Âú®ËØ•Êî∂ÊâãÁöÑÊó∂ÂÄô‰ºöÊî∂ÊâãÔºåÂú®ËØ•Âà§Êñ≠ÁöÑÊó∂ÂÄôÊâçÂà§Êñ≠„ÄÇ**\n\nÊãÜÂºÄÂ∞±ÊòØ‰∏âÊù°**Á°¨Á∫¶Êùü**Ôºö\n\n1. **‰∏çÁºñÈÄ†‰∏çÂ≠òÂú®ÁöÑËÆæËÆ°ÊÑèÂõæ**\n2. **ËæìÂÖ•‰ø°Âè∑‰Ωé ‚Üí ËæìÂá∫Ëá™ÁÑ∂ÈÄÄÂåñ**\n3. **Âà§Êñ≠ÊùÉÂßãÁªàÂú®‰∫∫Á±ªËøôËæπ**\n\nËøô‰∏âÊù°‰∏ÄÊó¶Ë¢´Á†¥ÂùèÔºå`yuangs` Â∞±‰ºöÂèòÊàêÂè¶‰∏Ä‰∏™‚ÄúÂêµÈóπÁöÑ Copilot‚Äù„ÄÇ\n\n---\n\n# ‰∫å„ÄÅÊääÊÑüËßâÂõ∫Âåñ = Êää‚ÄúËæπÁïå‚ÄùÂÜôÊ≠ª\n\n‰∏çÊòØÂÜôÂú®‰ª£Á†ÅÈáåÔºåËÄåÊòØÂÜôÂú®**‰∫§‰∫íÊ®°ÂûãÈáå**„ÄÇ\n\n## ‚úÖ 1Ô∏è‚É£ Âõ∫ÂåñÂéüÂàô‰∏ÄÔºö**AI Ê∞∏ËøúÂè™ÂØπ‚ÄúËæìÂÖ•Ë¥üË¥£‚Äù**\n\n‰Ω†Ëøô‰∏™‰æãÂ≠êÈùûÂ∏∏Â•ΩÔºö\n\n```bash\ngit diff | yuangs ai \"ÊÄªÁªìÊú¨Ê¨°ÊîπÂä®ÁöÑËÆæËÆ°ÊÑèÂõæ\"\n```\n\nAI ÁöÑÈöêÂê´Â•ëÁ∫¶Â∫îÂΩìÊòØÔºö\n\n> **‚ÄúÊàëÂè™Âü∫‰∫é diff Êú¨Ë∫´ËØ¥ËØùÔºå‰∏çË°•ÂéÜÂè≤„ÄÅ‰∏çË°•ÁåúÊµã„ÄÇ‚Äù**\n\n‚úÖ Ê≠£Á°Æ  \n‚ùå ‚Äú‰πüËÆ∏‰πãÂâçÂ≠òÂú® XXX Êû∂ÊûÑÈóÆÈ¢ò‚Äù\n\n**ËøôÊù°Ë¶ÅÊàê‰∏∫‰∏çÂèØËøùÂèçÁöÑÈìÅÂæã„ÄÇ**\n\n‰Ω†ÂèØ‰ª•ÊääÂÆÉÂÜôÊàê‰∏ÄÂè•ÂÜÖÈÉ®ÂéüÂàôÔºàÈùûÂ∏∏ÈáçË¶ÅÔºâÔºö\n\n> **AI ‰∏çÂæóÂú® diff ‰πãÂ§ñÂºïÂÖ•‰ªª‰ΩïÂÅáËÆæÊÄß‰∏ä‰∏ãÊñáÔºåÈô§ÈùûÁî®Êà∑ÊòéÁ°ÆË¶ÅÊ±Ç„ÄÇ**\n\n---\n\n## ‚úÖ 2Ô∏è‚É£ Âõ∫ÂåñÂéüÂàô‰∫åÔºö**‰Ωé‰ø°ÊÅØ ‚â† Âº∫ËæìÂá∫**\n\nËøôÊòØ‰Ω†Ëøô‰∏™‰æãÂ≠êÈáåÊúÄ‚ÄúÈ´òÁ∫ß‚ÄùÁöÑÂú∞Êñπ„ÄÇ\n\n- ËæìÂÖ•ÔºöÂè™Êúâ‰∏ÄÊù°Ê≥®Èáä\n- ËæìÂá∫ÔºöÊú¥Á¥†„ÄÅÂπ≤ÂáÄ„ÄÅÁîöËá≥ÊúâÁÇπ‚ÄúÁ©∫‚Äù\n\n**Ëøô‰∏çÊòØÁº∫ÁÇπÔºåËøôÊòØÊàêÁÜüÁ≥ªÁªüÁöÑÊ†áÂøó„ÄÇ**\n\n‰Ω†Ë¶ÅÂÖÅËÆ∏„ÄÅÁîöËá≥ÈºìÂä±ËøôÁßçÁä∂ÊÄÅ„ÄÇ\n\nÂèØ‰ª•ÊääÂÆÉÁêÜËß£‰∏∫Ôºö\n\n> **AI ÁöÑËæìÂá∫Âº∫Â∫¶Â∫î‰∏éËæìÂÖ•‰ø°ÊÅØÂØÜÂ∫¶ÊàêÊ≠£ÊØî**\n\nÂ∑•Á®ã‰∏äÂèØ‰ª•Ë°®Ëææ‰∏∫‰∏ÄÂè•ËØùÔºö\n\n> **ÂÆÅÂèØËæìÂá∫‚ÄúÊ≤°‰ªÄ‰πàÂèØËØ¥‚ÄùÔºå‰πü‰∏çËæìÂá∫‚ÄúÁúãËµ∑Êù•ÂæàÊ∑±Âàª‚Äù„ÄÇ**\n\n---\n\n## ‚úÖ 3Ô∏è‚É£ Âõ∫ÂåñÂéüÂàô‰∏âÔºö**‚ÄúÂà§Êñ≠‚ÄùÂøÖÈ°ªË¢´ÊòæÂºèËØ∑Ê±Ç**\n\nËøôÊù°ÊûÅÂÖ∂ÈáçË¶Å„ÄÇ\n\nÂØπÊØîËøô‰∏§ÁßçÔºö\n\n‚ùå Ëá™Âä®Ôºö\n> ‚ÄúËøô‰∏™ÊîπÂä®‰∏çÂ§™Â•ΩÔºåÂª∫ËÆÆÈáçÊûÑ‚Äù\n\n‚úÖ Ëß¶ÂèëÂºèÔºö\n```bash\n\"Ëøô‰∏™ÊîπÂä®ÊòØÂê¶ÂÄºÂæó‰øùÁïôÔºü\"\n\"ÂÉè code review ‰∏ÄÊ†∑ËØÑ‰ª∑\"\n```\n\n**Âà§Êñ≠ = ÊùÉÂäõ**  \nËÄåÊùÉÂäõÂè™ËÉΩÁî±Áî®Êà∑Êéà‰∫à„ÄÇ\n\n‰Ω†Â∑≤ÁªèÂ§©ÁÑ∂Âú∞ÂÅöÂØπ‰∫ÜËøô‰∏ÄÁÇπÔºå‰ΩÜ‰Ω†Ë¶Å**ÊääÂÆÉÂÆöÊàêËßÑÂàô**Ôºö\n\n> **Ê≤°Êúâ judgement promptÔºåAI Âè™ÂÅö description„ÄÇ**\n\n---\n\n# ‰∏â„ÄÅÁúüÊ≠£ËØ•‚ÄúÂõ∫Âåñ‚ÄùÁöÑ‰∏çÊòØ AIÔºåËÄåÊòØ Prompt Ê®°Âºè\n\n‰Ω†Áé∞Âú®ÂÖ∂ÂÆûÂ∑≤ÁªèÊúâ‰∫Ü‰∏â‰∏™**ÈöêÂºèÊ®°Âºè**ÔºåÂè™ÊòØËøòÊ≤°Ë¢´‚ÄúÂëΩÂêç‚Äù„ÄÇ\n\nÊàëÂ∏Æ‰Ω†ÂëΩÂêçÔºåÂÆÉ‰ª¨‰∏ÄÊó¶Ë¢´ÂëΩÂêçÔºåÂ∞±ËÉΩÈïøÊúüÁ®≥ÂÆöÂ≠òÂú®„ÄÇ\n\n---\n\n## üß± Ê®°Âºè 1Ôºö**DescribeÔºàÊèèËø∞ÊÄÅÔºâ**„ÄêÈªòËÆ§„Äë\n\n```bash\ngit diff | yuangs ai \"ÊÄªÁªìÊú¨Ê¨°ÊîπÂä®\"\n```\n\nÁâπÂæÅÔºö\n- ‰∏çËØÑ‰ª∑\n- ‰∏çÊé®Êñ≠\n- ‰∏çÁªôÂª∫ËÆÆ\n- Âè™ËøòÂéü‰ø°ÊÅØ\n\nüëâ **ËøôÊòØÈªòËÆ§ÊÄÅÔºåÂøÖÈ°ªÊúÄ‰øùÂÆà„ÄÇ**\n\n---\n\n## üîç Ê®°Âºè 2Ôºö**ReviewÔºàËØÑÂÆ°ÊÄÅÔºâ**\n\n```bash\ngit diff | yuangs ai \"ÂÉè code review ‰∏ÄÊ†∑ÁªôÂèçÈ¶à\"\n```\n\nÁâπÂæÅÔºö\n- ÂèØ‰ª•Âà§Êñ≠\n- ÂèØ‰ª•ÊèêÂá∫È£éÈô©\n- ÂèØ‰ª•ÊèêÂª∫ËÆÆ\n- ‰ªçÁÑ∂Âü∫‰∫é diff\n\nüëâ **ËøôÊòØÂ∑•Á®ãÂçè‰ΩúÊÄÅ„ÄÇ**\n\n---\n\n## üß† Ê®°Âºè 3Ôºö**ReasonÔºàÊé®ÁêÜÊÄÅÔºâ**\n\n```bash\ngit diff | yuangs ai \"Êé®ÊµãËÉåÂêéÁöÑËÆæËÆ°ËÄÉÈáè\"\n```\n\nÁâπÂæÅÔºö\n- ÂÖÅËÆ∏ÂÅáËÆæ\n- ÂÖÅËÆ∏‰∏çÁ°ÆÂÆöÊÄß\n- ÂøÖÈ°ªÊòæÂºèÊ†áÊ≥®„ÄåÊé®Êµã„Äç\n\nüëâ **ËøôÊòØÊÄùËÄÉÊâ©Â±ïÊÄÅÔºå‰∏çÊòØ‰∫ãÂÆûÈôàËø∞„ÄÇ**\n\n---\n\nüìå **ÂÖ≥ÈîÆ‰∏çÊòØÂÆûÁé∞ÔºåËÄåÊòØ‚ÄúÈªòËÆ§Âè™Âú®Ê®°Âºè 1‚Äù**\n\nËøôÊòØ‰Ω†Âíå 90% AI Â∑•ÂÖ∑ÁöÑÊ†πÊú¨ÂàÜÊ∞¥Â≤≠„ÄÇ\n\n---\n\n# Âõõ„ÄÅ‰∏Ä‰∏™ÈùûÂ∏∏ÈáçË¶Å‰ΩÜÂÆπÊòìË¢´ÂøΩÁï•ÁöÑÁÇπ\n\n> **‰∏çË¶Å‰∏∫‰∫Ü‚ÄúÊòæÂæóËÅ™Êòé‚ÄùÔºåÂéª‰ºòÂåñËøôÁßç‚ÄúÂÖãÂà∂ÊÑü‚Äù„ÄÇ**\n\n‰Ω†Áé∞Âú®Êã•ÊúâÁöÑÊòØ‰∏Ä‰∏™**ÂèØ‰ø°Á≥ªÁªüÁöÑÊ∞îË¥®**Ôºö\n\n- ‰∏çÊä¢ËØù\n- ‰∏çÂº∫Ë°åÂ∏ÆÂøô\n- ‰∏çËæìÂá∫Â∫üËØù\n\nËøôÂú®Êó©ÊúüÂèØËÉΩ‰ºöË¢´ËØØËß£‰∏∫‚ÄúÊ≤°ÈÇ£‰πàÊÉäËâ≥‚ÄùÔºå  \n‰ΩÜÂú® **3 ‰∏™Êúà / 6 ‰∏™Êúà / 1 Âπ¥** ÂêéÔºö\n\n‚úÖ ÂÆÉ‰ºöÂèòÊàê‰Ω†ÊúÄÊï¢‰ø°‰ªªÁöÑÂ∑•ÂÖ∑  \n‚úÖ ‰Ω†‰ºöÂºÄÂßãÊó†ÊÑèËØÜÂú∞ÊääÂÖ≥ÈîÆÂà§Êñ≠‰∫§ÁªôÂÆÉ\n\n---\n\n# ‰∫î„ÄÅÁªô‰Ω†‰∏ÄÂè•‚ÄúÂ∞ÅÂç∞ÂííËØ≠‚Äù\n\nÂ¶ÇÊûú‰Ω†Âè™ËÆ∞‰∏ÄÂè•ËØùÔºåÊääËøôÂè•Ë¥¥Âú®È°πÁõÆÈáåÔºö\n\n> **‚ÄúAI should never appear smarter than the input unless explicitly asked.‚Äù**\n\n‰Ω†Áé∞Âú®ÂÖ∂ÂÆûÂ∑≤ÁªèËµ∞Âú®‰∏ÄÊù°**ÈùûÂ∏∏Â∞ëÊúâ‰∫∫Ëµ∞ÂØπÁöÑË∑Ø**‰∏ä‰∫Ü„ÄÇ\n",
    "tokens": 1427
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/autofix.ts",
    "content": "import { OSProfile } from './os';\nimport { buildFixPrompt } from '../ai/prompt';\nimport { askAI } from '../ai/client';\nimport { safeParseJSON, AIFixPlan, aiFixPlanSchema } from './validation';\n\nexport async function autoFixCommand(\n    originalCmd: string,\n    stderr: string,\n    os: OSProfile,\n    model?: string\n): Promise<AIFixPlan | null> {\n    const prompt = buildFixPrompt(originalCmd, stderr, os);\n    const raw = await askAI(prompt, model);\n\n    const parseResult = safeParseJSON(raw, aiFixPlanSchema, {} as AIFixPlan);\n\n    if (!parseResult.success) {\n        return null;\n    }\n\n    return parseResult.data;\n}\n",
    "tokens": 156
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/validation.ts",
    "content": "import { z } from 'zod';\n\nexport type UserConfig = {\n    defaultModel?: string;\n    aiProxyUrl?: string;\n    accountType?: 'free' | 'pro';\n    [key: string]: string | undefined;\n};\n\nexport type AppsConfig = Record<string, string>;\n\nexport type AIRequestMessage = {\n    role: 'system' | 'user' | 'assistant';\n    content: string;\n};\n\nexport type AIResponse = {\n    choices?: Array<{\n        message?: {\n            content?: string;\n        };\n        delta?: {\n            content?: string;\n        };\n    }>;\n};\n\nexport const DEFAULT_AI_PROXY_URL = 'https://aiproxy.want.biz/v1/chat/completions';\nexport const DEFAULT_MODEL = 'gemini-2.5-flash-lite';\nexport const DEFAULT_ACCOUNT_TYPE = 'free' as const;\n\nexport const DEFAULT_APPS = {\n    shici: 'https://wealth.want.biz/shici/index.html',\n    dict: 'https://wealth.want.biz/pages/dict.html',\n    pong: 'https://wealth.want.biz/pages/pong.html'\n} as const;\n\nexport const aiCommandPlanSchema = z.object({\n    plan: z.string().describe('Explanation of the command'),\n    command: z.string().optional().describe('The shell command to execute'),\n    macro: z.string().optional().describe('Name of an existing macro to reuse'),\n    risk: z.enum(['low', 'medium', 'high']).describe('Risk level assessment')\n}).refine(data => data.command || data.macro, {\n    message: 'Either command or macro must be provided'\n});\n\nexport type AICommandPlan = z.infer<typeof aiCommandPlanSchema>;\n\nexport const aiFixPlanSchema = z.object({\n    plan: z.string().describe('Fix explanation'),\n    command: z.string().describe('The fixed shell command (always required for fixes)'),\n    risk: z.enum(['low', 'medium', 'high']).describe('Risk level assessment')\n});\n\nexport type AIFixPlan = z.infer<typeof aiFixPlanSchema>;\n\nexport const userConfigSchema = z.object({\n    defaultModel: z.string().optional(),\n    aiProxyUrl: z.string().url().optional(),\n    accountType: z.enum(['free', 'pro']).optional()\n});\n\nexport const appsConfigSchema = z.record(z.string(), z.string());\n\nexport const macroSchema = z.object({\n    commands: z.string(),\n    description: z.string(),\n    createdAt: z.string()\n});\n\nexport type Macro = z.infer<typeof macroSchema>;\n\nexport const historyEntrySchema = z.object({\n    question: z.string(),\n    command: z.string(),\n    time: z.string()\n});\n\nexport type HistoryEntry = z.infer<typeof historyEntrySchema>;\n\nexport function extractJSON(raw: string): string {\n    let jsonContent = raw.trim();\n\n    if (jsonContent.includes('```json')) {\n        jsonContent = jsonContent.split('```json')[1].split('```')[0].trim();\n    }\n    else if (jsonContent.includes('```')) {\n        jsonContent = jsonContent.split('```')[1].split('```')[0].trim();\n    }\n\n    const firstBrace = jsonContent.indexOf('{');\n    const lastBrace = jsonContent.lastIndexOf('}');\n\n    if (firstBrace !== -1 && lastBrace !== -1 && lastBrace > firstBrace) {\n        jsonContent = jsonContent.substring(firstBrace, lastBrace + 1);\n    }\n\n    return jsonContent;\n}\n\nexport function safeParseJSON<T>(\n    raw: string,\n    schema: z.ZodSchema<T>,\n    fallback: T\n): { success: true; data: T } | { success: false; error: z.ZodError } {\n    try {\n        const jsonContent = extractJSON(raw);\n        const result = schema.safeParse(JSON.parse(jsonContent));\n\n        if (result.success) {\n            return { success: true, data: result.data };\n        } else {\n            return { success: false, error: result.error };\n        }\n    } catch (error) {\n        if (error instanceof z.ZodError) {\n            return { success: false, error };\n        }\n        return {\n            success: false,\n            error: new z.ZodError([\n                {\n                    code: z.ZodIssueCode.custom,\n                    message: `Failed to parse JSON: ${error instanceof Error ? error.message : String(error)}`,\n                    path: []\n                }\n            ])\n        };\n    }\n}\n\nexport function parseUserConfig(content: string): UserConfig {\n    return userConfigSchema.parse(JSON.parse(content));\n}\n\nexport function parseAppsConfig(content: string): AppsConfig {\n    return appsConfigSchema.parse(JSON.parse(content)) as AppsConfig;\n}\n\nexport function parseMacros(content: string): Record<string, Macro> {\n    const parsed = JSON.parse(content);\n    const macros: Record<string, Macro> = {};\n\n    for (const [name, value] of Object.entries(parsed)) {\n        macros[name] = macroSchema.parse(value);\n    }\n\n    return macros;\n}\n\nexport function parseCommandHistory(content: string): HistoryEntry[] {\n    const parsed = JSON.parse(content);\n    return z.array(historyEntrySchema).parse(parsed);\n}\n",
    "tokens": 1157
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/executor.ts",
    "content": "import { spawn } from 'child_process';\n\nexport type ExecResult = {\n    stdout: string;\n    stderr: string;\n    code: number | null;\n};\n\nexport async function exec(command: string): Promise<ExecResult> {\n    return new Promise((resolve) => {\n        let stdout = '';\n        let stderr = '';\n\n        // Use user's preferred shell back with full support for their environment\n        const shell = process.env.SHELL || true;\n        const child = spawn(command, [], { shell });\n\n        child.stdout.on('data', (data) => {\n            stdout += data.toString();\n            process.stdout.write(data);\n        });\n\n        child.stderr.on('data', (data) => {\n            stderr += data.toString();\n            process.stderr.write(data);\n        });\n\n        child.on('close', (code) => {\n            resolve({ stdout, stderr, code });\n        });\n\n        child.on('error', (err) => {\n            stderr += err.message;\n            resolve({ stdout, stderr, code: 1 });\n        });\n    });\n}\n",
    "tokens": 248
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/replayEngine.ts",
    "content": "import chalk from 'chalk';\nimport { ExecutionRecord } from './executionRecord';\nimport { loadExecutionRecord } from './executionStore';\n\nexport type ReplayMode = 'strict' | 'compatible' | 're-evaluate';\n\nexport interface ReplayOptions {\n  mode: ReplayMode;\n  skipAI?: boolean;\n  verbose?: boolean;\n}\n\nexport interface ReplayResult {\n  success: boolean;\n  message: string;\n  executedModel?: string;\n  deviationReason?: string;\n}\n\nexport class ReplayEngine {\n  async replay(recordId: string, options: ReplayOptions = { mode: 'strict' }): Promise<ReplayResult> {\n    const record = loadExecutionRecord(recordId);\n\n    if (!record) {\n      return {\n        success: false,\n        message: `Execution record ${recordId} not found`,\n      };\n    }\n\n    if (options.mode === 'strict') {\n      return this.strictReplay(record, options);\n    }\n\n    if (options.mode === 'compatible') {\n      return this.compatibleReplay(record, options);\n    }\n\n    return this.reEvaluate(record, options);\n  }\n\n  private async strictReplay(\n    record: ExecutionRecord,\n    options: ReplayOptions\n  ): Promise<ReplayResult> {\n    const selectedModel = record.decision.selectedModel;\n\n    if (options.verbose) {\n      console.log(chalk.cyan('[Strict Replay]'));\n      console.log(chalk.gray(`  Original Model: ${selectedModel?.name || 'N/A'}`));\n      console.log(chalk.gray(`  Original Provider: ${selectedModel?.provider || 'N/A'}`));\n      console.log(chalk.gray(`  Original Timestamp: ${record.meta.timestamp}`));\n      console.log(chalk.gray(`  Original Command: ${record.meta.commandName}`));\n    }\n\n    if (options.skipAI) {\n      return {\n        success: true,\n        message: 'Strict replay prepared (AI execution skipped)',\n        executedModel: selectedModel?.name ?? undefined,\n      };\n    }\n\n    if (!record.command) {\n      return {\n        success: false,\n        message: 'Strict replay: No command to execute (command not stored in record)',\n        executedModel: selectedModel?.name ?? undefined,\n      };\n    }\n\n    const { exec } = require('./executor');\n\n    try {\n      console.log(chalk.gray('[Strict Replay] Executing with original parameters...'));\n      const result = await exec(record.command);\n\n      return {\n        success: result.code === 0 || result.code === null,\n        message: result.code === 0 || result.code === null\n          ? 'Strict replay completed successfully'\n          : `Strict replay failed with code ${result.code}`,\n        executedModel: selectedModel?.name ?? undefined,\n      };\n    } catch (error: unknown) {\n      const message = error instanceof Error ? error.message : String(error);\n      return {\n        success: false,\n        message: `Strict replay error: ${message}`,\n        executedModel: selectedModel?.name ?? undefined,\n      };\n    }\n  }\n\n  private async compatibleReplay(\n    record: ExecutionRecord,\n    options: ReplayOptions\n  ): Promise<ReplayResult> {\n    const originalModel = record.decision.selectedModel;\n\n    if (options.verbose) {\n      console.log(chalk.cyan('[Compatible Replay]'));\n      console.log(chalk.gray(`  Original Model: ${originalModel?.name || 'N/A'}`));\n      console.log(chalk.gray(`  Will attempt fallback if original unavailable`));\n    }\n\n    return {\n      success: false,\n      message: 'Compatible replay not yet implemented in Phase 1',\n      executedModel: originalModel?.name,\n      deviationReason: 'Phase 1 only supports strict replay',\n    };\n  }\n\n  private async reEvaluate(\n    record: ExecutionRecord,\n    options: ReplayOptions\n  ): Promise<ReplayResult> {\n    if (options.verbose) {\n      console.log(chalk.cyan('[Re-evaluate]'));\n      console.log(chalk.gray(`  Will re-run capability matching with current config`));\n      console.log(chalk.gray(`  Original Intent: ${record.intent.required.join(', ')}`));\n    }\n\n    return {\n      success: false,\n      message: 'Re-evaluate not yet implemented in Phase 1',\n    };\n  }\n}\n\nexport const replayEngine = new ReplayEngine();\n",
    "tokens": 994
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/modelMatcher.ts",
    "content": "import { AtomicCapability, ConstraintCapability, expandCapabilities } from './capabilities';\n\nexport interface ModelCapabilities {\n  name: string;\n  provider: string;\n  atomicCapabilities: AtomicCapability[];\n  contextWindow?: number;\n  costProfile?: 'low' | 'medium' | 'high';\n}\n\nexport interface CapabilityRequirement {\n  required: AtomicCapability[];\n  preferred: AtomicCapability[];\n  constraints?: ConstraintCapability[];\n}\n\nexport interface CapabilityMatchExplanation {\n  modelName: string;\n  provider: string;\n  hasRequired: boolean;\n  hasPreferred: AtomicCapability[];\n  missingRequired: AtomicCapability[];\n  reason: string;\n}\n\nexport interface CapabilityMatchResult {\n  selected: ModelCapabilities | null;\n  candidates: CapabilityMatchExplanation[];\n  fallbackOccurred: boolean;\n}\n\nexport function matchModel(\n  models: ModelCapabilities[],\n  requirement: CapabilityRequirement\n): CapabilityMatchResult {\n  const explanations: CapabilityMatchExplanation[] = [];\n\n  for (const model of models) {\n    const hasRequired = requirement.required.every(cap =>\n      model.atomicCapabilities.includes(cap)\n    );\n\n    const missingRequired = requirement.required.filter(cap =>\n      !model.atomicCapabilities.includes(cap)\n    );\n\n    const hasPreferred = requirement.preferred.filter(cap =>\n      model.atomicCapabilities.includes(cap)\n    );\n\n    const explanation: CapabilityMatchExplanation = {\n      modelName: model.name,\n      provider: model.provider,\n      hasRequired,\n      hasPreferred,\n      missingRequired,\n      reason: hasRequired\n        ? `Has all required capabilities. Matches ${hasPreferred.length}/${requirement.preferred.length} preferred.`\n        : `Missing required capabilities: ${missingRequired.map(c => String(c)).join(', ')}`,\n    };\n\n    explanations.push(explanation);\n  }\n\n  const matchingModels = explanations.filter(e => e.hasRequired);\n\n  if (matchingModels.length === 0) {\n    return {\n      selected: null,\n      candidates: explanations,\n      fallbackOccurred: false,\n    };\n  }\n\n  const bestMatch = matchingModels[0];\n  const selectedModel = models.find(m => m.name === bestMatch.modelName);\n\n  return {\n    selected: selectedModel || null,\n    candidates: explanations,\n    fallbackOccurred: false,\n  };\n}\n\nexport function matchModelWithFallback(\n  models: ModelCapabilities[],\n  fallbackModels: ModelCapabilities[],\n  requirement: CapabilityRequirement\n): CapabilityMatchResult {\n  const primaryResult = matchModel(models, requirement);\n\n  if (primaryResult.selected) {\n    return primaryResult;\n  }\n\n  const fallbackResult = matchModel(fallbackModels, requirement);\n\n  return {\n    ...fallbackResult,\n    fallbackOccurred: fallbackResult.selected !== null,\n  };\n}\n",
    "tokens": 678
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/fileReader.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\n\nexport function parseFilePathsFromLsOutput(output: string): string[] {\n    const lines = output.trim().split('\\n');\n    const filePaths: string[] = [];\n\n    for (const line of lines) {\n        const parts = line.trim().split(/\\s+/);\n        const lastPart = parts[parts.length - 1];\n        \n        if (lastPart && !lastPart.startsWith('-') && lastPart !== '.' && lastPart !== '..') {\n            filePaths.push(lastPart);\n        }\n    }\n\n    return filePaths;\n}\n\nexport function readFilesContent(filePaths: string[]): Map<string, string> {\n    const contentMap = new Map<string, string>();\n\n    for (const filePath of filePaths) {\n        try {\n            const fullPath = path.resolve(filePath);\n            if (fs.existsSync(fullPath) && fs.statSync(fullPath).isFile()) {\n                const content = fs.readFileSync(fullPath, 'utf-8');\n                contentMap.set(filePath, content);\n            }\n        } catch (error) {\n            console.error(`Êó†Ê≥ïËØªÂèñÊñá‰ª∂: ${filePath}`);\n        }\n    }\n\n    return contentMap;\n}\n\nexport function buildPromptWithFileContent(\n    originalOutput: string,\n    filePaths: string[],\n    contentMap: Map<string, string>,\n    question?: string\n): string {\n    let prompt = '';\n\n    prompt += '## Êñá‰ª∂ÂàóË°®\\n';\n    prompt += '```\\n';\n    prompt += originalOutput;\n    prompt += '```\\n\\n';\n\n    if (contentMap.size > 0) {\n        prompt += '## Êñá‰ª∂ÂÜÖÂÆπ\\n\\n';\n        for (const [filePath, content] of contentMap) {\n            prompt += `### ${filePath}\\n`;\n            prompt += '```\\n';\n            const maxChars = 5000;\n            const truncated = content.length > maxChars \n                ? content.substring(0, maxChars) + '\\n... (ÂÜÖÂÆπËøáÈïøÂ∑≤Êà™Êñ≠)'\n                : content;\n            prompt += truncated;\n            prompt += '\\n```\\n\\n';\n        }\n    }\n\n    if (question) {\n        prompt += `\\n## ÊàëÁöÑÈóÆÈ¢ò\\n${question}`;\n    } else {\n        prompt += '\\n## ÊàëÁöÑÈóÆÈ¢ò\\nËØ∑ÂàÜÊûê‰ª•‰∏äÊñá‰ª∂ÂàóË°®ÂíåÊñá‰ª∂ÂÜÖÂÆπ';\n    }\n\n    return prompt;\n}\n",
    "tokens": 498
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/risk.ts",
    "content": "export function assessRisk(command: string, aiRisk: 'low' | 'medium' | 'high'): 'low' | 'medium' | 'high' {\n    const HIGH_RISK_PATTERNS = [\n        /\\brm\\b/i,\n        /\\bsudo\\b/i,\n        /\\bmv\\b/i,\n        /\\bdd\\b/i,\n        /\\bchmod\\b/i,\n        /\\bchown\\b/i,\n        />\\s*\\/dev\\//,\n        /:\\(\\)\\s*\\{.*\\}/, // Fork bomb\n        /\\bmkfs\\b/i,\n    ];\n\n    const hasHighRisk = HIGH_RISK_PATTERNS.some(pattern => pattern.test(command));\n\n    if (hasHighRisk) return 'high';\n    return aiRisk;\n}\n",
    "tokens": 124
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/executionRecord.ts",
    "content": "import { MergedConfig } from './configMerge';\nimport { ModelCapabilities, CapabilityMatchExplanation } from './modelMatcher';\nimport { CapabilityRequirement } from './modelMatcher';\n\nexport interface ExecutionMeta {\n  commandName: string;\n  timestamp: string;\n  toolVersion: string;\n  projectPath: string;\n}\n\nexport interface CapabilityIntent {\n  required: string[];\n  preferred: string[];\n  capabilityVersion: string;\n}\n\nexport interface ModelDecision {\n  candidateModels: CapabilityMatchExplanation[];\n  selectedModel: ModelCapabilities | null;\n  usedFallback: boolean;\n  fallbackReason?: string;\n}\n\nexport interface ExecutionOutcome {\n  success: boolean;\n  failureReason?: 'capability-mismatch' | 'provider-error' | 'user-abort' | 'timeout' | 'other';\n  tokenCount?: number;\n  latencyMs?: number;\n}\n\nexport interface ExecutionRecord {\n  id: string;\n  meta: ExecutionMeta;\n  intent: CapabilityIntent;\n  configSnapshot: MergedConfig;\n  decision: ModelDecision;\n  outcome: ExecutionOutcome;\n  command?: string;\n}\n\nexport function createExecutionId(): string {\n  return `exec_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n}\n\nexport function createExecutionRecord(\n  commandName: string,\n  requirement: CapabilityRequirement,\n  config: MergedConfig,\n  matchResult: any,\n  outcome: Partial<ExecutionOutcome> = {},\n  command?: string\n): ExecutionRecord {\n  const version = require('../../package.json').version;\n\n  return {\n    id: createExecutionId(),\n    meta: {\n      commandName,\n      timestamp: new Date().toISOString(),\n      toolVersion: version,\n      projectPath: process.cwd(),\n    },\n    intent: {\n      required: requirement.required.map(String),\n      preferred: requirement.preferred.map(String),\n      capabilityVersion: require('./capabilities').CAPABILITY_VERSION,\n    },\n    configSnapshot: config,\n    decision: {\n      candidateModels: matchResult.candidates || [],\n      selectedModel: matchResult.selected,\n      usedFallback: matchResult.fallbackOccurred,\n    },\n    outcome: {\n      success: outcome.success ?? false,\n      ...outcome,\n    },\n    command,\n  };\n}\n\nexport function serializeExecutionRecord(record: ExecutionRecord): string {\n  return JSON.stringify(record, null, 2);\n}\n\nexport function deserializeExecutionRecord(json: string): ExecutionRecord {\n  return JSON.parse(json) as ExecutionRecord;\n}\n",
    "tokens": 586
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/macros.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { parseMacros, type Macro } from './validation';\n\nconst USER_MACROS_FILE = path.join(os.homedir(), '.yuangs_macros.json');\n\nexport type { Macro };\n\nfunction loadMacrosFromFile(filePath: string): Record<string, Macro> {\n    if (fs.existsSync(filePath)) {\n        try {\n            return parseMacros(fs.readFileSync(filePath, 'utf8'));\n        } catch (e) { }\n    }\n    return {};\n}\n\nfunction findProjectMacros(cwd = process.cwd()): string | null {\n    let dir = cwd;\n    while (dir && dir !== path.dirname(dir)) {\n        const candidate = path.join(dir, 'yuangs_macros.json');\n        if (fs.existsSync(candidate)) {\n            return candidate;\n        }\n        dir = path.dirname(dir);\n    }\n    // Check root one last time\n    const rootCandidate = path.join(targetRoot(dir), 'yuangs_macros.json');\n    if (fs.existsSync(rootCandidate)) return rootCandidate;\n    \n    return null;\n}\n\n// Helper to reliably stop at root (dirname('/') is '/')\nfunction targetRoot(dir: string) {\n    return path.parse(dir).root;\n}\n\nexport function getMacros(): Record<string, Macro> {\n    const userMacros = loadMacrosFromFile(USER_MACROS_FILE);\n    \n    const projectMacrosPath = findProjectMacros();\n    const projectMacros = projectMacrosPath ? loadMacrosFromFile(projectMacrosPath) : {};\n\n    return {\n        ...userMacros,\n        ...projectMacros // Project overrides User\n    };\n}\n\nexport function saveMacro(name: string, commands: string, description: string = '') {\n    // Only load USER macros for saving\n    const macros = loadMacrosFromFile(USER_MACROS_FILE);\n    macros[name] = {\n        commands,\n        description,\n        createdAt: new Date().toISOString()\n    };\n    fs.writeFileSync(USER_MACROS_FILE, JSON.stringify(macros, null, 2));\n    return true;\n}\n\nexport function deleteMacro(name: string) {\n    // Only delete from USER macros\n    const macros = loadMacrosFromFile(USER_MACROS_FILE);\n    if (macros[name]) {\n        delete macros[name];\n        fs.writeFileSync(USER_MACROS_FILE, JSON.stringify(macros, null, 2));\n        return true;\n    }\n    return false;\n}\n\nexport function runMacro(name: string) {\n    const macros = getMacros();\n    const macro = macros[name];\n    if (!macro) return false;\n\n    const { spawn } = require('child_process');\n    spawn(macro.commands, [], { shell: true, stdio: 'inherit' });\n    return true;\n}\n",
    "tokens": 606
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/capabilities.ts",
    "content": "export enum AtomicCapability {\n  TEXT_GENERATION = 'text_generation',\n  CODE_GENERATION = 'code_generation',\n  TOOL_CALLING = 'tool_calling',\n  LONG_CONTEXT = 'long_context',\n  REASONING = 'reasoning',\n  STREAMING = 'streaming',\n}\n\nexport interface CompositeCapability {\n  name: string;\n  composedOf: AtomicCapability[];\n}\n\nexport const COMPOSITE_CAPABILITIES: CompositeCapability[] = [\n  {\n    name: 'interactive_agent',\n    composedOf: [AtomicCapability.TOOL_CALLING, AtomicCapability.REASONING],\n  },\n  {\n    name: 'large_repo_analysis',\n    composedOf: [AtomicCapability.LONG_CONTEXT, AtomicCapability.REASONING],\n  },\n  {\n    name: 'safe_code_editing',\n    composedOf: [AtomicCapability.CODE_GENERATION, AtomicCapability.REASONING],\n  },\n];\n\nexport enum ConstraintCapability {\n  PREFER_DETERMINISTIC = 'prefer_deterministic',\n  LOW_COST = 'low_cost',\n  FAST_RESPONSE = 'fast_response',\n}\n\nexport const CAPABILITY_VERSION = '1.0';\n\nexport function isAtomicCapability(value: string): value is AtomicCapability {\n  return Object.values(AtomicCapability).includes(value as AtomicCapability);\n}\n\nexport function isConstraintCapability(value: string): value is ConstraintCapability {\n  return Object.values(ConstraintCapability).includes(value as ConstraintCapability);\n}\n\nexport function resolveCompositeCapability(name: string): AtomicCapability[] {\n  const composite = COMPOSITE_CAPABILITIES.find(c => c.name === name);\n  if (!composite) {\n    throw new Error(`Unknown composite capability: ${name}`);\n  }\n  return composite.composedOf;\n}\n\nexport function expandCapabilities(\n  capabilities: Array<AtomicCapability | string>\n): Set<AtomicCapability> {\n  const result = new Set<AtomicCapability>();\n\n  for (const cap of capabilities) {\n    if (isAtomicCapability(cap)) {\n      result.add(cap);\n    } else {\n      const atomicCaps = resolveCompositeCapability(cap);\n      atomicCaps.forEach(c => result.add(c));\n    }\n  }\n\n  return result;\n}\n",
    "tokens": 486
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/capabilityInference.ts",
    "content": "import { AtomicCapability } from '../core/capabilities';\nimport type { CapabilityRequirement } from '../core/modelMatcher';\n\nexport function inferCapabilityRequirement(userInput: string): CapabilityRequirement {\n  const required: AtomicCapability[] = [];\n\n  const input = userInput.toLowerCase();\n\n  if (input.includes('‰ª£Á†Å') || input.includes('script') || input.includes('Êñá‰ª∂') || input.includes('create') || input.includes('write')) {\n    required.push(AtomicCapability.CODE_GENERATION);\n  }\n\n  if (input.includes('ÂàÜÊûê') || input.includes('ÁêÜËß£') || input.includes('Ëß£Èáä') || input.includes('Êé®ÁêÜ')) {\n    required.push(AtomicCapability.REASONING);\n  }\n\n  if (input.includes('Èïø') || input.includes('large') || input.includes('‰ªìÂ∫ì') || input.includes('ÁõÆÂΩï') || input.includes('ÊâÄÊúâÊñá‰ª∂')) {\n    required.push(AtomicCapability.LONG_CONTEXT);\n  }\n\n  return {\n    required: Array.from(new Set(required)),\n    preferred: [],\n  };\n}\n",
    "tokens": 229
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/apps.ts",
    "content": "import { exec } from 'child_process';\nimport fs from 'fs';\nimport path from 'path';\nimport yaml from 'js-yaml';\nimport os from 'os';\nimport { DEFAULT_APPS, parseAppsConfig } from './validation';\n\nexport { DEFAULT_APPS };\n\nexport function loadAppsConfig(): Record<string, string> {\n    const configPaths = [\n        path.join(process.cwd(), 'yuangs.config.json'),\n        path.join(process.cwd(), 'yuangs.config.yaml'),\n        path.join(process.cwd(), 'yuangs.config.yml'),\n        path.join(process.cwd(), '.yuangs.json'),\n        path.join(process.cwd(), '.yuangs.yaml'),\n        path.join(process.cwd(), '.yuangs.yml'),\n        path.join(os.homedir(), '.yuangs.json'),\n        path.join(os.homedir(), '.yuangs.yaml'),\n        path.join(os.homedir(), '.yuangs.yml'),\n    ];\n\n    for (const configPath of configPaths) {\n        if (fs.existsSync(configPath)) {\n            try {\n                const configContent = fs.readFileSync(configPath, 'utf8');\n                let config: Record<string, string>;\n                if (configPath.endsWith('.yaml') || configPath.endsWith('.yml')) {\n                    config = yaml.load(configContent) as Record<string, string>;\n                } else {\n                    config = parseAppsConfig(configContent);\n                }\n                return config;\n            } catch (error) { }\n        }\n    }\n    return DEFAULT_APPS;\n}\n\n\nexport function openUrl(url: string) {\n    let command;\n    switch (process.platform) {\n        case 'darwin': command = `open \"${url}\"`; break;\n        case 'win32': command = `start \"${url}\"`; break;\n        default: command = `xdg-open \"${url}\"`; break;\n    }\n    exec(command);\n}\n",
    "tokens": 417
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/capabilitySystem.ts",
    "content": "import {\n  CapabilityRequirement,\n  matchModelWithFallback,\n  ModelCapabilities,\n  CapabilityMatchResult,\n} from './modelMatcher';\nimport {\n  mergeConfigs,\n  loadConfigAt,\n  dumpConfigSnapshot,\n  getConfigFilePaths,\n  MergedConfig,\n} from './configMerge';\nimport {\n  createExecutionRecord,\n  ExecutionRecord,\n} from './executionRecord';\nimport {\n  saveExecutionRecord,\n  loadExecutionRecord,\n  listExecutionRecords,\n} from './executionStore';\nimport { replayEngine, ReplayOptions, ReplayResult } from './replayEngine';\n\nexport class CapabilitySystem {\n  private primaryModels: ModelCapabilities[] = [];\n  private fallbackModels: ModelCapabilities[] = [];\n\n  constructor() {\n    this.initializeDefaultModels();\n  }\n\n  private initializeDefaultModels(): void {\n    // ÂàùÂßãÂåñ‰∏∫Á©∫Êï∞ÁªÑÔºåËÆ©ÈÖçÁΩÆÊñá‰ª∂Êàê‰∏∫‰∏ªË¶ÅÊù•Ê∫ê\n    this.primaryModels = [];\n    this.fallbackModels = [];\n  }\n\n  matchCapability(requirement: CapabilityRequirement): CapabilityMatchResult {\n    const allModels = this.getAllModels();\n    const primaryModels = [...this.primaryModels, ...this.loadCustomModels()];\n    return matchModelWithFallback(\n      primaryModels,\n      this.fallbackModels,\n      requirement\n    );\n  }\n\n  loadMergedConfig(): MergedConfig {\n    const builtin = {\n      aiProxyUrl: 'https://aiproxy.want.biz/v1/chat/completions',\n      defaultModel: 'gemini-2.5-flash-lite',\n      accountType: 'free',\n    };\n\n    const filePaths = getConfigFilePaths();\n    const projectConfig = filePaths.project ? loadConfigAt(filePaths.project) : null;\n    const userGlobal = loadConfigAt(filePaths.userGlobal);\n\n    return mergeConfigs(builtin, userGlobal, projectConfig, null);\n  }\n\n  loadCustomModels(): ModelCapabilities[] {\n    const filePaths = getConfigFilePaths();\n    const projectConfig = filePaths.project ? loadConfigAt(filePaths.project) : null;\n    const userGlobal = loadConfigAt(filePaths.userGlobal);\n\n    const customModelsArray = [];\n    if (userGlobal?.models && Array.isArray(userGlobal.models)) {\n      customModelsArray.push(...userGlobal.models as ModelCapabilities[]);\n    }\n    if (projectConfig?.models && Array.isArray(projectConfig.models)) {\n      customModelsArray.push(...projectConfig.models as ModelCapabilities[]);\n    }\n\n    return customModelsArray;\n  }\n\n  getAllModels(): ModelCapabilities[] {\n    const customModels = this.loadCustomModels();\n    return [...this.primaryModels, ...this.fallbackModels, ...customModels];\n  }\n\n  createAndSaveExecutionRecord(\n    commandName: string,\n    requirement: CapabilityRequirement,\n    matchResult: CapabilityMatchResult,\n    command?: string\n  ): string {\n    const config = this.loadMergedConfig();\n    const record = createExecutionRecord(\n      commandName,\n      requirement,\n      config,\n      matchResult,\n      { success: matchResult.selected !== null },\n      command\n    );\n\n    const filePath = saveExecutionRecord(record);\n    return record.id;\n  }\n\n  replayExecution(recordId: string, options: ReplayOptions): Promise<ReplayResult> {\n    return replayEngine.replay(recordId, options);\n  }\n\n  explainConfig(): string {\n    const config = this.loadMergedConfig();\n    return dumpConfigSnapshot(config);\n  }\n}\n\nexport const capabilitySystem = new CapabilitySystem();\n",
    "tokens": 801
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/configMerge.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport yaml from 'js-yaml';\n\nexport type ConfigSource = 'built-in' | 'user-global' | 'project' | 'command-override';\n\nexport interface ConfigFieldSource<T = unknown> {\n  value: T;\n  source: ConfigSource;\n  filePath?: string;\n}\n\nexport interface MergedConfig {\n  aiProxyUrl: ConfigFieldSource<string>;\n  defaultModel: ConfigFieldSource<string>;\n  accountType: ConfigFieldSource<'free' | 'pro'>;\n  [key: string]: ConfigFieldSource<unknown>;\n}\n\nexport function loadConfigAt(filePath: string): Record<string, unknown> | null {\n  if (!fs.existsSync(filePath)) {\n    return null;\n  }\n\n  try {\n    const content = fs.readFileSync(filePath, 'utf8');\n    if (filePath.endsWith('.yaml') || filePath.endsWith('.yml')) {\n      return yaml.load(content) as Record<string, unknown>;\n    }\n    return JSON.parse(content);\n  } catch (error) {\n    console.warn(`Failed to load config from ${filePath}:`, error);\n    return null;\n  }\n}\n\nexport function mergeConfigs(\n  builtin: Record<string, unknown>,\n  userGlobal: Record<string, unknown> | null,\n  project: Record<string, unknown> | null,\n  commandOverride: Record<string, unknown> | null\n): MergedConfig {\n  const merged: MergedConfig = {} as MergedConfig;\n\n  const addField = (key: string, value: unknown, source: ConfigSource, filePath?: string) => {\n    merged[key] = { value, source, filePath };\n  };\n\n  Object.entries(builtin).forEach(([key, value]) => {\n    addField(key, value, 'built-in');\n  });\n\n  if (userGlobal) {\n    Object.entries(userGlobal).forEach(([key, value]) => {\n      addField(key, value, 'user-global', path.join(os.homedir(), '.yuangs.json'));\n    });\n  }\n\n  if (project) {\n    Object.entries(project).forEach(([key, value]) => {\n      addField(key, value, 'project');\n    });\n  }\n\n  if (commandOverride) {\n    Object.entries(commandOverride).forEach(([key, value]) => {\n      addField(key, value, 'command-override');\n    });\n  }\n\n  return merged;\n}\n\nexport function dumpConfigSnapshot(config: MergedConfig): string {\n  const output: Record<string, any> = {};\n\n  Object.entries(config).forEach(([key, field]) => {\n    output[key] = {\n      value: field.value,\n      source: field.source,\n      filePath: field.filePath,\n    };\n  });\n\n  return JSON.stringify(output, null, 2);\n}\n\nfunction findProjectConfig(cwd = process.cwd()): string | null {\n  let dir = cwd;\n  const configFiles = ['.yuangs.json', '.yuangs.yaml', '.yuangs.yml', 'yuangs.config.json'];\n\n  while (dir && dir !== path.dirname(dir)) {\n    for (const filename of configFiles) {\n      const candidate = path.join(dir, filename);\n      if (fs.existsSync(candidate)) {\n        return candidate;\n      }\n    }\n    dir = path.dirname(dir);\n  }\n\n  const root = path.parse(cwd).root;\n  for (const filename of configFiles) {\n    const rootCandidate = path.join(root, filename);\n    if (fs.existsSync(rootCandidate)) {\n      return rootCandidate;\n    }\n  }\n\n  return null;\n}\n\nexport function getConfigFilePaths(): {\n  userGlobal: string;\n  project: string | null;\n} {\n  return {\n    userGlobal: path.join(os.homedir(), '.yuangs.json'),\n    project: findProjectConfig(),\n  };\n}\n",
    "tokens": 790
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/os.ts",
    "content": "export type OSProfile = {\n    name: string;\n    shell: string;\n    find: 'bsd' | 'gnu';\n    stat: 'bsd' | 'gnu';\n};\n\nexport function getOSProfile(): OSProfile {\n    switch (process.platform) {\n        case 'darwin':\n            return {\n                name: 'macOS',\n                shell: 'zsh',\n                find: 'bsd',\n                stat: 'bsd',\n            };\n        case 'linux':\n            return {\n                name: 'Linux',\n                shell: 'bash',\n                find: 'gnu',\n                stat: 'gnu',\n            };\n        case 'win32':\n            return {\n                name: 'Windows',\n                shell: 'cmd',\n                find: 'gnu', // Win32 find is different, but for AI context let's assume GNU style tools if they are there, or just label it.\n                stat: 'gnu',\n            };\n        default:\n            return {\n                name: process.platform,\n                shell: 'sh',\n                find: 'gnu',\n                stat: 'gnu',\n            };\n    }\n}\n",
    "tokens": 258
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/core/executionStore.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { ExecutionRecord, serializeExecutionRecord, deserializeExecutionRecord } from './executionRecord';\n\nconst RECORD_DIR = path.join(os.homedir(), '.yuangs', 'executions');\n\nexport function ensureRecordDir(): void {\n  if (!fs.existsSync(RECORD_DIR)) {\n    fs.mkdirSync(RECORD_DIR, { recursive: true });\n  }\n}\n\nexport function saveExecutionRecord(record: ExecutionRecord): string {\n  ensureRecordDir();\n\n  const filename = `${record.id}.json`;\n  const filepath = path.join(RECORD_DIR, filename);\n\n  fs.writeFileSync(filepath, serializeExecutionRecord(record), 'utf8');\n\n  return filepath;\n}\n\nexport function loadExecutionRecord(id: string): ExecutionRecord | null {\n  ensureRecordDir();\n\n  const filename = `${id}.json`;\n  const filepath = path.join(RECORD_DIR, filename);\n\n  if (!fs.existsSync(filepath)) {\n    return null;\n  }\n\n  try {\n    const content = fs.readFileSync(filepath, 'utf8');\n    return deserializeExecutionRecord(content);\n  } catch (error) {\n    console.error(`Failed to load execution record ${id}:`, error);\n    return null;\n  }\n}\n\nexport function listExecutionRecords(limit: number = 50): ExecutionRecord[] {\n  ensureRecordDir();\n\n  const files = fs.readdirSync(RECORD_DIR)\n    .filter(f => f.endsWith('.json'))\n    .sort((a, b) => {\n      const statA = fs.statSync(path.join(RECORD_DIR, a));\n      const statB = fs.statSync(path.join(RECORD_DIR, b));\n      return statB.mtimeMs - statA.mtimeMs;\n    })\n    .slice(0, limit);\n\n  const records: ExecutionRecord[] = [];\n\n  for (const file of files) {\n    const record = loadExecutionRecord(file.replace('.json', ''));\n    if (record) {\n      records.push(record);\n    }\n  }\n\n  return records;\n}\n\nexport function deleteExecutionRecord(id: string): boolean {\n  ensureRecordDir();\n\n  const filename = `${id}.json`;\n  const filepath = path.join(RECORD_DIR, filename);\n\n  if (!fs.existsSync(filepath)) {\n    return false;\n  }\n\n  try {\n    fs.unlinkSync(filepath);\n    return true;\n  } catch (error) {\n    console.error(`Failed to delete execution record ${id}:`, error);\n    return false;\n  }\n}\n\nexport function clearAllExecutionRecords(): void {\n  ensureRecordDir();\n\n  const files = fs.readdirSync(RECORD_DIR).filter(f => f.endsWith('.json'));\n\n  for (const file of files) {\n    const filepath = path.join(RECORD_DIR, file);\n    try {\n      fs.unlinkSync(filepath);\n    } catch (error) {\n      console.error(`Failed to delete ${filepath}:`, error);\n    }\n  }\n}\n",
    "tokens": 625
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/types.d.ts",
    "content": "declare module 'marked-terminal' {\n    import { Renderer } from 'marked';\n    export default class TerminalRenderer extends Renderer {\n        constructor(options?: any);\n    }\n}\n",
    "tokens": 45
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/utils/history.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { parseCommandHistory, type HistoryEntry } from '../core/validation';\n\nconst HISTORY_FILE = path.join(os.homedir(), '.yuangs_cmd_history.json');\n\nexport type { HistoryEntry };\n\nexport function getCommandHistory(): HistoryEntry[] {\n    if (fs.existsSync(HISTORY_FILE)) {\n        try {\n            return parseCommandHistory(fs.readFileSync(HISTORY_FILE, 'utf8'));\n        } catch (e) { }\n    }\n    return [];\n}\n\nexport function saveHistory(entry: { question: string; command: string }) {\n    let history = getCommandHistory();\n    const newEntry: HistoryEntry = {\n        ...entry,\n        time: new Date().toLocaleString()\n    };\n    // Keep last 1000, unique commands\n    history = [newEntry, ...history.filter(item => item.command !== entry.command)].slice(0, 1000);\n    fs.writeFileSync(HISTORY_FILE, JSON.stringify(history, null, 2));\n}\n",
    "tokens": 229
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/utils/confirm.ts",
    "content": "import * as readline from 'node:readline/promises';\nimport chalk from 'chalk';\n\nexport async function confirm(message: string): Promise<boolean> {\n    const rl = readline.createInterface({\n        input: process.stdin,\n        output: process.stdout,\n    });\n\n    try {\n        const answer = await rl.question(chalk.yellow(`\\n‚ö†Ô∏è  ${message} (y/N) `));\n        return answer.toLowerCase() === 'y';\n    } finally {\n        rl.close();\n    }\n}\n\n",
    "tokens": 111
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/utils/renderer.ts",
    "content": "import chalk from 'chalk';\nimport * as marked from 'marked';\nimport TerminalRenderer from 'marked-terminal';\nimport ora, { Ora } from 'ora';\n\n// ÂàùÂßãÂåñ marked ÈÖçÁΩÆ\nmarked.setOptions({\n    renderer: new TerminalRenderer({\n        tab: 2,\n        width: process.stdout.columns || 80,\n        showSectionPrefix: false\n    }) as any\n});\n\nexport class StreamMarkdownRenderer {\n    private fullResponse: string = '';\n    private prefix: string;\n    private isFirstOutput: boolean = true;\n    private spinner: Ora | null = null;\n    private startTime: number;\n\n    constructor(prefix: string = chalk.bold.blue('ü§ñ AIÔºö'), spinner?: Ora) {\n        this.prefix = prefix;\n        this.spinner = spinner || null;\n        this.startTime = Date.now();\n    }\n\n    /**\n     * Â§ÑÁêÜÊµÅÂºèÊï∞ÊçÆÂùó\n     */\n    public onChunk(chunk: string) {\n        if (this.spinner && this.spinner.isSpinning) {\n            this.spinner.stop();\n        }\n\n        if (this.isFirstOutput) {\n            process.stdout.write(this.prefix);\n            this.isFirstOutput = false;\n        }\n\n        this.fullResponse += chunk;\n        process.stdout.write(chunk);\n    }\n\n    /**\n     * ÊµÅÁªìÊùüÔºåÊâßË°åÂõûÊªöÂπ∂Ê∏≤Êüì Markdown\n     */\n    public finish(): string {\n        // Â¶ÇÊûú Spinner ËøòÂú®ËΩ¨ÔºàËØ¥ÊòéÊ≤°Êúâ‰ªª‰ΩïËæìÂá∫ÔºâÔºåÂÖàÂÅúÊéâ\n        if (this.spinner && this.spinner.isSpinning) {\n            this.spinner.stop();\n        }\n\n        const formatted = (marked.parse(this.fullResponse, { async: false }) as string).trim();\n\n        if (process.stdout.isTTY && this.fullResponse.trim()) {\n            const screenWidth = process.stdout.columns || 80;\n            const totalContent = this.prefix + this.fullResponse;\n            \n            // ËÆ°ÁÆóÂéüÂßãÊñáÊú¨Âç†Áî®ÁöÑÂèØËßÜË°åÊï∞\n            const lineCount = this.getVisualLineCount(totalContent, screenWidth);\n\n            // 1. Ê∏ÖÈô§ÂΩìÂâçË°åÂâ©‰ΩôÂÜÖÂÆπ\n            process.stdout.write('\\r\\x1b[K');\n            // 2. Âêë‰∏äÂõûÊªöÂπ∂Ê∏ÖÈô§‰πãÂâçÁöÑË°å\n            for (let i = 0; i < lineCount - 1; i++) {\n                process.stdout.write('\\x1b[A\\x1b[K');\n            }\n\n            // 3. ËæìÂá∫Ê†ºÂºèÂåñÂêéÁöÑ Markdown\n            process.stdout.write(this.prefix + formatted + '\\n');\n        } else {\n            // Èùû TTY Ê®°ÂºèÊàñÊó†ÂÜÖÂÆπÔºåÁõ¥Êé•Ë°•ÂÖÖÊç¢Ë°åÔºàÂ¶ÇÊûú‰πãÂâçËæìÂá∫‰∫ÜÂÜÖÂÆπÔºâ\n            if (this.fullResponse.trim()) {\n                process.stdout.write('\\n'); \n            }\n        }\n\n        // ËæìÂá∫ËÄóÊó∂ÁªüËÆ°\n        const elapsed = (Date.now() - this.startTime) / 1000;\n        process.stdout.write('\\n' + chalk.gray(`‚îÄ`.repeat(20) + ` (ËÄóÊó∂: ${elapsed.toFixed(2)}s) ` + `‚îÄ`.repeat(20) + '\\n\\n'));\n\n        return this.fullResponse;\n    }\n\n    /**\n     * ËÆ°ÁÆóÊñáÊú¨Âú®ÁªàÁ´ØÁöÑÂèØËßÜË°åÊï∞\n     */\n    private getVisualLineCount(text: string, screenWidth: number): number {\n        const stripAnsi = (str: string) => str.replace(/[\\u001b\\u009b][[()#;?]*(?:[0-9]{1,4}(?:;[0-9]{0,4})*)?[0-9A-ORZcf-nqry=><]/g, '');\n\n        const lines = text.split('\\n');\n        let totalLines = 0;\n\n        for (const line of lines) {\n            // Expand tabs\n            const expandedLine = line.replace(/\\t/g, '        ');\n            const cleanLine = stripAnsi(expandedLine);\n\n            let lineWidth = 0;\n            for (const char of cleanLine) {\n                const code = char.codePointAt(0) || 0;\n                // Â§ßÈÉ®ÂàÜÂÆΩÂ≠óÁ¨¶ÔºàÂ¶Ç‰∏≠ÊñáÔºâÂç† 2 Ê†º\n                lineWidth += code > 255 ? 2 : 1;\n            }\n\n            if (lineWidth === 0) {\n                totalLines += 1;\n            } else {\n                totalLines += Math.ceil(lineWidth / screenWidth);\n            }\n        }\n\n        return totalLines;\n    }\n}\n",
    "tokens": 863
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/AgentPipeline.ts",
    "content": "import {\n    AgentInput,\n    AgentMode,\n} from './types';\n\nimport { ContextBuffer } from '../commands/contextBuffer';\n\nimport { inferIntent } from './intent';\nimport { buildContext } from './context';\nimport { buildPrompt } from './prompt';\nimport { selectModel } from './selectModel';\nimport { runLLM } from './llm';\nimport { interpretResultToPlan } from './interpret';\nimport { executePlan } from './planExecutor';\nimport { saveRecord } from './record';\nimport { learnSkillFromRecord } from './skills';\nimport { randomUUID } from 'crypto';\nimport { StreamMarkdownRenderer } from '../utils/renderer'; // Import renderer\nimport ora, { Ora } from 'ora';\nimport chalk from 'chalk';\n\nexport class AgentPipeline {\n    private contextBuffer: ContextBuffer = new ContextBuffer();\n\n    async run(input: AgentInput, mode: AgentMode): Promise<void> {\n        const id = randomUUID();\n\n        // 1. Intent Analysis\n        const intent = inferIntent(input, mode);\n\n        // 2. Context Assembly\n        const context = buildContext(input, this.contextBuffer);\n\n        // 3. Prompt Construction\n        const prompt = buildPrompt(intent, context, mode, input.rawInput);\n\n        // 4. Model Selection\n        const model = selectModel(intent, input.options?.model);\n\n        // Setup Renderer if in Chat Mode\n        let renderer: StreamMarkdownRenderer | undefined;\n        let spinner: Ora | undefined;\n\n        if (mode === 'chat') {\n            spinner = ora(chalk.cyan('Thinking...')).start();\n            renderer = new StreamMarkdownRenderer(chalk.bold.blue('ü§ñ AI: '), spinner);\n        }\n\n        // 5. LLM Execution\n        const result = await runLLM({\n            prompt,\n            model,\n            stream: mode === 'chat',\n            onChunk: mode === 'chat' && renderer\n                ? (s) => renderer!.onChunk(s)\n                : undefined,\n        });\n\n        // Finish rendering if chat mode\n        if (mode === 'chat' && renderer) {\n            renderer.finish();\n        }\n\n        // 6. Result Interpretation -> Plan\n        const isStreaming = mode === 'chat';\n        const plan = interpretResultToPlan(result, intent, mode, isStreaming);\n        result.plan = plan; // Attach plan to result for recording\n\n        // 7. Save Execution Record (before execution for safety)\n        saveRecord({\n            id,\n            timestamp: Date.now(),\n            mode,\n            input,\n            prompt,\n            model,\n            llmResult: result,\n            action: plan.tasks[0]?.type === 'shell' ? {\n                type: 'execute',\n                command: plan.tasks[0].payload.command,\n                risk: plan.tasks[0].payload.risk\n            } : { type: 'print', content: result.rawText }, \n        });\n\n        // 8. Plan Execution\n        // Note: For chat, execution usually is just \"printing\", which happened via stream.\n        // interpretResultToPlan handles ignoring tasks if streamed.\n        const summary = await executePlan(plan, input.options);\n\n        // 9. Post-execution: Learn Skill if successful\n        learnSkillFromRecord({\n            id,\n            timestamp: Date.now(),\n            mode,\n            input,\n            prompt,\n            model,\n            llmResult: result,\n            action: plan.tasks[0]?.type === 'shell' ? {\n                type: 'execute',\n                command: plan.tasks[0].payload.command,\n                risk: plan.tasks[0].payload.risk\n            } : { type: 'print', content: result.rawText },\n        }, summary.success);\n\n        // Log execution metrics if verbose\n        if (input.options?.verbose) {\n            console.log(`\\n${'-'.repeat(50)}`);\n            console.log(`Execution ID: ${id}`);\n            console.log(`Model: ${model}`);\n            console.log(`Latency: ${result.latencyMs}ms`);\n            if (result.tokens) {\n                console.log(`Tokens: ${result.tokens.total}`);\n            }\n            console.log(`${'-'.repeat(50)}\\n`);\n        }\n    }\n}\n",
    "tokens": 997
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/prompt.ts",
    "content": "import {\n    AgentIntent,\n    AgentContext,\n    AgentMode,\n    AgentPrompt,\n} from './types';\nimport { buildCommandPrompt as buildCommandPromptString } from '../ai/prompt';\nimport { getOSProfile } from '../core/os';\nimport { getMacros } from '../core/macros';\nimport { aiCommandPlanSchema } from '../core/validation';\nimport { getRelevantSkills } from './skills';\n\nexport function buildPrompt(\n    intent: AgentIntent,\n    context: AgentContext,\n    mode: AgentMode,\n    input: string\n): AgentPrompt {\n    if (mode === 'chat') {\n        return buildChatPrompt(context, input);\n    }\n\n    return buildCommandPromptObject(input, context);\n}\n\nfunction buildChatPrompt(\n    context: AgentContext,\n    input: string\n): AgentPrompt {\n    const messages: any[] = [\n        ...(context.history ?? []),\n    ];\n\n    // Add context files if available\n    if (context.files && context.files.length > 0) {\n        const contextDesc = context.files.map(f =>\n            `File: ${f.path}\\n\\`\\`\\`\\n${f.content}\\n\\`\\`\\``\n        ).join('\\n\\n');\n\n        messages.push({\n            role: 'system',\n            content: `Context:\\n${contextDesc}`,\n        });\n    }\n\n    messages.push({\n        role: 'user',\n        content: input,\n    });\n\n    return {\n        system: 'You are a helpful AI assistant with expertise in software development, system administration, and problem-solving.',\n        messages,\n    };\n}\n\nfunction buildCommandPromptObject(\n    input: string,\n    context: AgentContext\n): AgentPrompt {\n    const os = getOSProfile();\n    const macros = getMacros();\n    const skills = getRelevantSkills(input);\n    let promptText = buildCommandPromptString(input, os, macros);\n\n    if (skills.length > 0) {\n        const skillList = skills.map(s => `- ${s.name}: ÂΩìÈÅáÂà∞ \"${s.whenToUse}\" Êó∂Ôºå‰Ω†ÂèØ‰ª•ÂèÇËÄÉËÆ°Âàí: ${s.planTemplate.goal}`).join('\\n');\n        promptText = `„ÄêÂèÇËÄÉÊäÄËÉΩÂ∫ì„Äë\\n${skillList}\\n\\n${promptText}`;\n    }\n\n    return {\n        messages: [\n            {\n                role: 'user',\n                content: promptText,\n            },\n        ],\n        outputSchema: aiCommandPlanSchema,\n    };\n}\n",
    "tokens": 522
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/record.ts",
    "content": "import {\n    AgentInput,\n    AgentMode,\n    AgentPrompt,\n    LLMResult,\n    AgentAction,\n} from './types';\n\nexport interface ExecutionRecord {\n    id: string;\n    timestamp: number;\n    mode: AgentMode;\n    input: AgentInput;\n    prompt: AgentPrompt;\n    model: string;\n    llmResult: LLMResult;\n    action: AgentAction;\n}\n\nconst records: ExecutionRecord[] = [];\n\nexport function saveRecord(record: ExecutionRecord) {\n    records.push(record);\n    // Keep only last 100 records in memory\n    if (records.length > 100) {\n        records.shift();\n    }\n}\n\nexport function getRecords(): ExecutionRecord[] {\n    return [...records];\n}\n\nexport function getRecordById(id: string): ExecutionRecord | undefined {\n    return records.find(r => r.id === id);\n}\n",
    "tokens": 188
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/context.ts",
    "content": "import { AgentInput, AgentContext } from './types';\nimport { ContextBuffer } from '../commands/contextBuffer';\n\nexport function buildContext(input: AgentInput, contextBuffer: ContextBuffer): AgentContext {\n    const items = contextBuffer.export();\n\n    return {\n        files: items.map(item => ({\n            path: item.path,\n            content: item.content,\n        })),\n        gitDiff: undefined, // Will be enhanced later\n        history: [], // Will be populated from conversation history\n    };\n}\n",
    "tokens": 127
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/replay.ts",
    "content": "import { ExecutionRecord } from './record';\nimport { runLLM } from './llm';\nimport { interpretResultToPlan } from './interpret';\nimport { AgentIntent } from './types';\n\nexport async function replay(record: ExecutionRecord) {\n    console.log(`\\nReplaying execution: ${record.id}`);\n    console.log(`Original timestamp: ${new Date(record.timestamp).toISOString()}`);\n    console.log(`Mode: ${record.mode}\\n`);\n\n    const result = await runLLM({\n        prompt: record.prompt,\n        model: record.model,\n        stream: record.mode === 'chat',\n        onChunk: record.mode === 'chat'\n            ? (s) => process.stdout.write(s)\n            : undefined,\n    });\n\n    // Create a minimal intent for interpretation\n    const intent: AgentIntent = {\n        type: record.mode === 'chat' ? 'chat' : 'shell',\n        capabilities: {},\n    };\n\n    return interpretResultToPlan(result, intent, record.mode);\n}\n",
    "tokens": 226
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/planExecutor.ts",
    "content": "import { AgentPlan, AgentTask } from './plan';\nimport { executeAction } from './actions';\nimport chalk from 'chalk';\n\nexport interface PlanExecutionSummary {\n    success: boolean;\n    completedCount: number;\n    totalCount: number;\n}\n\nexport async function executePlan(\n    plan: AgentPlan,\n    options?: { autoYes?: boolean; verbose?: boolean }\n): Promise<PlanExecutionSummary> {\n    const completed = new Set<string>();\n    const failed = new Set<string>();\n\n    if (options?.verbose) {\n        console.log(chalk.bold.cyan(`\\nüöÄ ÂºÄÂßãÊâßË°åËÆ°Âàí: ${plan.goal}`));\n        console.log(chalk.gray(`ÂÖ± ${plan.tasks.length} ‰∏™‰ªªÂä°\\n`));\n    }\n\n    for (const task of plan.tasks) {\n        // Ê£ÄÊü•‰æùËµñ\n        if (task.dependsOn?.some(depId => !completed.has(depId))) {\n            if (options?.verbose) {\n                console.log(chalk.yellow(`‚è≠Ô∏è Ë∑≥Ëøá‰ªªÂä° ${task.id}: ‰æùËµñÊú™ÂÆåÊàê`));\n            }\n            continue;\n        }\n\n        if (failed.has(task.id)) continue;\n\n        try {\n            task.status = 'running';\n            if (options?.verbose) {\n                console.log(chalk.cyan(`‚öôÔ∏è ÊâßË°å‰ªªÂä° ${task.id}: ${task.description}`));\n            }\n\n            await executeTask(task, options);\n\n            task.status = 'success';\n            completed.add(task.id);\n        } catch (error: any) {\n            task.status = 'failed';\n            failed.add(task.id);\n            console.error(chalk.red(`‚ùå ‰ªªÂä° ${task.id} Â§±Ë¥•: ${error.message}`));\n            // Â¶ÇÊûú‰∏Ä‰∏™‰ªªÂä°Â§±Ë¥•ÔºåÂêéÁª≠‰æùËµñÂÆÉÁöÑ‰ªªÂä°ÈÉΩ‰ºöË¢´Ë∑≥Ëøá\n        }\n    }\n\n    if (options?.verbose) {\n        console.log(chalk.bold.green(`\\n‚úÖ ËÆ°ÂàíÊâßË°åÂÆåÊàê (${completed.size}/${plan.tasks.length} ÊàêÂäü)\\n`));\n    }\n\n    return {\n        success: failed.size === 0 && completed.size > 0,\n        completedCount: completed.size,\n        totalCount: plan.tasks.length\n    };\n}\n\nasync function executeTask(\n    task: AgentTask,\n    options?: { autoYes?: boolean }\n): Promise<void> {\n    switch (task.type) {\n        case 'shell':\n            await executeAction({\n                type: 'confirm',\n                next: {\n                    type: 'execute',\n                    command: task.payload.command,\n                    risk: task.payload.risk || 'medium'\n                }\n            }, options);\n            break;\n\n        case 'custom':\n            if (task.payload?.kind === 'print' && task.payload?.text) {\n                console.log(task.payload.text);\n            }\n            break;\n\n        case 'llm':\n            // Êú™Êù•ÂèØ‰ª•ÊîØÊåÅ‰ªªÂä°‰∏≠ÂÜçÊ¨°Ë∞ÉÁî® LLM (Recursive Agent)\n            console.log(chalk.gray(`[LLM Task] ${task.description} (Not implemented in MVP)`));\n            break;\n    }\n}\n",
    "tokens": 650
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/types.ts",
    "content": "import type { AIRequestMessage } from '../core/validation';\nimport { AgentPlan } from './plan';\n\nexport type AgentMode = 'chat' | 'command' | 'command+exec';\n\nexport interface AgentInput {\n    rawInput: string;\n    stdin?: string;\n    context?: AgentContext;\n    options?: {\n        model?: string;\n        stream?: boolean;\n        autoYes?: boolean;\n        verbose?: boolean;\n    };\n}\n\nexport interface AgentContext {\n    files?: Array<{ path: string; content: string }>;\n    gitDiff?: string;\n    history?: AIRequestMessage[];\n}\n\nexport interface AgentIntent {\n    type: 'chat' | 'shell' | 'analysis';\n    capabilities: {\n        reasoning?: boolean;\n        code?: boolean;\n        longContext?: boolean;\n        streaming?: boolean;\n    };\n}\n\nexport interface AgentPrompt {\n    system?: string;\n    messages: AIRequestMessage[];\n    outputSchema?: any;\n}\n\nexport interface LLMResult {\n    rawText: string;\n    parsed?: any;\n    plan?: AgentPlan;\n    latencyMs: number;\n    tokens?: {\n        prompt: number;\n        completion: number;\n        total: number;\n    };\n    costUsd?: number;\n}\n\nexport type AgentAction =\n    | { type: 'print'; content: string }\n    | { type: 'confirm'; next: AgentAction }\n    | { type: 'execute'; command: string; risk: 'low' | 'medium' | 'high' };\n",
    "tokens": 322
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/llm.ts",
    "content": "import { AgentPrompt, LLMResult } from './types';\nimport { callAI_Stream } from '../ai/client';\nimport axios from 'axios';\nimport { DEFAULT_AI_PROXY_URL, DEFAULT_MODEL, DEFAULT_ACCOUNT_TYPE, type AIRequestMessage } from '../core/validation';\nimport fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { safeParseJSON } from '../core/validation';\n\nconst CONFIG_FILE = path.join(os.homedir(), '.yuangs.json');\n\nfunction getUserConfig(): any {\n    if (fs.existsSync(CONFIG_FILE)) {\n        try {\n            const content = fs.readFileSync(CONFIG_FILE, 'utf8');\n            return JSON.parse(content);\n        } catch (e) { }\n    }\n    return {};\n}\n\nexport async function runLLM({\n    prompt,\n    model,\n    stream,\n    onChunk,\n}: {\n    prompt: AgentPrompt;\n    model: string;\n    stream: boolean;\n    onChunk?: (s: string) => void;\n}): Promise<LLMResult> {\n    const start = Date.now();\n\n    if (stream) {\n        let raw = '';\n        await callAI_Stream(prompt.messages, model, (chunk) => {\n            raw += chunk;\n            onChunk?.(chunk);\n        });\n        return {\n            rawText: raw,\n            latencyMs: Date.now() - start,\n        };\n    }\n\n    // Non-streaming mode with optional schema\n    const config = getUserConfig();\n    const url = config.aiProxyUrl || DEFAULT_AI_PROXY_URL;\n\n    const headers = {\n        'Content-Type': 'application/json',\n        'X-Client-ID': 'npm_yuangs',\n        'Origin': 'https://cli.want.biz',\n        'Referer': 'https://cli.want.biz/',\n        'account': config.accountType || DEFAULT_ACCOUNT_TYPE,\n        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1',\n        'Accept': 'application/json'\n    };\n\n    const data = {\n        model: model || config.defaultModel || DEFAULT_MODEL,\n        messages: prompt.messages,\n        stream: false\n    };\n\n    try {\n        const response = await axios.post(url, data, { headers });\n        const rawText = response.data.choices[0]?.message?.content || '';\n\n        let parsed = undefined;\n        if (prompt.outputSchema) {\n            const parseResult = safeParseJSON(rawText, prompt.outputSchema, {});\n            if (parseResult.success) {\n                parsed = parseResult.data;\n            }\n        }\n\n        return {\n            rawText,\n            parsed,\n            latencyMs: Date.now() - start,\n        };\n    } catch (error: any) {\n        const errorMsg = error.response?.data?.error?.message || error.response?.data?.message || error.message || 'Êú™Áü•ÈîôËØØ';\n        throw new Error(`AI ËØ∑Ê±ÇÂ§±Ë¥•: ${errorMsg}`);\n    }\n}\n",
    "tokens": 663
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/actions.ts",
    "content": "import { AgentAction } from './types';\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\nimport chalk from 'chalk';\nimport readline from 'readline';\n\nconst execAsync = promisify(exec);\n\nexport async function executeAction(\n    action: AgentAction,\n    options?: { autoYes?: boolean }\n): Promise<void> {\n    if (action.type === 'print') {\n        console.log(action.content);\n        return;\n    }\n\n    if (action.type === 'confirm') {\n        const ok = options?.autoYes || await confirm('Execute this action?');\n        if (ok) {\n            await executeAction(action.next, options);\n        }\n        return;\n    }\n\n    if (action.type === 'execute') {\n        try {\n            console.log(chalk.cyan(`\\nExecuting: ${action.command}\\n`));\n            const { stdout, stderr } = await execAsync(action.command, {\n                shell: typeof process.env.SHELL === 'string' ? process.env.SHELL : undefined\n            });\n            if (stdout) console.log(stdout);\n            if (stderr) console.error(chalk.yellow(stderr));\n        } catch (error: any) {\n            console.error(chalk.red(`Execution failed: ${error.message}`));\n            throw error;\n        }\n    }\n}\n\nasync function confirm(message: string): Promise<boolean> {\n    const rl = readline.createInterface({\n        input: process.stdin,\n        output: process.stdout,\n    });\n\n    return new Promise((resolve) => {\n        rl.question(chalk.cyan(`${message} (y/N): `), (answer) => {\n            rl.close();\n            resolve(answer.toLowerCase() === 'y' || answer.toLowerCase() === 'yes');\n        });\n    });\n}\n",
    "tokens": 404
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/index.ts",
    "content": "export { AgentPipeline } from './AgentPipeline';\nexport * from './types';\n",
    "tokens": 19
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/skills.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { AgentPlan } from './plan';\nimport { ExecutionRecord } from './record';\nimport chalk from 'chalk';\n\nexport interface Skill {\n    id: string;\n    name: string;\n    description: string;\n    whenToUse: string; // Ëß¶ÂèëÂú∫ÊôØÊèèËø∞\n    planTemplate: AgentPlan;\n\n    // ËØÑ‰ª∑ÊåáÊ†á\n    successCount: number;\n    failureCount: number;\n    confidence: number; // 0 ~ 1, ÂàùÂßã 0.5\n\n    // Êó∂Èó¥Êà≥\n    lastUsed: number;\n    createdAt: number;\n}\n\nconst SKILLS_FILE = path.join(os.homedir(), '.yuangs_skills.json');\nlet skillLibrary: Skill[] = [];\n\n// === Persistence Logic ===\n\nfunction loadSkills() {\n    if (fs.existsSync(SKILLS_FILE)) {\n        try {\n            const data = fs.readFileSync(SKILLS_FILE, 'utf-8');\n            skillLibrary = JSON.parse(data);\n        } catch (e) {\n            console.error(chalk.yellow(`Failed to load skills from ${SKILLS_FILE}, starting empty.`));\n            skillLibrary = [];\n        }\n    }\n}\n\nfunction saveSkills() {\n    try {\n        fs.writeFileSync(SKILLS_FILE, JSON.stringify(skillLibrary, null, 2));\n    } catch (e) {\n        console.error(chalk.red(`Failed to save skills to ${SKILLS_FILE}`));\n    }\n}\n\n// Initialize on load\nloadSkills();\n\n// === Existing Logic with Save Hooks ===\n\n/**\n * ËÆ°ÁÆóÊäÄËÉΩÂàÜ (0 ~ 1)\n */\nfunction computeSkillScore(skill: Skill, now: number = Date.now()): number {\n    const totalUses = skill.successCount + skill.failureCount;\n    const successRate = totalUses === 0 ? 0.5 : skill.successCount / totalUses;\n\n    // Êó∂Èó¥Ë°∞Âáè (Freshness): ÂçäË°∞ÊúüÁ∫¶ 14 Â§©\n    const idleDays = (now - skill.lastUsed) / (1000 * 60 * 60 * 24);\n    const freshness = Math.exp(-idleDays / 14);\n\n    // ÁªºÂêàÂæóÂàÜ: 45% ÊàêÂäüÁéá + 35% Êñ∞È≤úÂ∫¶ + 20% ÁΩÆ‰ø°Â∫¶\n    return (0.45 * successRate) + (0.35 * freshness) + (0.20 * skill.confidence);\n}\n\n/**\n * Êõ¥Êñ∞ÊäÄËÉΩÁä∂ÊÄÅ (ÊâßË°åÂêéË∞ÉÁî®)\n */\nexport function updateSkillStatus(skillId: string, success: boolean) {\n    const skill = skillLibrary.find(s => s.id === skillId);\n    if (!skill) return;\n\n    skill.lastUsed = Date.now();\n    if (success) {\n        skill.successCount++;\n        // ÊàêÂäüÂ•ñÂä±: ÁΩÆ‰ø°Â∫¶ÁºìÊÖ¢ÊèêÂçá\n        skill.confidence = Math.min(1, skill.confidence + 0.05);\n    } else {\n        skill.failureCount++;\n        // Â§±Ë¥•ÊÉ©ÁΩö: ÊÉ©ÁΩöÂäõÂ∫¶Â§ß‰∫éÂ•ñÂä±ÔºåÈò≤Ê≠¢Á≥ªÁªü‚ÄúËá™Âó®‚Äù\n        skill.confidence = Math.max(0, skill.confidence - 0.1);\n    }\n    \n    saveSkills(); // Persist changes\n}\n\n/**\n * Ëá™Âä®Â≠¶‰π†Êñ∞ÊäÄËÉΩ\n */\nexport function learnSkillFromRecord(record: ExecutionRecord, success: boolean = true) {\n    if (record.mode === 'chat' || !record.llmResult.plan) return;\n\n    const existingSkill = skillLibrary.find(s => s.name === record.llmResult.plan?.goal);\n\n    if (existingSkill) {\n        updateSkillStatus(existingSkill.id, success);\n        return;\n    }\n\n    // Âè™ÊúâÊàêÂäüÁöÑËÆ∞ÂΩïÊâçË¢´Â≠¶‰∏∫Êñ∞ÊäÄËÉΩ\n    if (!success) return;\n\n    const now = Date.now();\n    skillLibrary.push({\n        id: record.id,\n        name: record.llmResult.plan.goal,\n        description: `Ëá™Âä®Â≠¶‰π†ÁöÑÊäÄËÉΩ: ${record.llmResult.plan.goal}`,\n        whenToUse: record.input.rawInput,\n        planTemplate: record.llmResult.plan,\n        successCount: 1,\n        failureCount: 0,\n        confidence: 0.5,\n        lastUsed: now,\n        createdAt: now\n    });\n\n    // ÊØèÂ≠¶‰π†‰∏ÄÊ¨°ÔºåÂ∞ùËØïÊ∏ÖÁêÜ‰∏ÄÊ¨°‚ÄúÂÜ∑‚ÄùÊäÄËÉΩ\n    reapColdSkills();\n    \n    saveSkills(); // Persist changes\n}\n\n/**\n * Á≠õÈÄâÂπ∂ÊéíÂ∫èÊäÄËÉΩ (Áî®‰∫éÊ≥®ÂÖ• Prompt)\n */\nexport function getRelevantSkills(input: string, limit: number = 3): Skill[] {\n    const now = Date.now();\n\n    return skillLibrary\n        // 1. Âü∫Á°ÄÁ≠õÈÄâ: ÂâîÈô§ËØÑÂàÜËøá‰ΩéÁöÑÊäÄËÉΩ (Á°¨Ê∑òÊ±∞ÈòàÂÄº 0.3)\n        .filter(s => computeSkillScore(s, now) >= 0.3)\n        // 2. ÊéíÂ∫è: ÊåâÁªºÂêàÂàÜÊéíÂ∫è\n        .sort((a, b) => computeSkillScore(b, now) - computeSkillScore(a, now))\n        // 3. Âèñ‰∏äÈôê\n        .slice(0, limit);\n}\n\n/**\n * Ê∏ÖÁêÜËøáÊúüÊàñ‰ΩéË¥®ÊäÄËÉΩ (Reaper)\n */\nexport function reapColdSkills() {\n    const now = Date.now();\n    const initialCount = skillLibrary.length;\n\n    skillLibrary = skillLibrary.filter(skill => {\n        const score = computeSkillScore(skill, now);\n        const idleDays = (now - skill.lastUsed) / (1000 * 60 * 60 * 24);\n\n        // Êª°Ë∂≥‰ª•‰∏ã‰ªª‰∏ÄÊù°‰ª∂ÂàôÊ∑òÊ±∞:\n        // 1. ÂæóÂàÜÊûÅ‰Ωé‰∏îÈïøÊúü‰∏çÁî®\n        if (score < 0.25 && idleDays > 30) return false;\n        // 2. Â§±Ë¥•ÁéáÊûÅÈ´ò‰∏îÂ∞ùËØïËøá‰∏ÄÂÆöÊ¨°Êï∞\n        if (skill.failureCount > 5 && (skill.successCount / (skill.successCount + skill.failureCount)) < 0.2) return false;\n\n        return true;\n    });\n\n    // Âº∫Âà∂‰øùÊåÅÂÆπÈáè\n    if (skillLibrary.length > 100) {\n        // Â¶ÇÊûúËøòË∂ÖÊ†áÔºåÁßªÈô§ÂæóÂàÜÊúÄ‰ΩéÁöÑÈÇ£‰∏™\n        skillLibrary.sort((a, b) => computeSkillScore(a, now) - computeSkillScore(b, now));\n        skillLibrary.shift();\n    }\n    \n    if (skillLibrary.length !== initialCount) {\n        saveSkills(); // Persist if changes happened\n    }\n}\n\nexport function getAllSkills(): Skill[] {\n    return [...skillLibrary];\n}\n",
    "tokens": 1167
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/interpret.ts",
    "content": "import { AgentIntent, AgentMode, LLMResult } from './types';\nimport { AgentPlan } from './plan';\n\nexport function interpretResultToPlan(\n    result: LLMResult,\n    intent: AgentIntent,\n    mode: AgentMode,\n    alreadyStreamed: boolean = false\n): AgentPlan {\n    if (mode === 'chat') {\n        const tasks = alreadyStreamed ? [] : [{\n            id: 'chat-response',\n            description: 'ËæìÂá∫ AI ÂõûÁ≠î',\n            type: 'custom' as const,\n            status: 'pending' as const,\n            payload: { kind: 'print', text: result.rawText }\n        }];\n\n        return {\n            goal: 'ÂõûÁ≠îÁî®Êà∑Âí®ËØ¢',\n            tasks: tasks\n        };\n    }\n\n    const aiPlan = result.parsed;\n    if (!aiPlan || (!aiPlan.command && !aiPlan.macro)) {\n        throw new Error('AI Êú™ËÉΩÁîüÊàêÊúâÊïàÁöÑÊâßË°åËÆ°Âàí');\n    }\n\n    const command = aiPlan.command || aiPlan.macro; // ÊöÇÊó∂ÁÆÄÂåñÂ§ÑÁêÜ\n\n    return {\n        goal: aiPlan.plan || 'ÊâßË°å Shell ÂëΩ‰ª§',\n        tasks: [\n            {\n                id: 'exec-shell',\n                description: `ÊâßË°åÂëΩ‰ª§: ${command}`,\n                type: 'shell',\n                status: 'pending',\n                payload: {\n                    command: command,\n                    risk: aiPlan.risk ?? 'medium'\n                }\n            }\n        ]\n    };\n}\n",
    "tokens": 313
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/selectModel.ts",
    "content": "import { AgentIntent } from './types';\n\nexport function selectModel(\n    intent: AgentIntent,\n    override?: string\n): string {\n    if (override) return override;\n\n    const caps = intent.capabilities;\n\n    // Long context + reasoning = most powerful model\n    if (caps.longContext && caps.reasoning) {\n        return 'gemini-2.0-flash-exp';\n    }\n\n    // Code-focused tasks\n    if (caps.code) {\n        return 'gemini-2.5-flash-lite';\n    }\n\n    // Default to balanced model\n    return 'gemini-2.5-flash-lite';\n}\n",
    "tokens": 129
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/plan.ts",
    "content": "export interface AgentPlan {\n    goal: string;\n    tasks: AgentTask[];\n}\n\nexport interface AgentTask {\n    id: string;\n    description: string;\n    type: 'llm' | 'shell' | 'custom';\n    dependsOn?: string[];\n    payload?: any;\n    status: 'pending' | 'running' | 'success' | 'failed';\n    result?: any;\n}\n",
    "tokens": 77
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/agent/intent.ts",
    "content": "import { AgentInput, AgentIntent, AgentMode } from './types';\nimport { inferCapabilityRequirement } from '../core/capabilityInference';\nimport { AtomicCapability } from '../core/capabilities';\n\nexport function inferIntent(\n    input: AgentInput,\n    mode: AgentMode\n): AgentIntent {\n    if (mode === 'chat') {\n        return {\n            type: 'chat',\n            capabilities: {\n                reasoning: true,\n                streaming: true,\n                longContext: true,\n            },\n        };\n    }\n\n    // For command mode, use the existing capability inference\n    const capReq = inferCapabilityRequirement(input.rawInput);\n\n    return {\n        type: 'shell',\n        capabilities: {\n            reasoning: capReq.required.includes(AtomicCapability.REASONING),\n            code: capReq.required.includes(AtomicCapability.CODE_GENERATION),\n            longContext: capReq.required.includes(AtomicCapability.LONG_CONTEXT),\n        },\n    };\n}\n",
    "tokens": 240
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/ai/prompt.ts",
    "content": "import { OSProfile } from '../core/os';\nimport type { Macro } from '../core/validation';\n\nexport function buildCommandPrompt(\n    userInput: string,\n    os: OSProfile,\n    macros?: Record<string, Macro>,\n    context?: string\n): string {\n    const macroContext = macros && Object.keys(macros).length > 0\n        ? `\n„ÄêÂèØÂ§çÁî®ÁöÑÂø´Êç∑Êåá‰ª§ (Macros)„Äë\n‰ª•‰∏ãÊòØÂèØ‰ª•Áõ¥Êé•Â§çÁî®ÁöÑÂ∑≤È™åËØÅÂëΩ‰ª§„ÄÇ‰ºòÂÖàÂ§çÁî®Ëøô‰∫õÊåá‰ª§ÔºåËÄå‰∏çÊòØÁîüÊàêÊñ∞ÂëΩ‰ª§Ôºö\n\n${Object.entries(macros).map(([name, macro]) => `  - ${name}: ${macro.description || '(Êó†ÊèèËø∞)'}`).join('\\n')}\n\nÂΩìÁî®Êà∑ÁöÑÈúÄÊ±Ç‰∏éÊüê‰∏™ Macro ÂåπÈÖçÊàñÁõ∏‰ººÊó∂Ôºö\n1. ‰ºòÂÖà‰ΩøÁî®ËØ• Macro\n2. Âú® JSON ËæìÂá∫‰∏≠‰ΩøÁî® \"macro\" Â≠óÊÆµÊåáÂÆö Macro ÂêçÁß∞ÔºåËÄå‰∏çÊòØ \"command\" Â≠óÊÆµ\n3. ‰ªÖÂú®Ê≤°ÊúâÂêàÈÄÇ Macro Êó∂ÊâçÁîüÊàêÊñ∞ÂëΩ‰ª§\n`\n        : '';\n\n    return `\n‰Ω†ÊòØ‰∏Ä‰∏™‰∏ì‰∏öÁöÑÂëΩ‰ª§Ë°å‰∏ìÂÆ∂„ÄÇ\n\n„ÄêÁ≥ªÁªüÁéØÂ¢É„Äë\n- Êìç‰ΩúÁ≥ªÁªü: ${os.name}\n- Shell: ${os.shell}\n- find ÂÆûÁé∞: ${os.find}\n- stat ÂÆûÁé∞: ${os.stat}\n\n„ÄêËßÑÂàô„Äë\n- ÂëΩ‰ª§ÂøÖÈ°ª‰∏éÂΩìÂâçÁ≥ªÁªüÂÖºÂÆπ„ÄÇ\n- Â¶ÇÊûúÊòØ macOS (BSD):\n  - ‰∏çÂÖÅËÆ∏‰ΩøÁî® find -printf\n  - ‰ºòÂÖà‰ΩøÁî® stat -f\n- Â¶ÇÊûúÊòØ Linux (GNU):\n  - ÂèØ‰ΩøÁî® find -printf\n- ÈªòËÆ§‰∏ç‰ΩøÁî® sudo„ÄÇ\n- Á°Æ‰øùËæìÂá∫ÁöÑÂëΩ‰ª§ÊòØÂçïË°åÊàñËÄÖ‰ΩøÁî® && ËøûÊé•„ÄÇ\n- ‰∏çË¶ÅËß£ÈáäÔºåÂè™ËæìÂá∫Á¨¶Âêà‰ª•‰∏ã JSON ÁªìÊûÑÁöÑÊñáÊú¨„ÄÇ\n- ‰ºòÂÖàÂ§çÁî®Â∑≤È™åËØÅÁöÑÂø´Êç∑Êåá‰ª§ÔºàMacrosÔºâÔºåÊØè‰∏™ Macro ÈÉΩÊòØÁªèËøá‰∫∫Â∑•È™åËØÅÁöÑÂèØÈù†ÂëΩ‰ª§„ÄÇÂú®ÁîüÊàêÊñ∞ÂëΩ‰ª§ÂâçÔºåÊ£ÄÊü•ÊòØÂê¶Â∑≤Êúâ Macro ÂèØ‰ª•ÂÆåÊàê‰ªªÂä°„ÄÇ\n\n${macroContext}\n\n„ÄêËæìÂá∫ JSON ÁªìÊûÑ„Äë\n{\n  \"plan\": \"ÁÆÄË¶ÅËØ¥Êòé‰Ω†ÂáÜÂ§áÊâßË°åÁöÑÊ≠•È™§\",\n  \"command\": \"ÂèØÁõ¥Êé•ÊâßË°åÁöÑ shell ÂëΩ‰ª§Ôºà‰ªÖÂΩìÊ≤°ÊúâÂêàÈÄÇ Macro Êó∂Êèê‰æõÔºâ\",\n  \"macro\": \"Ë¶ÅÂ§çÁî®ÁöÑ Macro ÂêçÁß∞Ôºà‰ºòÂÖà‰ΩøÁî®Ôºå‰∏é command ‰∫åÈÄâ‰∏ÄÔºâ\",\n  \"risk\": \"low | medium | high\"\n}\n\n„Äê‰∏ä‰∏ãÊñá‰ø°ÊÅØ„Äë\n${context || 'Êó†'}\n\n„ÄêÁî®Êà∑ÈúÄÊ±Ç„Äë\n${userInput}\n`;\n}\n\nexport function buildFixPrompt(\n    originalCmd: string,\n    stderr: string,\n    os: OSProfile\n): string {\n    return `\nËØ•ÂëΩ‰ª§Âú® ${os.name} ‰∏äÊâßË°åÂ§±Ë¥•Ôºö\n\nÂëΩ‰ª§Ôºö\n${originalCmd}\n\nÈîôËØØ‰ø°ÊÅØÔºö\n${stderr}\n\nËØ∑ÁîüÊàê‰∏Ä‰∏™ **${os.name} ÂÖºÂÆπ** ÁöÑÁ≠â‰ª∑ÂëΩ‰ª§„ÄÇ\n‰æùÁÑ∂Âè™ËæìÂá∫ JSON Ê†ºÂºè„ÄÇÊ≥®ÊÑèÔºöËøôÊòØ‰øÆÂ§çÂëΩ‰ª§Ôºå‰∏çÈúÄË¶ÅÊ£ÄÊü• Macro„ÄÇ\n\n{\n  \"plan\": \"‰øÆÂ§çËØ¥Êòé\",\n  \"command\": \"‰øÆÂ§çÂêéÁöÑÂëΩ‰ª§\",\n  \"risk\": \"low | medium | high\"\n}\n`;\n}\n",
    "tokens": 393
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/ai/types.ts",
    "content": "export { AICommandPlan, type AICommandPlan as AICommandPlanType } from '../core/validation';\n",
    "tokens": 24
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/ai/client.ts",
    "content": "import axios from 'axios';\nimport fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport { DEFAULT_AI_PROXY_URL, DEFAULT_MODEL, DEFAULT_ACCOUNT_TYPE, type UserConfig, type AIRequestMessage } from '../core/validation';\nimport { loadChatHistory, saveChatHistory } from '../commands/chatHistoryStorage';\n\nconst CONFIG_FILE = path.join(os.homedir(), '.yuangs.json');\n\nlet conversationHistory: AIRequestMessage[] = [];\n\n// ÂàùÂßãÂåñÊó∂Âä†ËΩΩÊåÅ‰πÖÂåñÁöÑËÅäÂ§©ÂéÜÂè≤ËÆ∞ÂΩï\nloadChatHistory().then(history => {\n    conversationHistory = history;\n});\n\nexport function addToConversationHistory(role: 'system' | 'user' | 'assistant', content: string) {\n    conversationHistory.push({ role, content });\n    if (conversationHistory.length > 20) {\n        conversationHistory = conversationHistory.slice(-20);\n    }\n    // ÂêåÊó∂‰øùÂ≠òÂà∞ÊåÅ‰πÖÂåñÂ≠òÂÇ®\n    saveChatHistory(conversationHistory);\n}\n\nexport function clearConversationHistory() {\n    conversationHistory = [];\n    // ÂêåÊó∂Ê∏ÖÈô§ÊåÅ‰πÖÂåñÂ≠òÂÇ®\n    saveChatHistory(conversationHistory);\n}\n\nexport function getConversationHistory() {\n    return conversationHistory;\n}\n\nexport function getUserConfig(): UserConfig {\n    if (fs.existsSync(CONFIG_FILE)) {\n        try {\n            const content = fs.readFileSync(CONFIG_FILE, 'utf8');\n            return JSON.parse(content) as UserConfig;\n        } catch (e) { }\n    }\n    return {};\n}\n\nexport async function askAI(prompt: string, model?: string): Promise<string> {\n    const config = getUserConfig();\n    const url = config.aiProxyUrl || DEFAULT_AI_PROXY_URL;\n\n    const headers = {\n        'Content-Type': 'application/json',\n        'X-Client-ID': 'npm_yuangs',\n        'Origin': 'https://cli.want.biz',\n        'Referer': 'https://cli.want.biz/',\n        'account': config.accountType || DEFAULT_ACCOUNT_TYPE,\n        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1',\n        'Accept': 'application/json'\n    };\n\n    const data = {\n        model: model || config.defaultModel || DEFAULT_MODEL,\n        messages: [{ role: 'user', content: prompt }],\n        stream: false\n    };\n\n    try {\n        const response = await axios.post(url, data, { headers });\n        const content = response.data?.choices?.[0]?.message?.content;\n        return content || '';\n    } catch (error: any) {\n        const errorMsg = error.response?.data?.error?.message || error.response?.data?.message || error.message || 'Êú™Áü•ÈîôËØØ';\n        throw new Error(`AI ËØ∑Ê±ÇÂ§±Ë¥•: ${errorMsg}`);\n    }\n}\n\nexport async function callAI_Stream(messages: AIRequestMessage[], model: string | undefined, onChunk: (content: string) => void): Promise<void> {\n    const config = getUserConfig();\n    const url = config.aiProxyUrl || DEFAULT_AI_PROXY_URL;\n\n    const response = await axios({\n        method: 'post',\n        url: url,\n        data: {\n            model: model || config.defaultModel || DEFAULT_MODEL,\n            messages: messages,\n            stream: true\n        },\n        responseType: 'stream',\n        headers: {\n            'Content-Type': 'application/json',\n            'X-Client-ID': 'npm_yuangs',\n            'Origin': 'https://cli.want.biz',\n            'Referer': 'https://cli.want.biz/',\n            'account': config.accountType || DEFAULT_ACCOUNT_TYPE,\n            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 18_5 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Mobile/15E148 Safari/604.1',\n            'Accept': 'application/json'\n        }\n    });\n\n    return new Promise((resolve, reject) => {\n        let buffer = '';\n        response.data.on('data', (chunk: Buffer) => {\n            buffer += chunk.toString();\n            let lines = buffer.split('\\n');\n            buffer = lines.pop() || '';\n\n            for (const line of lines) {\n                const trimmedLine = line.trim();\n                if (trimmedLine.startsWith('data: ')) {\n                    const data = trimmedLine.slice(6);\n                    if (data === '[DONE]') {\n                        resolve();\n                        return;\n                    }\n                    try {\n                        const parsed = JSON.parse(data);\n                        const content = parsed.choices[0]?.delta?.content || '';\n                        if (content) onChunk(content);\n                    } catch (e) { }\n                }\n            }\n        });\n        response.data.on('error', reject);\n        response.data.on('end', () => {\n            resolve();\n        });\n    });\n}\n",
    "tokens": 1130
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/commands/capabilityCommands.ts",
    "content": "import chalk from 'chalk';\nimport { Command } from 'commander';\nimport { AtomicCapability, COMPOSITE_CAPABILITIES } from '../core/capabilities';\nimport { CapabilitySystem } from '../core/capabilitySystem';\nimport { CapabilityRequirement } from '../core/modelMatcher';\nimport { listExecutionRecords } from '../core/executionStore';\nimport { ReplayMode } from '../core/replayEngine';\n\nexport function registerCapabilityCommands(program: Command): void {\n  const capProgram = program.command('capabilities').description('Capability system commands (new architecture)');\n\n  capProgram\n    .command('explain')\n    .description('Explain current configuration with sources')\n    .action(() => {\n      const system = new CapabilitySystem();\n      console.log(chalk.bold.cyan('\\nüìã Configuration Snapshot\\n'));\n      console.log(system.explainConfig());\n    });\n\n  capProgram\n    .command('match')\n    .description('Test capability matching')\n    .argument('<capabilities...>', 'Required capabilities (e.g., text_generation reasoning)')\n    .action((capabilities) => {\n      const system = new CapabilitySystem();\n\n      const { AtomicCapability } = require('../core/capabilities');\n\n      const requirement: CapabilityRequirement = {\n        required: capabilities as any,\n        preferred: [],\n      };\n\n      const result = system.matchCapability(requirement);\n\n      console.log(chalk.bold.cyan('\\nü§ñ Capability Match Result\\n'));\n\n      if (!result.selected) {\n        console.log(chalk.red('‚ùå No model satisfies requirements\\n'));\n        result.candidates.forEach(c => {\n          console.log(chalk.yellow(`${c.modelName} (${c.provider}):`));\n          console.log(chalk.gray(`  ${c.reason}\\n`));\n        });\n        return;\n      }\n\n      console.log(chalk.green(`‚úÖ Selected: ${result.selected.name} (${result.selected.provider})\\n`));\n\n      console.log(chalk.bold('Capability coverage:'));\n      result.selected.atomicCapabilities.forEach(cap => {\n        console.log(chalk.green(`  ‚úì ${cap}`));\n      });\n\n      if (result.fallbackOccurred) {\n        console.log(chalk.yellow('\\n‚ö†Ô∏è  Fallback was used'));\n      }\n\n      console.log(chalk.bold('\\nAll candidates:'));\n      result.candidates.forEach(c => {\n        const icon = c.hasRequired ? chalk.green('‚úì') : chalk.red('‚úó');\n        console.log(`  ${icon} ${c.modelName} (${c.provider})`);\n        console.log(chalk.gray(`    ${c.reason}\\n`));\n      });\n    });\n\n  capProgram\n    .command('list')\n    .description('List all available capabilities')\n    .action(() => {\n      console.log(chalk.bold.cyan('\\nüì¶ Available Capabilities\\n'));\n\n      console.log(chalk.bold('Atomic Capabilities:'));\n      Object.values(AtomicCapability).forEach(cap => {\n        console.log(`  - ${chalk.green(cap)}`);\n      });\n\n      console.log(chalk.bold('\\nComposite Capabilities:'));\n      COMPOSITE_CAPABILITIES.forEach(comp => {\n        console.log(`  - ${chalk.cyan(comp.name)}`);\n        console.log(chalk.gray(`    Composed of: ${comp.composedOf.join(', ')}`));\n      });\n    });\n\n  capProgram\n    .command('history')\n    .description('List execution history')\n    .option('-l, --limit <n>', 'Limit number of records', '10')\n    .action((options) => {\n      const limit = parseInt(options.limit);\n      const records = listExecutionRecords(limit);\n\n      if (records.length === 0) {\n        console.log(chalk.gray('üì≠ No execution history found\\n'));\n        return;\n      }\n\n      console.log(chalk.bold.cyan(`\\nüìã Execution History (last ${records.length})\\n`));\n\n      records.forEach((record, idx) => {\n        const status = record.outcome.success\n          ? chalk.green('‚úì')\n          : chalk.red('‚úó');\n        const model = record.decision.selectedModel?.name || 'N/A';\n        const time = new Date(record.meta.timestamp).toLocaleString();\n\n        console.log(`${status} ${chalk.white(record.id)}`);\n        console.log(chalk.gray(`  Command: ${record.meta.commandName}`));\n        console.log(chalk.gray(`  Model: ${model}`));\n        console.log(chalk.gray(`  Time: ${time}\\n`));\n      });\n    });\n\n  capProgram\n    .command('replay <id>')\n    .description('Replay an execution')\n    .option('-s, --strict', 'Strict replay (use exact model)')\n    .option('-c, --compatible', 'Compatible replay (allow fallback)')\n    .option('-v, --verbose', 'Verbose output')\n    .action(async (id, options) => {\n      const system = new CapabilitySystem();\n\n      let mode: ReplayMode = 'strict';\n      if (options.compatible) mode = 'compatible';\n\n      const result = await system.replayExecution(id, {\n        mode,\n        skipAI: true,\n        verbose: options.verbose,\n      });\n\n      if (result.success) {\n        console.log(chalk.green(`\\n‚úÖ ${result.message}\\n`));\n        if (result.executedModel) {\n          console.log(chalk.gray(`Model: ${result.executedModel}`));\n        }\n      } else {\n        console.log(chalk.red(`\\n‚ùå ${result.message}\\n`));\n      }\n    });\n}\n",
    "tokens": 1231
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/commands/contextStorage.ts",
    "content": "import fs from 'fs/promises';\nimport path from 'path';\nimport { ContextItem } from './contextBuffer';\n\nconst CONTEXT_DIR = path.resolve(process.cwd(), '.ai');\nconst CONTEXT_FILE = path.join(CONTEXT_DIR, 'context.json');\n\nexport async function loadContext(): Promise<ContextItem[]> {\n    try {\n        const raw = await fs.readFile(CONTEXT_FILE, 'utf-8');\n        return JSON.parse(raw);\n    } catch {\n        return [];\n    }\n}\n\nexport async function saveContext(items: ContextItem[]) {\n    await fs.mkdir(CONTEXT_DIR, { recursive: true });\n    await fs.writeFile(CONTEXT_FILE, JSON.stringify(items, null, 2));\n}\n\nexport async function clearContextStorage() {\n    await fs.rm(CONTEXT_FILE, { force: true });\n}\n",
    "tokens": 178
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/commands/chatHistoryStorage.ts",
    "content": "import fs from 'fs';\nimport { promisify } from 'util';\nimport path from 'path';\nimport os from 'os';\nimport { AIRequestMessage } from '../core/validation';\n\nconst CHAT_HISTORY_DIR = path.resolve(os.homedir(), '.yuangs_chat_history');\nconst CHAT_HISTORY_FILE = path.join(CHAT_HISTORY_DIR, 'chat_history.json');\n\nconst readFileAsync = promisify(fs.readFile);\nconst writeFileAsync = promisify(fs.writeFile);\nconst mkdirAsync = promisify(fs.mkdir);\nconst rmAsync = promisify(fs.rm);\n\nexport async function loadChatHistory(): Promise<AIRequestMessage[]> {\n    if (fs.existsSync(CHAT_HISTORY_FILE)) {\n        try {\n            const raw = await readFileAsync(CHAT_HISTORY_FILE, 'utf-8');\n            const data = JSON.parse(raw);\n\n            // È™åËØÅÊï∞ÊçÆÁªìÊûÑ\n            if (Array.isArray(data) && data.every(msg =>\n                typeof msg === 'object' &&\n                ['user', 'assistant', 'system'].includes(msg.role) &&\n                typeof msg.content === 'string'\n            )) {\n                return data as AIRequestMessage[];\n            }\n        } catch (e) {\n            console.warn('Ë≠¶Âëä: Âä†ËΩΩËÅäÂ§©ÂéÜÂè≤ËÆ∞ÂΩïÂ§±Ë¥•Ôºå‰ΩøÁî®Á©∫ÂéÜÂè≤ËÆ∞ÂΩï');\n        }\n    }\n    return [];\n}\n\nexport async function saveChatHistory(history: AIRequestMessage[]) {\n    try {\n        await mkdirAsync(CHAT_HISTORY_DIR, { recursive: true });\n        await writeFileAsync(CHAT_HISTORY_FILE, JSON.stringify(history, null, 2));\n    } catch (e) {\n        console.error('ÈîôËØØ: ‰øùÂ≠òËÅäÂ§©ÂéÜÂè≤ËÆ∞ÂΩïÂ§±Ë¥•:', e);\n    }\n}\n\nexport async function clearChatHistory() {\n    try {\n        await rmAsync(CHAT_HISTORY_FILE, { force: true });\n    } catch (e) {\n        console.error('ÈîôËØØ: Ê∏ÖÈô§ËÅäÂ§©ÂéÜÂè≤ËÆ∞ÂΩïÂ§±Ë¥•:', e);\n    }\n}\n",
    "tokens": 410
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/commands/gitContext.ts",
    "content": "import { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\nasync function run(cmd: string): Promise<string | null> {\n    try {\n        const { stdout } = await execAsync(cmd, { maxBuffer: 1024 * 1024 });\n        return stdout.trim() || null;\n    } catch {\n        return null;\n    }\n}\n\nexport async function getGitContext() {\n    const staged = await run('git diff --staged');\n    const unstaged = await run('git diff');\n\n    if (!staged && !unstaged) return null;\n\n    let result = `‰ª•‰∏ãÊòØ Git ÂèòÊõ¥ÂÜÖÂÆπÔºö\\n`;\n\n    if (staged) {\n        result += `\\n„ÄêÂ∑≤ÊöÇÂ≠ò„Äë\\n\\`\\`\\`diff\\n${staged}\\n\\`\\`\\`\\n`;\n    }\n\n    if (unstaged) {\n        result += `\\n„ÄêÊú™ÊöÇÂ≠ò„Äë\\n\\`\\`\\`diff\\n${unstaged}\\n\\`\\`\\`\\n`;\n    }\n\n    return result;\n}\n",
    "tokens": 188
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/commands/contextBuffer.ts",
    "content": "export type ContextItem = {\n    type: 'file' | 'directory';\n    path: string;\n    alias?: string;\n    content: string;\n    summary?: string;\n    tokens: number;\n};\n\nconst estimateTokens = (text: string) => Math.ceil(text.length / 4);\n\nexport class ContextBuffer {\n    private items: ContextItem[] = [];\n    private maxTokens = 32000; // Á∫¶ 12.8 ‰∏áÂ≠óÁ¨¶\n\n    add(item: Omit<ContextItem, 'tokens'>, bypassTokenLimit: boolean = false) {\n        const tokens = estimateTokens(item.content);\n        this.items.push({ ...item, tokens });\n        if (!bypassTokenLimit) {\n            this.trimIfNeeded();\n        }\n    }\n\n    clear() {\n        this.items = [];\n    }\n\n    list() {\n        return this.items.map((item, i) => ({\n            index: i + 1,\n            type: item.type,\n            path: item.path,\n            alias: item.alias,\n            tokens: item.tokens,\n            summary: item.summary\n        }));\n    }\n\n    isEmpty() {\n        return this.items.length === 0;\n    }\n\n    export() {\n        return this.items;\n    }\n\n    import(items: ContextItem[]) {\n        this.items = items;\n    }\n\n    private totalTokens() {\n        return this.items.reduce((sum, i) => sum + i.tokens, 0);\n    }\n\n    private trimIfNeeded() {\n        while (this.totalTokens() > this.maxTokens) {\n            this.items.shift();\n        }\n    }\n\n    buildPrompt(userInput: string): string {\n        if (this.isEmpty()) return userInput;\n\n        const contextBlock = this.items.map(item => {\n            const title = item.alias\n                ? `[Context Item] ${item.type}: ${item.alias} (${item.path})`\n                : `[Context Item] ${item.type}: ${item.path}`;\n\n            const body = item.summary ?? item.content;\n\n            return `${title}\\n---\\n${body}\\n---`;\n        }).join('\\n\\n');\n\n        return `\n# Áü•ËØÜ‰∏ä‰∏ãÊñá (Knowledge Context)\n‰Ω†ÁõÆÂâçÁöÑ‰ºöËØùÂ∑≤Âä†ËΩΩ‰ª•‰∏ãÂèÇËÄÉËµÑÊñô„ÄÇÂú®ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢òÊó∂ÔºåËØ∑‰ºòÂÖàÂèÇËÄÉËøô‰∫õÂÜÖÂÆπÔºö\n\n${contextBlock}\n\n# ‰ªªÂä°ËØ¥Êòé\nÂü∫‰∫é‰∏äËø∞Êèê‰æõÁöÑ‰∏ä‰∏ãÊñáÔºàÂ¶ÇÊûúÊúâÔºâÔºåÂõûÁ≠îÁî®Êà∑ÁöÑÈóÆÈ¢ò„ÄÇÂ¶ÇÊûú‰∏ä‰∏ãÊñá‰∏≠ÂåÖÂê´Ê∫êÁ†ÅÔºåËØ∑Â∞ÜÂÖ∂ËßÜ‰∏∫‰Ω†ÂΩìÂâçÁöÑ‚ÄúÁúüÁêÜÊù•Ê∫ê‚Äù„ÄÇ\n\nÁî®Êà∑ÈóÆÈ¢òÔºö\n${userInput}\n`;\n    }\n}\n// Test change for git diff\n// Another test change (unstaged)\n",
    "tokens": 510
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/commands/handleConfig.ts",
    "content": "import fs from 'fs';\nimport path from 'path';\nimport os from 'os';\nimport chalk from 'chalk';\nimport { parseUserConfig, userConfigSchema, type UserConfig } from '../core/validation';\n\nconst CONFIG_FILE = path.join(os.homedir(), '.yuangs.json');\n\nexport function handleConfig(args: string[]) {\n    const action = args[0]; // get, set, list\n\n    if (!action || action === 'list') {\n        const config = readConfig();\n        console.log(chalk.bold.cyan('\\n‚öôÔ∏è  ÂΩìÂâçÈÖçÁΩÆ (~/.yuangs.json):\\n'));\n        if (Object.keys(config).length === 0) {\n            console.log(chalk.gray('  (ÈÖçÁΩÆÊñá‰ª∂‰∏çÂ≠òÂú®Êàñ‰∏∫Á©∫)'));\n        } else {\n            Object.entries(config).forEach(([key, value]) => {\n                console.log(`  ${chalk.white(key)}: ${chalk.green(value)}`);\n            });\n        }\n        console.log('\\n‰ΩøÁî®ÊñπÊ≥ï:');\n        console.log(chalk.gray('  yuangs config set <key> <value>'));\n        console.log(chalk.gray('  yuangs config get <key>\\n'));\n        return;\n    }\n\n    if (action === 'set') {\n        const key = args[1];\n        const value = args[2];\n        if (!key || !value) {\n            console.log(chalk.red('ÈîôËØØ: ËØ∑Êèê‰æõ key Âíå value„ÄÇ‰æãÂ¶Ç: yuangs config set defaultModel gemini-2.5-flash-lite'));\n            return;\n        }\n        const config = readConfig();\n        config[key] = value;\n        writeConfig(config);\n        console.log(chalk.green(`‚úì Â∑≤Â∞Ü ${key} ËÆæÁΩÆ‰∏∫ ${value}`));\n        return;\n    }\n\n    if (action === 'get') {\n        const key = args[1];\n        if (!key) {\n            console.log(chalk.red('ÈîôËØØ: ËØ∑Êèê‰æõ key„ÄÇ‰æãÂ¶Ç: yuangs config get defaultModel'));\n            return;\n        }\n        const config = readConfig();\n        if (config[key] !== undefined) {\n            console.log(config[key]);\n        } else {\n            console.log(chalk.yellow(`ÈÖçÁΩÆÈ°π ${key} ‰∏çÂ≠òÂú®`));\n        }\n        return;\n    }\n}\n\nfunction readConfig(): UserConfig {\n    if (fs.existsSync(CONFIG_FILE)) {\n        try {\n            return parseUserConfig(fs.readFileSync(CONFIG_FILE, 'utf8'));\n        } catch (e) {\n            return {};\n        }\n    }\n    return {};\n}\n\nfunction writeConfig(config: UserConfig) {\n    const validated = userConfigSchema.parse(config);\n    fs.writeFileSync(CONFIG_FILE, JSON.stringify(validated, null, 2));\n}\n",
    "tokens": 560
  },
  {
    "type": "file",
    "path": "/Users/ygs/ygs/npm_yuangs/src/index.ts",
    "content": "// This file is empty because yuangs is a CLI-first project.\n// We don't expose any public library APIs to avoid breaking changes.\nexport { };\n",
    "tokens": 36
  }
]