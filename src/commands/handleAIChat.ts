import chalk from 'chalk';
import ora from 'ora';
import * as readline from 'node:readline/promises';
import { callAI_Stream, getConversationHistory, addToConversationHistory, clearConversationHistory } from '../ai/client';



export async function handleAIChat(question: string | null, model?: string) {
    if (question) {
        // First answer the provided question
        await askOnceStream(question, model);

        // If not a TTY, we stop here (likely piped input)
        if (!process.stdin.isTTY) {
            return;
        }
    }

    // Interactive mode
    console.log(chalk.bold.cyan('\nğŸ¤– è¿›å…¥ AI äº¤äº’æ¨¡å¼ (è¾“å…¥ exit é€€å‡º)\n'));

    const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout
    });

    try {
        while (true) {
            const q = await rl.question(chalk.green('ä½ ï¼š'));
            const trimmed = q.trim();

            if (['exit', 'quit', 'bye'].includes(trimmed.toLowerCase())) {
                console.log(chalk.cyan('ğŸ‘‹ å†è§ï¼'));
                break;
            }
            if (trimmed === '/clear') {
                clearConversationHistory();
                console.log(chalk.yellow('âœ“ å¯¹è¯å†å²å·²æ¸…ç©º\n'));
                continue;
            }
            if (trimmed === '/history') {
                const history = getConversationHistory();
                if (history.length === 0) {
                    console.log(chalk.gray('æš‚æ— å¯¹è¯å†å²\n'));
                } else {
                    history.forEach((msg) => {
                        const prefix = msg.role === 'user' ? chalk.green('ä½ : ') : chalk.blue('AI: ');
                        console.log(prefix + msg.content);
                    });
                }
                continue;
            }
            if (!trimmed) continue;

            await askOnceStream(trimmed, model);
        }
    } finally {
        rl.close();
    }
}

async function askOnceStream(question: string, model?: string) {
    const startTime = Date.now();
    const messages = [...getConversationHistory()];
    messages.push({ role: 'user', content: question });

    const spinner = ora(chalk.cyan('AI æ­£åœ¨æ€è€ƒ...')).start();
    let fullResponse = '';

    try {
        await callAI_Stream(messages, model, (chunk) => {
            if (spinner.isSpinning) {
                spinner.stop();
                process.stdout.write(chalk.bold.blue('ğŸ¤– AIï¼š'));
            }
            fullResponse += chunk;
            process.stdout.write(chunk);
        });

        addToConversationHistory('user', question);
        addToConversationHistory('assistant', fullResponse);

        const elapsed = (Date.now() - startTime) / 1000;
        console.log('\n' + chalk.gray(`â”€`.repeat(20) + ` (è€—æ—¶: ${elapsed.toFixed(2)}s) ` + `â”€`.repeat(20) + '\n'));
    } catch (error: any) {
        if (spinner.isSpinning) {
            spinner.fail(chalk.red('AI å“åº”å‡ºé”™'));
        } else {
            console.log(chalk.red('\n[AI Error]: ' + error.message));
        }
    }
}
